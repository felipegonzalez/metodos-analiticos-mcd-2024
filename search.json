[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos analíticos",
    "section": "",
    "text": "Temario y referencias\nEste es un curso de estadística bayesiana con énfasis en inferencia causal y flujos de trabajo robustos para análisis de datos. Está basado en el material de McElreath (2020).\nTodas las notas y material del curso estarán en este repositorio.\n\nModelos estadísticos e inferencia causal\nBásicos del flujo de trabajo para inferencia bayesiana\nBásicos de modelación\nModelos gráficos (DAGS) y efectos causales\nExperimentos. Buenos y malos controles\nMCMC, Monte Carlo Hamiltoniano y Stan\nFlujo de trabajo bayesiano avanzado\nModelos jerárquicos\nError de medición y clasificación incorrecta\nDatos faltantes\nOtros métodos de inferencia causal\n\n\nEvaluación\n\nTareas semanales (20%)\nExamen parcial (40% teórico)\nUn examen final (40% práctico)\n\n\n\nMaterial\nCada semestre las notas cambian, en algunas partes considerablemente. Las de este semestre están en este repositorio, incluyendo ejemplos, ejercicios y tareas.\n\n\nReferencias principales\nEste curso sigue aproximadamente la primera referencia (Statistical Rethinking).\n\nStatistical Rethinking\nCausal Inference in Statistics: a primer\nCounterfactuals and Causal Inference: Methods and Principles for Social Research\nBayesian workflow]\nTowards a principled Bayesian workflow\n\n\n\nOtras referencias\n\nThe Book of Why\nCausal Inference: The Mixtape\nData Analysis Using Regression and Multilevel/Hierarchical Models\nPattern Recognition and Machine Learning\n\n\n\nSoftware: R y Rstudio\nPara hacer las tareas y exámenes pueden usar cualquier lenguaje de programación que les convenga (R o Python, por ejemplo) - el único requisito esté basado en código y no point-and-click. Adicionalmente usaremos Stan:\n\nStan: a state-of-the-art platform for statistical modeling and high-performance statistical computation, que tiene interfaces en R, Python, Julia, etc.\n\n\n\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ."
  },
  {
    "objectID": "01-introduccion.html#diagramas-causales",
    "href": "01-introduccion.html#diagramas-causales",
    "title": "1  Introducción",
    "section": "1.1 Diagramas causales",
    "text": "1.1 Diagramas causales\nEn primer lugar, observamos (McElreath (2020)):\n\n\n\n\n\n\nCausas y mecanismos\n\n\n\nLas razones de cómo hacemos análisis estadístico (que procedimiento o algoritmo seleccionamos, por ejemplo) en un problema dado no están en los datos observados, las causas de los datos.\n\n\nLas causas de los datos no pueden extrarse de los datos solamente. Muchas veces nos referimos a las causas de los datos como el proceso generador de los datos: esto incluye aspectos del fenómeno que nos interesa (ciencia o proceso de negocios, etc.), así como el proceso de observación (muestras, valores no observados, etc.).\nConsideremos un ejemplo simple para ilustrar este primer principio:\n\nEjemplo (cálculos renales)\nEste es un estudio real acerca de tratamientos para cálculos renales (Julious y Mullee (1994)). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.\nLa tabla original tiene 700 renglones (cada renglón es un paciente)\n\ncalculos &lt;- read_csv(\"../datos/kidney_stone_data.csv\")\nnames(calculos) &lt;- c(\"tratamiento\", \"tamaño\", \"éxito\")\ncalculos &lt;- calculos |&gt; \n   mutate(tamaño = ifelse(tamaño == \"large\", \"grandes\", \"chicos\")) |&gt; \n   mutate(resultado = ifelse(éxito == 1, \"mejora\", \"sin_mejora\")) |&gt; \n   select(tratamiento, tamaño, resultado)\nnrow(calculos)\n\n[1] 700\n\n\ny se ve como sigue (muestreamos algunos renglones):\n\ncalculos |&gt; \n   sample_n(10) |&gt; kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nresultado\n\n\n\n\nA\ngrandes\nsin_mejora\n\n\nA\nchicos\nsin_mejora\n\n\nB\nchicos\nmejora\n\n\nA\ngrandes\nmejora\n\n\nA\ngrandes\nmejora\n\n\nA\ngrandes\nmejora\n\n\nA\nchicos\nmejora\n\n\nB\nchicos\nmejora\n\n\nB\ngrandes\nmejora\n\n\nA\ngrandes\nmejora\n\n\n\n\n\n\n\nAunque estos datos contienen información de 700 pacientes, los datos pueden resumirse sin pérdida de información contando como sigue:\n\ncalculos_agregada &lt;- calculos |&gt; \n   group_by(tratamiento, tamaño, resultado) |&gt; \n   count()\ncalculos_agregada |&gt; kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nresultado\nn\n\n\n\n\nA\nchicos\nmejora\n81\n\n\nA\nchicos\nsin_mejora\n6\n\n\nA\ngrandes\nmejora\n192\n\n\nA\ngrandes\nsin_mejora\n71\n\n\nB\nchicos\nmejora\n234\n\n\nB\nchicos\nsin_mejora\n36\n\n\nB\ngrandes\nmejora\n55\n\n\nB\ngrandes\nsin_mejora\n25\n\n\n\n\n\n\n\nComo en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:\n\ncalculos_agregada |&gt; pivot_wider(names_from = resultado, values_from = n) |&gt; \n   mutate(total = mejora + sin_mejora) |&gt; \n   mutate(prop_mejora = round(mejora / total, 2)) |&gt; \n   select(tratamiento, tamaño, total, prop_mejora) |&gt; \n   arrange(tamaño) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\ntotal\nprop_mejora\n\n\n\n\nA\nchicos\n87\n0.93\n\n\nB\nchicos\n270\n0.87\n\n\nA\ngrandes\n263\n0.73\n\n\nB\ngrandes\n80\n0.69\n\n\n\n\n\n\n\nEsta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Pero es apropiada para empezar a contestar la pregunta:\n\n¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?\n\nSupongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:\n\ncalculos |&gt; group_by(tratamiento) |&gt; \n   summarise(prop_mejora = mean(resultado == \"mejora\") |&gt; round(2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\nprop_mejora\n\n\n\n\nA\n0.78\n\n\nB\n0.83\n\n\n\n\n\n\n\ny parece ser que el tratamiento \\(B\\) es mejor que el \\(A\\). Esta es una paradoja (un ejemplo de la paradoja de Simpson) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar \\(B\\)? ¿Si sabe debería recetar \\(A\\)? Esta discusión parece no tener mucho sentido.\nPodemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:\n\ncalculos |&gt; group_by(tratamiento, tamaño) |&gt; count() |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nn\n\n\n\n\nA\nchicos\n87\n\n\nA\ngrandes\n263\n\n\nB\nchicos\n270\n\n\nB\ngrandes\n80\n\n\n\n\n\n\n\nNuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos. En este caso, hay una decisión pues A es una cirugía y B es un procedimiento menos invasivo, y se prefiere utilizar el tratamiento \\(A\\) para cálculos grandes, y \\(B\\) para cálculos chicos. Esto quiere decir que en la tabla total el tratamiento \\(A\\) está en desventaja porque se usa en casos más difíciles, pero el tratamiento \\(A\\) parece ser en general mejor. La razón es probablemente un proceso de optimización de recursos y riesgo que hacen los doctores.\n\nEn este caso, una mejor respuesta a la pregunta de qué tratamiento es mejor es la que presenta los datos desagregados.\nLa tabla desagregada de asignación del tratamiento nos informa acerca de cómo se está distribuyendo el tratamiento en los pacientes.\n\n\n\n\n\n\n\nNota\n\n\n\nLos resúmenes descriptivos acompañados de hipótesis causales acerca del proceso generador de datos, nos guía hacia descripciones interpretables de los datos.\n\n\nLas explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos.\nPodemos codificar la información causal con un diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    T \n    M \n    C\n  edge [minlen = 3]\n    T -&gt; M\n    C -&gt; T\n    C -&gt; M\n{ rank = same; M; T }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEs decir, el tamaño de los cálculos es una causa común de tratamiento (T) y resultado (M). Veremos más adelante que la decisión de condicionar a el tipo de cálculos proviene de un análisis relativamente simple de este diagrama causal, independientemente de los métodos que usemos para estimar las proporciones de interés (en este ejemplo, examinar las tablas cruzadas es equivalente a hacer estimaciones de máxima verosimlitud).\n\n\nEjemplo (cálculos renales 2)\nContrastemos el ejemplo anterior usando exactamente la misma tabla de datos, pero con el supuesto de un proceso generador diferente. En este caso, los tratamientos son para mejorar alguna enfermedad del corazón. Sabemos que parte del efecto de este tratamiento ocurre gracias a una baja en presión arterial de los pacientes, así que después de administrar el tratamiento, se toma la presión arterial de los pacientes. Ahora tenemos la tabla agregada y desagregada como sigue:\n\ncorazon &lt;- calculos |&gt; \n  select(tratamiento, presión = tamaño, resultado) |&gt; \n  mutate(presión = ifelse(presión == \"grandes\", \"alta\", \"baja\"))\ncorazon_agregada &lt;- corazon |&gt; \n   group_by(tratamiento, presión, resultado) |&gt; \n   count()\ncorazon_agregada |&gt; pivot_wider(names_from = resultado, values_from = n) |&gt; \n   mutate(total = mejora + sin_mejora) |&gt; \n   mutate(prop_mejora = round(mejora / total, 2)) |&gt; \n   select(tratamiento, presión, total, prop_mejora) |&gt; \n   arrange(presión) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\npresión\ntotal\nprop_mejora\n\n\n\n\nA\nalta\n263\n0.73\n\n\nB\nalta\n80\n0.69\n\n\nA\nbaja\n87\n0.93\n\n\nB\nbaja\n270\n0.87\n\n\n\n\n\n\n\n\ncorazon |&gt; group_by(tratamiento) |&gt; \n   summarise(prop_mejora = mean(resultado == \"mejora\") |&gt; round(2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\nprop_mejora\n\n\n\n\nA\n0.78\n\n\nB\n0.83\n\n\n\n\n\n\n\n¿Cuál creemos que es el mejor tratamiento en este caso? ¿Deberíamos usar la tabla agregada o la desagregada por presión?\n\nEn este caso, la tabla agregada es más apropiada (B es mejor tratamiento).\nLa razón es que presión en este caso es una consecuencia de tomar el tratamiento, y como las tablas muestran, B es más exitoso en bajar la presión de los pacientes.\nSi sólo comparamos dentro de los grupos de presión baja o de presión alta, ignoramos lo más importante del tratamiento en la probabilidad de mejorar.\n\nNuestros supuestos causales podemos mostrarlos con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    P\n    T \n    M \n  edge [minlen = 3]\n    T -&gt; P\n    P -&gt; M\n    T -&gt; M\n{ rank = same; M; T}\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nNótese que el análisis más apropiado no está en los datos: en ambos casos la tabla de datos es exactamente la misma. Los supuestos acerca del proceso que genera los datos sin embargo nos lleva a respuestas opuestas."
  },
  {
    "objectID": "01-introduccion.html#diagramas-causales-1",
    "href": "01-introduccion.html#diagramas-causales-1",
    "title": "1  Introducción",
    "section": "Diagramas causales",
    "text": "Diagramas causales\nLos diagramas de arriba se llaman DAGs (Gráficas dirigidas acíclicas), y no son generadas por datos observados, sino que codifican conocimiento acerca del fenómenos y los datos observados. Nos ayudan a (McElreath (2020)):\n\nPensar claramente en términos científicos/de negocio acerca de nuestro problema\nExpresar los supuestos que hacemos que soportan nuestro análisis\nEntender qué podemos entender o explicar, sin hacer supuestos adicionales acerca de las relaciones particulares entre las variables.\nGuiar el análisis para decidir que modelos o procedimientos usar para contestar preguntas de interés.\n\nLos DAGs se construyen con causas, e implican asociaciones observables, pero no se construyen con asociaciones simplemente. El pensamiento causal es útil siempre que queremos responder preguntas acerca de un fenómeno de interés. En particular nos asisten en :\n\nAnálisis descriptivo\n\nComo vimos en el ejemplo anterior, incluso el análisis descriptivo (qué tabla usar, qué gráfica usar) de datos requiere de un análisis causal.\nMuchas veces los datos que tenemos, por distintas razones, tienen características que requieren procesarlos (por ejemplo ponderarlos) para que nos den respuestas entendibles.\n\n\n\nInferencia causal\n\nEfectos de intervenciones: En algunos casos, queremos saber consecuencias de una intervención sobre un sistema o proceso dados (por ejemplo, ¿cuántos accidentes graves habría si pusiéramos una multa por no usar cinturón de seguridad?). Esto requiere utilizar pensamiento causal.\nContrafactuales: También es usual necesitar pensar cómo serían las cosas si el pasado se hubiera desarrollado de manera distinta (por ejemplo, ¿cómo serían las ventas si no se hubiera gastado en publicidad?) en publicidad ?).\n\n\n\nDiseño de estudios o experimentos\n\nSi queremos recolectar datos acerca de un fenómeno particular (por ejemplo, ¿cómo debo seleccionar una muestra para medir orientación política de una población?), diseños eficientes requieren tener conocimiento de dominio acerca de las causas de las variables que nos interesa medir. Por ejemplo, si queremos tomar una muestra de casillas para estimar el resultado de una votación, deberíamos considerar variables geográficas como distrito electoral, grado de urbanización, etc.\n\n\n\nPredicción\n\nIncluso en problemas de predicción, modelos útiles resultan de pensar en la estructura causal del problema. Ignorar estos aspectos puede llevar fácilmente a evaluación incorrecta del desempeño, filtración de datos, o modelos que no pueden implementarse en la práctica.\n\n\n\nOtro ejemplo (admisiones de Berkeley)\nUna ejemplo al que regresaremos más adelante es el siguiente: en 1973 se recolectaron datos agregados de solicitantes para estudiar en Berkeley para los 6 departamentos más grandes, clasificados por sexo del solicitante y si fue admitido o no. Los resultados se muestran a continuación:\n\ndata(\"UCBAdmissions\")\nadm_original &lt;- UCBAdmissions |&gt; as_tibble() |&gt; \n   pivot_wider(names_from = Admit, values_from = n) \nadm_original |&gt; knitr::kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nGender\nDept\nAdmitted\nRejected\n\n\n\n\nMale\nA\n512\n313\n\n\nFemale\nA\n89\n19\n\n\nMale\nB\n353\n207\n\n\nFemale\nB\n17\n8\n\n\nMale\nC\n120\n205\n\n\nFemale\nC\n202\n391\n\n\nMale\nD\n138\n279\n\n\nFemale\nD\n131\n244\n\n\nMale\nE\n53\n138\n\n\nFemale\nE\n94\n299\n\n\nMale\nF\n22\n351\n\n\nFemale\nF\n24\n317\n\n\n\n\n\n\n\ny las proporciones de admisión por sexo y departamente son las siguientes:\n\nadm_tbl &lt;- adm_original |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected), 2), total = Admitted + Rejected) |&gt; \n   select(Gender, Dept, prop_adm, total) |&gt; \n   pivot_wider(names_from = Gender, values_from = prop_adm:total)\nadm_tbl |&gt; knitr::kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nDept\nprop_adm_Male\nprop_adm_Female\ntotal_Male\ntotal_Female\n\n\n\n\nA\n0.62\n0.82\n825\n108\n\n\nB\n0.63\n0.68\n560\n25\n\n\nC\n0.37\n0.34\n325\n593\n\n\nD\n0.33\n0.35\n417\n375\n\n\nE\n0.28\n0.24\n191\n393\n\n\nF\n0.06\n0.07\n373\n341\n\n\n\n\n\n\n\nComplementamos con las tasas de aceptación a total por género, y tasas de aceptación por departamento:\n\nadm_original |&gt; group_by(Gender) |&gt; \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nGender\nAdmitted\nRejected\nprop_adm\n\n\n\n\nFemale\n557\n1278\n0.30\n\n\nMale\n1198\n1493\n0.45\n\n\n\n\n\n\n\nLa pregunta que queremos hacer es: ¿existe discriminación por sexo en la selección de candidatos? Examinando las tablas no está clara cuál es la respuesta.\n\nadm_original |&gt; group_by(Dept) |&gt; \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nDept\nAdmitted\nRejected\nprop_adm\n\n\n\n\nA\n601\n332\n0.64\n\n\nB\n370\n215\n0.63\n\n\nC\n322\n596\n0.35\n\n\nD\n269\n523\n0.34\n\n\nE\n147\n437\n0.25\n\n\nF\n46\n668\n0.06\n\n\n\n\n\n\n\nDiscutiremos este ejemplo con más detalle más adelante. La interpretación debe ser hecha con cuidado, y debemos establecer claramente los supuestos que fundamentan nuestra decisión de mostrar cada tabla y de qué forma mostrarlas."
  },
  {
    "objectID": "01-introduccion.html#modelos-y-algoritmos",
    "href": "01-introduccion.html#modelos-y-algoritmos",
    "title": "1  Introducción",
    "section": "1.2 Modelos y algoritmos",
    "text": "1.2 Modelos y algoritmos\nEn muchos cursos introductorios de estadística se muestran distintos tipos de procedimientos, que aplican según el tipo de datos (por ejemplo, categóricos o numéricos, pareados, no pareados, etc), generalmente con el propósito de evaluar evidencia en contra de una hipótesis nula. Por ejemplo, de McElreath (2020):\n\n\n\nEjemplo de proceso de decisión para procedimientos estadísticos\n\n\nEste enfoque puede ser confuso en un principio (¿cómo se relacionan todos estos procedimientos?), y también restringir nuestra capacidad para analizar datos: ¿qué hacemos cuando no se cumplen los supuestos de un procedimiento? Adicionalmente si no tenemos mucha experiencia, la manera en que fallan estas herramientas puede ser poco intuitiva y difícil de descubrir.\nY aunque son herramientas poderosas, no sustituyen el pensamiento científico o de proceso de negocios. Estas herramientas no generan hallazgos si no están acompañados de pensamiento causal.\nBuscamos entonces:\n\nDar herramientas (bayesianas) para analizar datos que son más flexibles, y se puedan adaptar a distintas situaciones.\nProponer un proceso para analizar datos, que sea más sistemático, robusto, y maneras de checar que el proceso es correcto o hace lo que pensamos que tiene qué hacer.\nLigar 1 y 2 con supuestos causales claros para proponer una interpretación sólida de nuestros resultados."
  },
  {
    "objectID": "01-introduccion.html#análisis-como-proceso",
    "href": "01-introduccion.html#análisis-como-proceso",
    "title": "1  Introducción",
    "section": "1.3 Análisis como proceso",
    "text": "1.3 Análisis como proceso\nIremos refinando nuestro poco a poco, conforme veamos distintas herramientas y problemas. El más básico es el siguiente (McElreath (2020)):\n\nDefinir un modelo generativo para la muestra de datos.\nDefinir la cantidad que queremos estimar en relación al fenómeno de interés.\nDefinir un proceso estadístico para hacer una estimación.\nProbar el proceso 3 usando 1 y 2.\n(Usar datos) Analizar los datos, resumir resultados.\nChecar cómputos y desempeño del modelo.\n\nEste proceso no es exclusivo de los modelos bayesianos, pero quizá es más natural, como veremos, cuando adoptamos el punto de vista bayesiano. Su propósito es múltiple: verificar que nuestros modelos están estimando las cantidades que realmente nos interesan, según nuestros supuestos, verificar los programas y cómputos con los que se obtienen resultados, y checar la adecuación del modelo a datos reales, cuestionando supuestos teóricos y supuestos de modelación.\nFinalmente, quisiéramos llegar a un proceso como el que se describe en Towards a Principled Bayesian Workflow, e incorporar el que se detalla en Gelman et al. (2020):\n\n\n\nGelman et al, Bayesian Workflow"
  },
  {
    "objectID": "01-introduccion.html#modelación-y-análisis-ingeniería",
    "href": "01-introduccion.html#modelación-y-análisis-ingeniería",
    "title": "1  Introducción",
    "section": "1.4 Modelación y análisis: ingeniería",
    "text": "1.4 Modelación y análisis: ingeniería\nCualquier proceso de análisis de datos se beneficia de muchos aspectos de ingenería de software. Parte de la profesionalización del análisis de datos que observamos en ciencia de datos es utilizar las herramientas reconocidas para resolver problemas de desarrollo y calidad de código, así como su documentación.\n\nAnálisis como software: Una parte de este proceso está relacionado con la reproducibilidad y documentación del trabajo, y su objetivo es evitar errores de programación y de organización (esta parte hablaremos menos: es necesario seguir los estándares de la industria para obtener resultados más confiables).\nOtra parte es el proceso con el cual construimos y contrastamos modelos para contestar preguntas, verificamos los modelos y sus respuestas y checamos resultados de cómputos.\n\n\n\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C. Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, y Martin Modrák. 2020. «Bayesian Workflow». https://arxiv.org/abs/2011.01808.\n\n\nJulious, Steven A, y Mark A Mullee. 1994. «Confounding and Simpson’s paradox». BMJ 309 (6967): 1480-81. https://doi.org/10.1136/bmj.309.6967.1480.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ."
  },
  {
    "objectID": "02-flujo-basico.html#paso-1-modelo-generativo",
    "href": "02-flujo-basico.html#paso-1-modelo-generativo",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.1 Paso 1: Modelo generativo",
    "text": "2.1 Paso 1: Modelo generativo\nConsideremos primero qué variables de interés tenemos: \\(p\\), la proporción de seropositivos en la población, \\(N\\) que es el número de personas a las que les hicimos la prueba, y \\(N_{+}\\) y \\(N_{-}\\) que cuentan el número de positivos y seronegativos en la muestra. Supondremos que la prueba da resultados exactos. Denotaremos por \\(\\theta\\) a la proporción de seropositivos en la muestra.\nComenzamos construyendo el diagrama que indica cómo influye cada variable en otra (nota: no son asociaciones, sino que indican qué variables “escuchan” a otras para determinar su valor). En este caso, \\(N\\) y \\(\\theta\\) son variable que no depende de ninguna otra, mientras que \\(N_{+}\\) y \\(N_{-}\\) dependen de \\(N\\) y \\(\\theta\\). Como \\(\\theta\\) es una cantidad que no observamos directamente, mostramos su nodo como un círculo.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta [label = &lt;&theta;&gt;]\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    theta -&gt; Npos\n    theta -&gt; Nneg\n    N -&gt; Npos\n    N -&gt; Nneg\n    #esp -&gt; Pos\n    #sens -&gt; Pos\n    #esp -&gt; Neg\n    #sens -&gt; Neg\n{ rank = same; theta; N }\n{ rank = same; Npos; Nneg}\n#{ rank = max; sens; esp}\n\n  \n}\n\", width = 300, height = 100)\n\n\n\n\n\n\nQue también podríamos simplificar (suponiendo la \\(N\\) fija y conocida, pues \\(N_+\\) y \\(M\\) dan \\(N_{-}\\)) como:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta [label = &lt;&theta;&gt;]\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    theta -&gt; Npos\n    N -&gt; Npos\n    #esp -&gt; Pos\n    #sens -&gt; Pos\n    #esp -&gt; Neg\n    #sens -&gt; Neg\n{ rank = same; theta; N }\n{ rank = same; Npos}\n#{ rank = max; sens; esp}\n\n  \n}\n\", width = 300, height = 100)\n\n\n\n\n\n\nY ahora construimos el modelo generativo. Supondremos que la muestra de \\(N\\) personas se toma de manera aleatoria de la población (una población grande, así que podemos ignorar el efecto de muestreo). Supondremos provisionalmente, además, que la prueba es perfecta, es decir, no hay falsos positivos o negativos.\nLa siguiente función simula una muestra de \\(N\\) personas, y regresa el número de Positivos y Negativos en la muestra.\n\nsim_pos_neg &lt;- function(theta = 0.01, N = 20, sens = 1, esp = 1) {\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, theta)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra\n  Pos &lt;- Pos_verdadero\n  Neg &lt;- 1 - Pos\n  # Observaciones\n  tibble(Pos = Pos, Neg = Neg)\n}\n\nPodemos hacer algunas pruebas del modelo generativo en casos extremos:\n\nset.seed(8212)\nsim_pos_neg(theta = 1.0, N = 10)\n\n# A tibble: 10 × 2\n     Pos   Neg\n   &lt;int&gt; &lt;dbl&gt;\n 1     1     0\n 2     1     0\n 3     1     0\n 4     1     0\n 5     1     0\n 6     1     0\n 7     1     0\n 8     1     0\n 9     1     0\n10     1     0\n\nsim_pos_neg(theta = 0.0, N = 10)\n\n# A tibble: 10 × 2\n     Pos   Neg\n   &lt;int&gt; &lt;dbl&gt;\n 1     0     1\n 2     0     1\n 3     0     1\n 4     0     1\n 5     0     1\n 6     0     1\n 7     0     1\n 8     0     1\n 9     0     1\n10     0     1\n\nsim_pos_neg(theta = 0.1, N = 1e7) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.1001\n\n\nEn la práctica podemos definir pruebas más exhaustivas si es necesario. En este caso, se trata principalmente de pruebas unitarias que se utilizan comunmente en desarrollo de software.\n\n\n\n\n\n\nPruebas unitarias\n\n\n\nLa práctica estándar de pruebas unitarias consiste en probar unidades relativamente pequeñas de código (por ejemplo funciones) para verificar que funcionan correctamente.\nEsta estrategia debe utilizarse también, en la medida de los posible, en estadística."
  },
  {
    "objectID": "02-flujo-basico.html#paso-2-definir-estimando",
    "href": "02-flujo-basico.html#paso-2-definir-estimando",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.2 Paso 2: Definir estimando",
    "text": "2.2 Paso 2: Definir estimando\nAhora podemos definir en términos de nuestro modelo el valor que queremos estimar. En este caso, coincide con un párametro del modelo \\(\\theta\\), pero no necesariamente es así siempre: como veremos más adelante, puede ser una cantidad que se deriva de otras variables y parámetros del modelo."
  },
  {
    "objectID": "02-flujo-basico.html#paso-3-definir-un-proceso-estadístico",
    "href": "02-flujo-basico.html#paso-3-definir-un-proceso-estadístico",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.3 Paso 3: definir un proceso estadístico",
    "text": "2.3 Paso 3: definir un proceso estadístico\nDada la información limitada que tenemos acerca de la población, esperamos tener cierta incertidumbre en nuestra estimación del valor de \\(\\theta\\). En estadística bayesiana esta incertidumbre la expresamos mediante una distribución de probabilidades sobre posibles valores del \\(\\theta\\). Si denotamos por \\(D\\) a los datos observados, nuestro objetivo es calcular o aproximar\n\\[p(\\theta|D)\\] que es una distribución sobre los posibles valores de \\(\\theta\\), una vez que tenemos información de la muestra, y que pone más masa de probabilidad sobre las conjeturas de \\(\\theta\\) que son más probables o creíbles. A esta distribución le llamamos la distribución posterior de \\(\\theta\\).\nCon esta posterior podemos hacer afirmaciones probabilísticas de la forma:\n\n¿Cuál es la probabilidad de que \\(\\theta\\) sea menor a 1%? (Muy pocos seropositivos)\n¿Cuál es la probabildad de que \\(\\theta\\) sea mayor a 80%? (Población cerca de saturación)\n\nEstas cantidades se calculan, al menos teóricamente, integrando \\(p(\\theta|D)\\) sobre los valores de \\(\\theta\\) que nos interesan, por ejemplo,\n\\[P(\\theta &lt;= 0.01) = \\int_0^{0.01} p(\\theta|D) d\\theta\\] Nota: la integral la interpretamos como suma en el caso discreto.\nSupongamos entonces una \\(\\theta\\) dada, y que observamos la muestra \\(1,0,0,1,0\\). La probabilidad de observar esta muestra es (suponiendo observaciones independientes):\n\\[\\theta(1-\\theta)(1-\\theta)\\theta(1-\\theta) = \\theta^2(1-\\theta)^3\\] Para algunos valores de \\(\\theta\\) (posibles conjeturas acerca del valor de \\(\\theta\\)) podemos escribir una tabla como sigue (Nota: discretizamos por el momento a un número finito de valores de \\(\\theta\\) para hacer el argumento más simple):\n\ntheta &lt;- seq(0, 1, length.out = 11)\ntibble(conjetura_theta = theta, verosimiltud = theta^2 * (1 - theta)^3) |&gt; \n  kbl(col.names = c(\"Conjetura θ\", \"p(D|θ)\"),\n      escape = FALSE) \n\n\n\n\nConjetura θ\np(D|θ)\n\n\n\n\n0.0\n0.00000\n\n\n0.1\n0.00729\n\n\n0.2\n0.02048\n\n\n0.3\n0.03087\n\n\n0.4\n0.03456\n\n\n0.5\n0.03125\n\n\n0.6\n0.02304\n\n\n0.7\n0.01323\n\n\n0.8\n0.00512\n\n\n0.9\n0.00081\n\n\n1.0\n0.00000\n\n\n\n\n\n\n\nEn la tabla vemos que hay algunas conjeturas, o posibles valores de \\(\\theta\\), que tienen probabilidad considerablemente más alta que otra. La notación\n\\[p(D|\\theta)\\] significa: la probabilidad de los datos \\(D\\) dado el valor de \\(\\theta\\). Nótese que esta distribución no es la posterior que describimos arriba, y no es una distribución de probabilidad sobre \\(\\theta\\) (las probabilidades no suman uno). Esta función se llama usualmente verosimilitud de los datos, e incorpora supuestos concretos del proceso generador de los datos.\nUsando reglas de probabilidad (en particular la regla de Bayes), observamos que\n\\[p(\\theta | D) = \\frac{p(D|\\theta)p(\\theta)} { p(D)}.\\] Como \\(p(\\theta|D)\\) debe dar una distribución de probabilidad (suma o integra a 1), entonces \\(p(D)\\) debe ser una constante de normalización para el numerador de la derecha, es decir, basta escribir\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta) \\] Ahora es donde encontramos que tenemos que tener \\(p(\\theta)\\) para poder calcular la cantidad que nos interesa, que es la distribución posterior \\(p(\\theta|D)\\). \\(p(\\theta)\\), la distribución a priori o distribución inicial es simplemente una afirmación de dónde puede estar \\(\\theta\\), antes de observar ningún dato.\nPor el momento, podríamos poner \\(p(\\theta)\\) constante, de manera que es parte de la constante de normalización, y sólo tendríamos que normalizar como sigue:\n\ntheta &lt;- seq(0, 1, length.out = 11)\nprob_post &lt;- tibble(conjetura = theta, probablidad = theta^2 * (1 - theta)^3) |&gt; \n  mutate(prob_posterior = probablidad / sum(probablidad)) \nprob_post |&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(D|θ)\",\"p(θ|D)\")) |&gt;\n  kable_paper()\n\n\n\n\nConjetura θ\np(D|θ)\np(θ|D)\n\n\n\n\n0.0\n0.00000\n0.0000000\n\n\n0.1\n0.00729\n0.0437444\n\n\n0.2\n0.02048\n0.1228923\n\n\n0.3\n0.03087\n0.1852385\n\n\n0.4\n0.03456\n0.2073807\n\n\n0.5\n0.03125\n0.1875188\n\n\n0.6\n0.02304\n0.1382538\n\n\n0.7\n0.01323\n0.0793879\n\n\n0.8\n0.00512\n0.0307231\n\n\n0.9\n0.00081\n0.0048605\n\n\n1.0\n0.00000\n0.0000000\n\n\n\n\n\n\n\nCon esto, expresamos nuestro conocimiento acerca de \\(\\theta\\), después de observar los datos, con una distribución posterior de probabilidad sobre las posibles conjecturas. Este es el resultado principal de inferencia bayesiana, y es la base para tomar decisiones relativas a \\(\\theta\\).\n\nUsando información adicional\nSupongamos que tenemos información adicional acerca de \\(\\theta\\), por ejemplo, que en un experimento similar anterior alguien tomó una muestra de dos personas, y encontraron dos negativos. Tenemos entonces como creencias inciales:\n\ntheta &lt;- seq(0, 1, length.out = 11)\nprob_priori &lt;- tibble(conjetura = theta) |&gt; \n  mutate(prob_priori = (1 - theta) * (1 - theta)) |&gt; \n  mutate(prob_priori = prob_priori / sum(prob_priori)) \nprob_priori |&gt;\n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\")) |&gt; kable_paper()\n\n\n\n\nConjetura θ\np(θ)\n\n\n\n\n0.0\n0.2597403\n\n\n0.1\n0.2103896\n\n\n0.2\n0.1662338\n\n\n0.3\n0.1272727\n\n\n0.4\n0.0935065\n\n\n0.5\n0.0649351\n\n\n0.6\n0.0415584\n\n\n0.7\n0.0233766\n\n\n0.8\n0.0103896\n\n\n0.9\n0.0025974\n\n\n1.0\n0.0000000\n\n\n\n\n\n\n\nPor ejemplo, al probabilidad inicial de que \\(\\theta\\) sea muy grande es cercana a cero, pues observamos dos negativos y ningún positivo. Ahora regresamos a considerar nuestra fórmula\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta), \\]\nEn este caso, la apriori o inicial tiene un efecto sobre la posterior. Reconsideramos entonces la posterior de nuestra muestra de 5 personas, y calculamos el producto de \\(P(D|\\theta)\\) por \\(p(\\theta)\\):\n\nprob_post &lt;- prob_priori |&gt; \n  mutate(verosimilitud = theta^2 * (1 - theta)^3) |&gt; \n  mutate(prod = verosimilitud * prob_priori)\n\nprob_post|&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\", \"p(D|θ)\",\n                      \"p(D|θ)p(θ)\")) |&gt; kable_paper()\n\n\n\n\nConjetura θ\np(θ)\np(D|θ)\np(D|θ)p(θ)\n\n\n\n\n0.0\n0.2597403\n0.00000\n0.0000000\n\n\n0.1\n0.2103896\n0.00729\n0.0015337\n\n\n0.2\n0.1662338\n0.02048\n0.0034045\n\n\n0.3\n0.1272727\n0.03087\n0.0039289\n\n\n0.4\n0.0935065\n0.03456\n0.0032316\n\n\n0.5\n0.0649351\n0.03125\n0.0020292\n\n\n0.6\n0.0415584\n0.02304\n0.0009575\n\n\n0.7\n0.0233766\n0.01323\n0.0003093\n\n\n0.8\n0.0103896\n0.00512\n0.0000532\n\n\n0.9\n0.0025974\n0.00081\n0.0000021\n\n\n1.0\n0.0000000\n0.00000\n0.0000000\n\n\n\n\n\n\n\nY finalmente, normalizamos para encontrar la probabilidad posterior:\n\nprob_post &lt;- prob_post |&gt; \n  mutate(prob_posterior = prod / sum(prod))\n\nprob_post|&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\", \"p(D|θ)\",\n    \"p(D|θ)p(θ)\", \"p(θ|D)\"), escape = FALSE) |&gt; kable_paper()\n\n\n\n\nConjetura θ\np(θ)\np(D|θ)\np(D|θ)p(θ)\np(θ|D)\n\n\n\n\n0.0\n0.2597403\n0.00000\n0.0000000\n0.0000000\n\n\n0.1\n0.2103896\n0.00729\n0.0015337\n0.0992712\n\n\n0.2\n0.1662338\n0.02048\n0.0034045\n0.2203539\n\n\n0.3\n0.1272727\n0.03087\n0.0039289\n0.2542983\n\n\n0.4\n0.0935065\n0.03456\n0.0032316\n0.2091640\n\n\n0.5\n0.0649351\n0.03125\n0.0020292\n0.1313412\n\n\n0.6\n0.0415584\n0.02304\n0.0009575\n0.0619745\n\n\n0.7\n0.0233766\n0.01323\n0.0003093\n0.0200177\n\n\n0.8\n0.0103896\n0.00512\n0.0000532\n0.0034430\n\n\n0.9\n0.0025974\n0.00081\n0.0000021\n0.0001362\n\n\n1.0\n0.0000000\n0.00000\n0.0000000\n0.0000000\n\n\n\n\n\n\n\nLa última columna nos da el resultado final de la inferencia bayesiana. Podemos resumir algunas de sus características, por ejemplo:\n\nEs muy poco probable que la seropositividad sea mayor o igual a 0.7\nUn intervalo de 90% de probabilidad para la seropositividad es \\([0.1, 0.5]\\)\n\nLa gráfica de la posterior es:\n\nprob_post |&gt;\n  ggplot(aes(x = conjetura, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") \n\n\n\n\nAhora podemos definir, para nuestro ejemplo discretizado, la función que calcula la posterior dados los pasos 1 y 2:\n\ncalcular_posterior &lt;- function(muestra, prob_priori){\n  # distribución inicial o a prior\n  theta &lt;- seq(0, 1, length.out = 11)\n  priori &lt;- tibble(theta = theta, prob_priori = (1 - theta) * (1 - theta)) |&gt; \n    mutate(prob_priori = prob_priori / sum(prob_priori))\n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post &lt;- tibble(theta = theta) |&gt; \n      left_join(priori, by = \"theta\") |&gt; \n      mutate(prob_posterior = theta ^ Npos * (1 - theta)^(N - Npos) * prob_priori) |&gt; \n    mutate(prob_posterior = prob_posterior / sum(prob_posterior)) \n  prob_post |&gt; select(theta, prob_posterior)\n}\n\n\nmuestra &lt;- c(1,0,0,1,0)\n\n\ncalcular_posterior(muestra, prob_priori) \n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0         0       \n 2   0.1       0.0993  \n 3   0.2       0.220   \n 4   0.3       0.254   \n 5   0.4       0.209   \n 6   0.5       0.131   \n 7   0.6       0.0620  \n 8   0.7       0.0200  \n 9   0.8       0.00344 \n10   0.9       0.000136\n11   1         0       \n\n\nProcedemos ahora a hacer algunas pruebas simples de nuestra función:\n\ncalcular_posterior(rep(0, 50)) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0.996\n 2   0.1          0.004\n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0    \n 6   0.5          0    \n 7   0.6          0    \n 8   0.7          0    \n 9   0.8          0    \n10   0.9          0    \n11   1            0    \n\ncalcular_posterior(rep(1, 50)) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0    \n 2   0.1          0    \n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0    \n 6   0.5          0    \n 7   0.6          0    \n 8   0.7          0    \n 9   0.8          0.011\n10   0.9          0.989\n11   1            0    \n\ncalcular_posterior(c(rep(0, 100), rep(1, 100))) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0    \n 2   0.1          0    \n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0.023\n 6   0.5          0.966\n 7   0.6          0.01 \n 8   0.7          0    \n 9   0.8          0    \n10   0.9          0    \n11   1            0    \n\n\n\n\nMás verificaciones a priori\nOtra verificación útil que podemos hacer es, una vez que hemos definido nuestro modelo generativo y un modelos estadístico asociado, generar bajo simulación datos que podríamos observar. Esto tiene como fin verificar que nuestro modelo generativo y nuestro modelo estadístico producen datos que están de acuerdo con el conocimiento experto (teoría científica o conocimiento de negocio).\nAsí que simulamos datos del modelo:\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\n\nPodemos ver por ejemplo dónde esperamos ver el número de positivos a lo largo de distintas muestras, cuando \\(N=30\\):\n\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos)) |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n`summarise()` has grouped output by 'rep'. You can override using the `.groups`\nargument.\n\n\n\n\n\nObservamos que con nuestros supuestos, hay una probabilidad alta de observar 0 positivos (alrededor de 0.30). Esto se debe en parte a la discretización que hicimos, y que nuestra apriori pone peso considerable en prevalencia igual a cero, lo que quizá no es muy realista, y probablemente deberíamos escoger al menos una discretización más fina.\nTambién, si consideramos los supuestos como correctos, esto puede indicar el riesgo de usar una muestra chica para estimar prevalencia si esta es muy baja: es probable que obtengamos 0 observaciones positivas.\n\n\n\n\n\n\nVerificación predictiva a priori\n\n\n\nCon este tipo de verificaciones podemos detectar las consecuencias de nuestros supuestos (incluyendo la elección de distribuciones a prior), así como otras decisiones de modelado (como la discretización).\nConflictos con el conocimiento del área deben ser explorados para entenderlos y si es necesario corregir nuestros supuestos.\n\n\nEste tipo de verificaciones es muy flexible, y debe adaptarse a los aspectos del conocimiento del área que son importantes para los expertos. Podemos usar todos nuestros recursos analíticos (tablas, resúmenes, gráficas) para producir estos chequeos."
  },
  {
    "objectID": "02-flujo-basico.html#paso-4-probar-el-proceso-de-estimación",
    "href": "02-flujo-basico.html#paso-4-probar-el-proceso-de-estimación",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.4 Paso 4: Probar el proceso de estimación",
    "text": "2.4 Paso 4: Probar el proceso de estimación\nAntes de utilizar datos, verificamos cómo se comporta nuestro proceso de estimación de acuerdo a los supuestos de nuestro modelo generativo.\n\n\n\n\n\n\nVerificación a priori\n\n\n\nLo mínimo que esperamos de nuestro método es que, bajo nuestros propios supuestos acerca del proceso generador de datos y nuestro procedimiento de estimación definido, nuestra función de estimación no tenga problemas numéricos o de programación, y que las estimaciones que arroja son apropiadas para la cantidad que nos interesa estimar. El procedimiento a grandes rasgos es:\n\nEstablecer valores de los parámetros a estimar\nSimular datos observados (con una \\(N\\) apropiada, dependiendo del tamaño de muestra que esperamos, aunque se puede explorar hacer más grande o más chico este valor).\nCalcular posterior de las cantidades de interés\nCompara los valores de 1) con la posterior de 3)\n\n\n\nDefinir que las posteriores son apropiadas para la cantidad que nos interesa estimar es delicado, y más adelante veremos algunos criterios para evaluar este aspecto. Por lo pronto, haremos algunas pruebas simples que pueden diagnosticar errores graves:\n\ntheta &lt;- 0.2\nN &lt;- 30\n# simular\nset.seed(9914)\ndatos_sim &lt;- sim_pos_neg(theta = theta, N = N)\nposterior &lt;- calcular_posterior(datos_sim$Pos)\nggplot(posterior, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(xintercept = theta, color = \"red\", linetype = \"dashed\")\n\n\n\n\nEn este caso, la estimación parece correcta. Podemo repetir el proceso con distintos valores de \\(\\theta\\):\n\nset.seed(21)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      posterior &lt;- calcular_posterior(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\nY vemos que en general nuestro método parece funcionar correctamente.\n\n\n\n\n\n\nObservaciones\n\n\n\n\nMás adelante veremos cómo comparar valores a estimar con la posterior a través de varias simulaciones de manera más rigurosa. Por el momento, recuerda que incluso pruebas simples o limitadas son mejores que ninguna prueba.\nTípicamente los valores iniciales se toman de la distribución a priori, como hicimos arriba. Esta prueba es en general más apropiada, pues no nos interesan configuración de parámetros con probabilidad inicial extremadamente baja (imposibles según nuestros supuestos), pero también es posible tomar algunos valores fijos de interés.\nVeremos más de chequeos o pruebas predictivas a priori, que en general también sirven para entender la adecuación del modelo y supuestos en términos de teoría y\n\n\n\nEste paso también es importante para entender si, bajo nuestros propios supuestos, es factible obtener información útil bajo el diseño que propongamos. Por ejemplo, alguien podría proponer un diseño de muestra que sólo tome 5 personas. Podemos probar cómo se comportan nuestras estimaciones:\n\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 3)\n      posterior &lt;- calcular_posterior(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\nNuestra respuesta en este caso es que quizá con 3 personas la información obtenida no será suficiente para tomar decisiones útiles: nótese que la posterior está muy poco concentrada alrededor del verdadero valor de \\(\\theta\\).\n\n2.4.1 Introduciendo un bug\nSupongamos que tenemos un error en el cálculo de la posterior:\n\ncalcular_posterior_bug &lt;- function(muestra, prob_priori){\n  # distribución inicial o a prior\n  theta &lt;- seq(0, 1, length.out = 11)\n  priori &lt;- tibble(theta = theta, prob_priori = (1 - theta) * (1 - theta)) |&gt; \n    mutate(prob_priori = prob_priori / sum(prob_priori))\n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post &lt;- tibble(theta = theta) |&gt; \n      left_join(priori, by = \"theta\") |&gt; \n    # la siguiente línea tiene un error!\n      mutate(prob_posterior = theta ^ Npos * (1 - theta)^((N - Npos * prob_priori))) |&gt; \n    mutate(prob_posterior = prob_posterior / sum(prob_posterior)) \n  prob_post |&gt; select(theta, prob_posterior)\n}\n\nNuestro chequeo apriori se ve entonces:\n\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      posterior &lt;- calcular_posterior_bug(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\nDonde vemos en varios casos que la “posterior” está lejos de ser consistente con los valores simulados de prueba para \\(\\theta\\).\n\n\n\n\n\n\nAspectos numéricos\n\n\n\nEs importante notar que los cálculos que hicimos arriba ingoran un principio importante al hacer cálculos de productos de probabilidades: generalmente es mejor utilizar la escala logarítmica para hacer los cálculos, y sólo al final convertir a probabilidades. Esto es porque es fácil tener subflujos numéricos al multiplicar muchas probabilidades pequeñas.\n\n\nAunque en este caso no es crítico, la siguiente función sigue esta práctica que en general es necesario seguir:\n\n# Evitar desbordes al sumar exponenciales\nlog_sum_exp &lt;- function(x){\n  max_x &lt;- max(x)\n  max_x + log(sum(exp(x - max_x)))\n}\ncalcular_posterior &lt;- function(muestra, prob_priori){\n  # evitar 0 o 1 exactos\n  theta &lt;- seq(1e-12, 1 - 1e-12, length.out = 11)\n  # no es necesario normalizar esta distribución apriori\n  log_priori &lt;- tibble(theta = theta, log_prob_priori = 2 * log(1 - theta)) \n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post_tbl &lt;- tibble(theta = theta) |&gt; \n    left_join(log_priori, by = \"theta\") |&gt; \n    # log verosimilitud\n    mutate(log_prob_posterior = \n        Npos * log(theta) + log(1 - theta) * (N - Npos)) |&gt; \n    # sumar log apriori\n    mutate(log_prob_posterior = log_prob_posterior + log_prob_priori) |&gt; \n    mutate(log_prob_posterior_norm = \n      log_prob_posterior - log_sum_exp(log_prob_posterior)) |&gt; \n    mutate(prob_posterior = exp(log_prob_posterior_norm))\n  prob_post_tbl |&gt; select(theta, prob_posterior)\n}\n\nEjercicio: corre las pruebas para esta versión de la función como hicimos arriba. Este es un cambio correcto, y desde el punto de vista de desarrollo, si nuestra batería de pruebas es apropiado podemos hacerlo con más confianza."
  },
  {
    "objectID": "02-flujo-basico.html#paso-5-analizar-los-datos-y-resumir-resultados.",
    "href": "02-flujo-basico.html#paso-5-analizar-los-datos-y-resumir-resultados.",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.5 Paso 5: Analizar los datos y resumir resultados.",
    "text": "2.5 Paso 5: Analizar los datos y resumir resultados.\nCon este trabajo hecho (ojo: para modelos grandes es un trabajo considerable, pero importante), podemos proceder a analizar los datos.\nSupongamos que se tomó una muestra de \\(N=20\\) personas, con 17 negativos y 3 positivos. Calculamos la posterior:\n\n# en nuestro modelo *no* importa el orden, verifica:\ndatos_tbl &lt;- tibble(Pos = c(rep(1, 3), rep(0, 17)))\nposterior &lt;- calcular_posterior(muestra = datos_tbl$Pos)\nggplot(posterior, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") \n\n\n\n\nY hay varias maneras de resumir esta posterior. Por ejemplo, podemos calcular (ojo: veremos más detalles de esto más adelante):\n\n# Media\nposterior |&gt; \n  mutate(theta = theta) |&gt; \n  summarise(media = sum(theta * prob_posterior))\n\n# A tibble: 1 × 1\n  media\n  &lt;dbl&gt;\n1 0.166\n\n# Intervalo de alta probabilidad 90%\nposterior |&gt; \n  mutate(theta = theta) |&gt; \n  arrange(desc(prob_posterior)) |&gt; \n  mutate(cumsum = cumsum(prob_posterior)) |&gt; \n  filter(cumsum &lt;= 0.9) |&gt; \n  pull(theta) |&gt; \n  range()\n\n[1] 0.1 0.2"
  },
  {
    "objectID": "02-flujo-basico.html#paso-6-evaluar-el-modelo-y-cómputos",
    "href": "02-flujo-basico.html#paso-6-evaluar-el-modelo-y-cómputos",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.6 Paso 6: Evaluar el modelo y cómputos",
    "text": "2.6 Paso 6: Evaluar el modelo y cómputos\nEn este ejemplo, el modelo es muy simple, y los cómputos son sencillos. Para modelos más complejos es necesario checar que los cómputos sean correctos, y que el modelo ajusta razonablemente bien a los datos en los aspectos que nos interesan, de modo que dejaremos esta discusión cuando veamos el flujo bayesiano más avanzado."
  },
  {
    "objectID": "02-flujo-basico.html#versión-continua",
    "href": "02-flujo-basico.html#versión-continua",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.7 Versión continua",
    "text": "2.7 Versión continua\nEn el ejemplo anterior utilizamos una variable aleatoria discreta para modelar la seroprevalencia, pero esto generalmente no es conveniente. Ahora repetimos el ejercicio considerando más naturalmente que \\(\\theta\\) puede tomar cualquier valor en \\([0,1]\\).\nPara el paso 1 y 2 (definir modelo generativo y cantidad a estimar), utilizamos el mismo diagrama de arriba y la misma función que simula datos. Igual que antes, para cualquier muestra \\(D\\) compuesta de 0 y 1’s (negativos y positivos), la probabilidad de observar la muestra \\(D\\) dada una conjetura \\(\\theta\\) es:\n\\[ p(D|\\theta) = \\theta^{N_+}(1-\\theta)^{N_-}\\] Y recordamos que desde el punto de vista bayesiano, queremos resumir nuestra información obtenida con la distribución posterior \\(p(\\theta|D)\\), e igual que antes tenemos que:\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta).\\] Por el momento pondremos la densidad continua uniforme \\(p(\\theta) = 1\\) para \\(\\theta\\in [0,1]\\) (densidad uniforme), entonces\n\\[p(\\theta|D) \\propto \\theta^{N_+}(1-\\theta)^{N_-}\\]\nEn este caso, para normalizar tenemos que hacer la integral de la expresión de la derecha, y dividir por el resultado. En general, escribiremos\n\\[B(a,b) = \\int_{0}^1 \\theta^{a-1}(1-\\theta)^{b-1} d\\theta\\] así que en nuestro caso, la posterior es:\n\\[p(\\theta|D) = \\frac{1}{B(N_+ + 1,N_{-}+1)} \\theta^{N_+}(1-\\theta)^{N_-}\\] Es posible demostrar con cálculo que \\(B(a,b) = \\frac{(a-1)!(b-1)!}{(a+b-1)!}\\), pero eso no es importante. Este tipo de densidades pertenecen a la familia beta con parámetros \\((a,b)\\), donde \\(a&gt;0, b&gt;0\\).\nPor ejemplo, si observamos 2 positivos y tres negativos, nuestra posterior es una beta con parámetros \\((3,4)\\), y se ve así:\n\nlibrary(tidyverse)\ntheta &lt;- seq(0,1, 0.01)\ntibble(theta = theta, densidad = dbeta(theta, 3, 4)) |&gt; \n  ggplot(aes(x = theta, y = densidad)) +\n  geom_line() +\n  labs(x = \"theta\", y = \"Densidad posterior\") \n\n\n\n\nNotamos adicionalmente que es posible seleccionar otra distribución inicial que no sea la uniforme. En este caso particular es conveniente (aunque no siempre tiene sentido) usar una distribución beta, de manera que es fácil ver que si ponemos por ejemplo\n\\[p(\\theta) \\propto \\theta^{a}(1-\\theta)^{b}\\]\nentonces la posterior, por la fórmula de Bayes, es:\n\\[p(\\theta|D) \\propto \\theta^{N_+ +a }(1-\\theta)^{N_{-}+b}\\] que también es de la familia beta, pero con parámetros \\((N_+ +a+1, N_- +b+1)\\).\n\n2.7.1 Ejercicio: actualizaciones de posterior\nPodemos examinar la posterior para dados distintos datos. Supondremos que la distribución a priori es uniforme.\n\nset.seed(92192)\ntheta_seq &lt;- seq(0,1, 0.001)\ndatos_sim &lt;- sim_pos_neg(theta = 0.25, N = 12) |&gt; \n  mutate(obs = ifelse(Pos==1, \"P\", \"N\")) |&gt; \n  mutate(n = 1:12)\n# graficar posteriores para cada n\ndatos_graf &lt;- datos_sim |&gt; \n  mutate(n_pos = cumsum(Pos), n_neg = cumsum(Neg)) |&gt; \n  mutate(muestra = accumulate(obs, ~ paste0(.x, .y))) |&gt; \n  group_by(n) |&gt;\n  mutate(dens_graf = \n    list(tibble(theta = theta_seq, densidad = dbeta(theta_seq, 1 + n_pos, 1 + n_neg)))) |&gt; \n  unnest(dens_graf)\nggplot(datos_graf, aes(x=theta, y = densidad, group = n)) +\n  geom_line() + \n  facet_wrap(~ muestra) +\n  geom_abline(slope = 0, intercept = 1, color = \"gray\") \n\n\n\n\nAhora repetimos con una inicial beta \\((0,2)\\) (que equivale a observar dos negativos y ningún positivo en una muestra de 3 personas), de modo que \\(p(\\theta) = 2(1-\\theta)\\):\n\nset.seed(92192)\ntheta_seq &lt;- seq(0,1, 0.001)\ndatos_sim &lt;- sim_pos_neg(theta = 0.25, N = 12) |&gt; \n  mutate(obs = ifelse(Pos==1, \"P\", \"N\")) |&gt; \n  mutate(n = 1:12)\n# graficar posteriores para cada n\ndatos_graf &lt;- datos_sim |&gt; \n  mutate(n_pos = cumsum(Pos), n_neg = cumsum(Neg)) |&gt; \n  mutate(muestra = accumulate(obs, ~ paste0(.x, .y))) |&gt; \n  group_by(n) |&gt;\n  mutate(dens_graf = \n    list(tibble(theta = theta_seq, \n                densidad = dbeta(theta_seq, 1 + n_pos + 0, 1 + n_neg + 2)))) |&gt; \n  unnest(dens_graf)\nggplot(datos_graf, aes(x=theta, y = densidad, group = n)) +\n  geom_line() + \n  facet_wrap(~ muestra) +\n  geom_abline(slope = -2, intercept = 2, color = \"gray\") \n\n\n\n\n\nEn este punto, podríamos ir al siguiente paso, que es escribir una función para calcular la posterior. En realidad ya sabemos su función de densidad, pero cualquier resumen que hagamos de esta distribución requerirá de integrales (¿por qué? piensa en cómo calcular la probabilidad de ser menor que un valor, o cómo se calcula la media).\nAunque en este ejemplo simple la posterior tiene una forma conocida y hay manera de calcular (analíticamente o con rutinas numéricas ya implementadas) esos resúmenes de interés (media, cuantiles, etc.), en general calcular integrales no es una estrategia que podamos llevar muy lejos.\n\n\nMás de verificaciones apriori\nAntes de continuar, sin embargo, veremos cómo se veo el chequeo predictivo a priori que consideramos en la sección de arriba.\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # apriori seleccionada\n      theta_sim &lt;- rbeta(1, 1, 3)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\n\nPodemos ver por ejemplo dónde esperamos ver el número de positivos a lo largo de distintas muestras, cuando \\(N=30\\):\n\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos)) |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n`summarise()` has grouped output by 'rep'. You can override using the `.groups`\nargument.\n\n\n\n\n\nEste resultado es consecuencia de nuestros supuestos, antes de ver los datos, y resume que esperamos con mayor probabilidad un número bajo de positivos (en una muestra de N=30), y que es muy poco probable que observemos prevalencias muy altas. Dependiendo de la situación, este puede ser un resultado aceptable.\nUn resultado no aceptable para una enfermedad que sabemos que es relativamente rara (aunque tenemos incertidumbre), por ejemplo, podría ser el siguiente:\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # apriori seleccionada\n      theta_sim &lt;- rbeta(1, 30, 3)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos)) |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n`summarise()` has grouped output by 'rep'. You can override using the `.groups`\nargument.\n\n\n\n\n\nEste resultado no es aceptable cuando sabemos que es prácticamente imposible que la mayoría de la población está infectada. Debemos entonces regresar y ajustar nuestros supuestos: el problema en este caso es la elección de la distribución a priori para \\(\\theta\\).\nObservación: la crítica es sobre el conjunto completo de supuestos iniciales que hacemos acerca del problema. Cuando los diagnósticos no son aceptables desde el punto de vista teórico es necesario investigar dónde está el problema. Las distribuciones apriori que usamos, igual que cualquier supuesto, están sujetas a esta crítica. Nótese que esta crítica la estamos haciendo sin ver los datos que esperamos observar: es una crítica de supuestos.\n\n\n2.7.2 Métodos Monte Carlo\nUna vez que tenemos la densidad posterior podemos mostrarla o resumirla de varias maneras. Si tenemos una expresión analítica, esos resúmen típicamente consisten de integrales, por ejemplo:\n\nLa media o mediana posterior\nDeciles o u otro tipo de percentiles de la posterior\nIntervalos de probabilidad posterior\n\nEste proceso puede ser no trivial incluso para densidades posteriores conocidas. La alternativa a integrar es simular de la posterior y calcular las cantidades de interés a partir de las simulaciones. En general, esto es más fácil que integrar. En nuestro ejemplo, en lugar de usar una función de calcular_posterior, construimos una que es simular_posterior.\nEsta función será simple porque simular de una beta es un problema estándar, y existen muchas implementaciones. Podríamos escribir, por ejemplo:\n\nsimular_posterior &lt;- function(muestra, n){\n  tibble(theta = \n    rbeta(n, sum(muestra) + 1, length(muestra) - sum(muestra) + 1))\n}\n\n\nmuestra\n\n[1] 1 0 0 1 0\n\nsims_post &lt;- simular_posterior(muestra, 10000)\n\n\nsims_post |&gt; \n  ggplot(aes(x = theta)) +\n  geom_histogram(bins = 50)\n\n\n\n\nSi queremos calcular la media, por ejemplo, hacemos\n\n sims_post |&gt; pull(theta) |&gt;  mean()\n\n[1] 0.4280916\n\n\nSi queremos la probabilidad de que la prevalencia esté por debajo de 20% hacemos:\n\nsims_post |&gt; \n  summarise(prob = mean(theta &lt; 0.2))\n\n# A tibble: 1 × 1\n    prob\n   &lt;dbl&gt;\n1 0.0961\n\n\nMuchas veces se presentan intervalos de probabilidad posterior, por ejemplo, podríamos reportar que con 90% de probabilidad la prevalencia está en el siguiente intervalo:\n\nsims_post |&gt; \n  summarise(inf = quantile(theta, 0.05),\n            sup = quantile(theta, 0.95)) |&gt; \n  mutate(inf = round(inf, 2),\n         sup = round(sup, 2))\n\n# A tibble: 1 × 2\n    inf   sup\n  &lt;dbl&gt; &lt;dbl&gt;\n1  0.16  0.73\n\n\nObservación: No hay un intervalo mágico que debe reportarse (por ejemplo 95% de probabilida es una costumbre o superstición). Hay varias maneras de construir intervalos de probabilidad. Dejaremos esta discusión para más adelante.\n\n\n\n\n\n\nMétodos Monte Carlo\n\n\n\nLos métodos Monte Carlo están basados en simulación de variables aleatorias. Las cantidades que nos interesan son integrales bajo una densidad de probabilidad. Si queremos calcular en general \\[I = \\int f(x)p(x)dx,\\] simulamos una gran cantidad de observaciones \\(x_1,\\ldots, x_M\\) bajo \\(p(x)\\), y entonces (Ley de los grandes números):\n\\[\\frac{1}{M} \\sum_{i=1}^{M} x_i \\to I\\] cuando \\(M\\to \\infty\\). De este modo, podemos aproximar con la precisión que requiramos la integral \\(I\\).\n\n\nNota 1: Sin más información del proceso de simulación, no es posible demostrar que una aproximación es “suficientemente” buena, no importa que tan grande sea \\(M\\). Más adelante veremos una batería de diagnósticos para al menos excluir los casos comunes en los que la aproximación es mala.\nNota 2: En nuestro caso, las integrales de interés usualmente son de la forma \\[I = \\int f(\\theta)p(\\theta|D) d\\theta,\\] donde \\(D\\) es la información de la muestra, \\(\\theta\\) es un vector de parámetros del modelo, y \\(f(\\theta)\\) es una función de \\(\\theta\\) que nos interesa. Por ejemplo, para la media posterior de \\(\\theta_i\\), usaríamos \\(f(\\theta) = \\theta_i\\). Podemos aproximar cualquier integral si tenemos simulaciones de la posterior:\n\\[\\theta_i \\sim p(\\theta|D) \\implies \\frac{1}{M} \\sum_{i=1}^{M} f(\\theta_i) \\to I.\\]\n\nFinalmente, checamos todo nuestra construcción de estimación como hicimos arriba, la diferencia es que ahora usamos simulaciones para entender el comportamiento de la posterior. En este caso, el proceso es como sigue:\n\nGeneramos un valor de la apriori \\(\\theta_{sim} \\sim \\text{Beta}(1,3)\\)\nSimulamos datos de la muestra (\\(N=25\\)) con el valor simulado de \\(\\theta\\)\nSimulamos 10000 valores de la posterior\nRepetimos 1-3\n\n\nset.seed(812)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 25)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior(datos_sim$Pos, 10000)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\n\nAhora usamos histogramas por ejemplo para mostrar cómo luce la posterior, y comparamos con los valores de la simulación:\n\nggplot(simulacion_rep, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)"
  },
  {
    "objectID": "02-flujo-basico.html#observaciones-1",
    "href": "02-flujo-basico.html#observaciones-1",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.8 Observaciones",
    "text": "2.8 Observaciones\nEl proceso de arriba lo refinaremos considerablemente en el resto del curso.\n\nEn primer lugar, los modelos generativos serán más complicados, y estarán basados en teoría más compleja (que expresamos con diagramas causales)\nUsaremos más herramientas y componentes para construir modelos estadísticos apropiados, ya sea que construyamos un modelo completo para todo el proceso de generación de datos, o que usemos modelos estándar como regresión para aproximar respuestas, cuando es apropiado\nRefinaremos el proceso de checar que el cómputo (checar Monte Carlo) y la inferencia (verificación apriori) es correcta bajo nuestros supuestos.\nFinalmente, veremos qué hacer después de hacer la estimación y que los puntos de arriba están resueltos, para tener confianza en nuestras conclusiones."
  },
  {
    "objectID": "02-flujo-basico.html#ventajas-y-desventajas-de-métodos-bayesianos",
    "href": "02-flujo-basico.html#ventajas-y-desventajas-de-métodos-bayesianos",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.9 Ventajas y desventajas de métodos bayesianos",
    "text": "2.9 Ventajas y desventajas de métodos bayesianos"
  },
  {
    "objectID": "02-flujo-basico-2.html#prevalencia-con-error-conocido",
    "href": "02-flujo-basico-2.html#prevalencia-con-error-conocido",
    "title": "3  Flujo de trabajo básico: refinando el modelo",
    "section": "3.1 Prevalencia con error conocido",
    "text": "3.1 Prevalencia con error conocido\nNuestro ejemplo de la sección es poco realista. Usualmente, las pruebas que son utilizadas para medir la prevalencia no son perfectas. Bajo condiciones muy controladas, el perfil de desempeño de las pruebas se miden, y los resultados son del siguiente tipo:\n\nEn pruebas de gold standard, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas.\nSin considerar la incertidumbre, esto implica que la prueba tiene una sensibilidad de 84% y una especificidad de 99.5%.\n\n\n3.1.1 Paso 1: modelo generativo\nPrimero supondremos que estos porcentajes de error son fijos. Nuestro modelo que incluye el error de medición se como sigue:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    p\n    Npos\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    Nobs [label = &lt;N&lt;SUB&gt;obs&lt;/SUB&gt;&gt;]\n    #Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    p -&gt; Npos\n    #p -&gt; Nneg\n    N -&gt; Npos\n    Npos -&gt; Nobs\n    #N -&gt; Nneg\n    esp -&gt; Nobs\n    sens -&gt; Nobs\n    #esp -&gt; Nneg\n    #sens -&gt; Nneg\n{ rank = same; p; N }\n{ rank = same; Npos}\n{ rank = max; sens; esp}\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nDonde vemos ahora que el estado real de cada persona de la prueba es desconocido, aunque el resultado de la prueba depende de ese estado, y la cantidad de positivos que observamos es ahora \\(N_{obs}\\), que depende también de la sensibilidad y especificidad de la prueba.\nY para constuir el modelo generativo notamos que la probabilidad de que un individuo infectado salga positivo es \\(\\text{sens}\\), y la probabilidad de que un individuo no infectado salga positivo es \\((1-\\text{esp})\\). De este modo, el modelo generativo es:\n\nsim_pos_neg &lt;- function(theta = 0.01, N = 20, sens = 0.84, esp = 0.995) {\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, theta)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra: si es positivo, calculamos\n  # la probabilidad de que realmente sea positivo\n  sim_tbl &lt;- tibble(Pos_verdadero, Neg_verdadero) |&gt; \n    mutate(Pos = rbinom(N, 1, Pos_verdadero * sens + Neg_verdadero * (1-esp))) |&gt; \n    mutate(Neg = 1 - Pos)\n  # Observaciones\n  sim_tbl |&gt; select(Pos, Neg)\n}\n\nHacemos unas pruebas:\n\nset.seed(8212)\nsim_pos_neg(theta = 0.3, N = 1e7, sens = 0.7, esp = 1) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.2099\n\nsim_pos_neg(theta = 0.3, N = 1e7, sens = 1, esp = 1) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.3001\n\n\n\n\n3.1.2 Paso 2: cantidad a estimar\nEn este punto hay que tener cuidado, porque no queremos estimar la proporción de positivos potenciales en la población (pues la prueba es imperfedta), sino la proporción de verdaderos positivos en la población. Esta cantidad sigue siendo representada por \\(\\theta\\) en nuestro modelo generativo.\n\n\n3.1.3 Paso 3: modelo estadístico\nEl modelo estadístico es ahora diferente. Vamos a plantear primero \\(p(D|\\theta, sens, esp)\\), que es la probabilidad de observar los datos \\(D\\) dado que \\(\\theta\\) es el parámetro de interés, y \\(sens\\) y \\(esp\\) (que en este caso suponemos conocidos). Es fácil ver que la probabilidad de obtener un positivo ahora es:\n\\(\\theta_{obs} = P(Positivo | \\theta, sens, esp) = \\theta \\cdot sens + (1-\\theta) \\cdot (1-esp)\\)\nSi llamamos a esta cantidad \\(\\theta_{obs}\\), de forma que dada una muestra de 0’s y 1’s, tenemos que la verosimilitud de la muestra dada cada conjetura \\(\\theta\\), y con \\(sens\\) y \\(esp\\) fijas, es:\n\\[p(D|\\theta, sens, esp) = \\theta_{obs}^{N_{+}}(1-\\theta_{obs})^{N_{-}}\\] Suponiendo que la distribución apriori de \\(\\theta\\) es uniforme, tenemos entonces que la distribución posterior cumple:\n\\[p(\\theta|D, sens, esp) \\propto \\theta_{obs}^{N_{+}}(1-\\theta_{obs})^{N_{-}}\\] donde \\(\\theta_obs\\) está dada por la fórmula de arriba. Sustituyendo:\n\\[p(\\theta|D, sens, esp) \\propto (\\theta \\cdot sens + (1-\\theta) \\cdot (1-esp))^{N_{+}}(\\theta(1-sens) + (1-\\theta)esp)^{N_{-}}\\]\nEsta posterior tiene la estructura de una distribución beta, pero es un poco más complicada. En este punto, utilizaremos una técnica que funciona para problemas chicos (de unos cuantos parámetros), y que consiste en hacer una aproximación discreta de la distribución posterior:\n\n\n\n\n\n\nMétodo de aproximación de rejilla\n\n\n\n\nDividimos el intervalo \\([0,1]\\) en \\(m\\) partes iguales, y calculamos el valor de la expresión proporcional a la posterior en cada uno de estos\nNormalizamos estos valores para que sumen 1, y obtenemos una distribución discreta que aproxima la posterior\nMuestreamos de esta distribución discreta para obtener una muestra de la posterior\n\nEste método sólo es factible en modelos simples cuando hay solamente unos cuantos parámetros por estimar, pues su complejidad crece exponencialmente con el número de parámetros. Rara vez se usa en la práctica por esta razón.\n\n\nAquí implementamos esta técnica de aproximación por rejilla. Incluimos también una Beta(1,3) como a priori:\n\nsimular_posterior_error &lt;- function(muestra, n, sens = 1, esp = 1){\n    theta &lt;- seq(1e-12, 1-1e-12, by = 0.0001)\n    p_obs &lt;- theta * sens + (1 - theta) * (1 - esp)\n    # verosimilitud (en logaritmo)\n    log_dens_sin_norm &lt;- log(p_obs) * sum(muestra) +  \n      log(1-p_obs) * (length(muestra) - sum(muestra))\n    # a priori\n    log_dens_sin_norm &lt;- log_dens_sin_norm + dbeta(theta, 1, 3, log = TRUE)\n    # normalizar\n    log_dens_norm &lt;- log_dens_sin_norm - log_sum_exp(log_dens_sin_norm)\n    densidad_post &lt;- exp(log_dens_norm)\n    tibble(theta = sample(theta, size = n, replace = TRUE, prob = densidad_post))\n}\n\nY ahora podemos ver cómo se ve la posterior:\n\nset.seed(328)\nuna_muestra &lt;- sim_pos_neg(theta = 0.2, N = 600, sens = 0.6, esp = 0.999)\nmean(una_muestra$Pos)\n\n[1] 0.1233333\n\nsims_post_error &lt;- \n  simular_posterior_error(una_muestra$Pos, 5000, sens = 0.6, esp = 0.999) \nsims_post_error |&gt;\n  ggplot(aes(x = theta)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nAhora seguimos el flujo. Agregaremos la verificación a priori para entender si nuestro modelo recupera los parámetros.\n\nset.seed(8112)\nsimulacion_rep_error &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 150, sens = 0.6, esp = 0.999)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior_error(datos_sim$Pos, 10000, sens = 0.6, esp = 0.999)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\n\nAhora usamos histogramas por ejemplo para mostrar cómo luce la posterior, y comparamos con los valores de la simulación:\n\nggplot(simulacion_rep_error, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\nFigura 3.1: Verificación a priori\n\n\n\n\nContrasta con lo que pasaría si usaramos el modelo sin considerar fuentes de error:\n\nset.seed(812)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 150, sens = 0.6, esp = 0.999)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior_error(datos_sim$Pos, 10000, 1, 1)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\n\nAhora usamos histogramas por ejemplo para mostrar cómo luce la posterior, y comparamos con los valores de la simulación:\n\nggplot(simulacion_rep, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\nFigura 3.2: Verificación a priori fallida (modelo incorrecto)\n\n\n\n\nEste resultado está lejos de ser aceptable.\nComparamos esta densidad con lo que obtendríamos sin considerar el error de medición, con los mismos datos:\n\nset.seed(8)\nsims_post &lt;- \n  simular_posterior_error(una_muestra$Pos, 5000, 1, 1)\nambas_sims_tbl &lt;- \n  sims_post_error |&gt;\n  mutate(tipo = \"Con error\") |&gt;\n  bind_rows(sims_post |&gt;\n              mutate(tipo = \"Sin error\"))\nambas_sims_tbl |&gt; ggplot(aes(x = theta, fill = tipo)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 50) +\n  scale_fill_manual(values = c(\"red\", \"blue\")) +\n  geom_vline(xintercept = 0.2, linetype = \"dashed\", color = \"black\")\n\n\n\n\nY vemos que la diferencia entre las distribuciones es considerable. En primer lugar, la distribución con error de medición es más ancha (hay más incertidumbre). En segundo lugar, como estimador de el parámetro de interés, nuestro modelo que no considera el error parece dar estimaciones sesgadas hacia abajo. Esto es porque la prevalencia no es tan baja, y la sensibilidad de la prueba no es muy buena, de manera que con el modelo con error inferimos correctamente que hay más prevalencia que lo que indicaría la proporción de positivos en las pruebas.\nAunque este ejemplo es claro, prevalencia, sensibilidad y especificidad interactúan de maneras a veces poco intuitivas."
  },
  {
    "objectID": "02-flujo-basico-2.html#prevalencia-con-datos-de-referencia",
    "href": "02-flujo-basico-2.html#prevalencia-con-datos-de-referencia",
    "title": "3  Flujo de trabajo básico: refinando el modelo",
    "section": "3.2 Prevalencia con datos de referencia",
    "text": "3.2 Prevalencia con datos de referencia\nAhora haremos un paso adicional: los valores de sensibilidad y especificidad generalmente no son conocidos con certeza, sino que son estimados a partir de una muestra de “estándar de oro”. En esta prueba particular, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas. Consideraremos 122 y 401 como tamaños de muestra fijos y conocidos (las personas fueron extraídas de otra población).\nDenotamos como \\(Ref\\) a los datos de referencia de “estándar de oro”.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta\n    esp\n    sens\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n  node [shape=plaintext]\n    Nobs [label = &lt;N&lt;SUB&gt;obs&lt;/SUB&gt;&gt;]\n   # Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n  edge [minlen = 3]\n    theta -&gt; Npos\n    #p -&gt; Nneg\n    N -&gt; Npos\n    Npos -&gt; Nobs\n    #N -&gt; Nneg\n    esp -&gt; Nobs\n    sens -&gt; Nobs\n    #esp -&gt; Nneg\n    #sens -&gt; Nneg\n    esp -&gt; Ref\n    sens -&gt; Ref\n{ rank = same; theta; N }\n#{ rank = same; Npos; Nneg}\n{ rank = max; sens; esp}\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nPor los argumentos de arriba, las distribuciones de esp y sens son beta y podemos incorporarlas en la simulación de la posterior. Nuestra nueva función para simular el proceso generativo es:\n\nsim_pos_neg &lt;- function(p = 0.01, N = 20, pos_gold = c(103,122), neg_gold = c(399,401)) {\n  # Simular especificidad y sensibilidad\n  sens &lt;- rbeta(1, pos_gold[1] + 1, pos_gold[2] - pos_gold[1] + 1)\n  esp &lt;- rbeta(1, neg_gold[1] + 1, neg_gold[2] - neg_gold[1] + 1)\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, p)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra: si es positivo, calculamos\n  # la probabilidad de que realmente sea positivo\n  sim_tbl &lt;- tibble(Pos_verdadero, Neg_verdadero) |&gt; \n    mutate(Pos = rbinom(N, 1, Pos_verdadero * sens + Neg_verdadero * (1-esp))) |&gt; \n    mutate(Neg = 1 - Pos)\n  # Observaciones\n  sim_tbl |&gt; select(Pos, Neg)\n}\n\nConsiderando que tenemos tres parámetros, en este punto decidimos no hacer la aproximación de rejilla. Es posible hacer otro tipo de aproximaciones (por ejemplo cuadráticas), pero en lugar de esto veremos cómo lo haríamos con Stan. Más adelante discutiremos los algoritmos que Stan utiliza para simular de la posterior de modelos muy generales. Por el momento, notamos que está basado en un algoritmo de simulación MCMC (Markov Chain Montecarlo), que es el estándar para modelos que no son muy simples. Este ejemplo es para ilustrar cómo resolveríamos el problema más general, no es necesario que en este punto entiendas cómo funciona o los detalles de la implementación.\n\nlibrary(cmdstanr)\nmod_sc &lt;- cmdstan_model(\"./src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; n;\n  int&lt;lower=0&gt; kit_pos;\n  int&lt;lower=0&gt; n_kit_pos;\n  int&lt;lower=0&gt; kit_neg;\n  int&lt;lower=0&gt; n_kit_neg;\n}\n\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; //seroprevalencia\n  real&lt;lower=0, upper=1&gt; sens; //sensibilidad\n  real&lt;lower=0, upper=1&gt; esp; //especificidad\n}\n\ntransformed parameters {\n  real&lt;lower=0, upper=1&gt; prob_pos;\n\n  prob_pos = theta * sens + (1 - theta) * (1 - esp);\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  // modelos para resultados del kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales para cantidades no medidas\n  theta ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\n\nn &lt;- 50\nN &lt;- 3300\ndatos_lista &lt;- list(N = 3300, n = 50,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste &lt;- mod_sc$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\nsims &lt;- ajuste$draws(c(\"theta\", \"sens\", \"esp\"), format = \"df\")\nresumen &lt;- ajuste$summary(c(\"theta\"))\n\n\nresumen |&gt; select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean      q5    q95\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 theta    0.0104 0.00243 0.0174\n\n\nY podemos graficar la posterior de la seroprevalencia:\n\nggplot(sims, aes(x = theta)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nY vemos que los datos son consistentes con el dato reportado por los autores (alrededor de 1.2%), pero que no podemos excluir valores de prevalencia muy bajos (por abajo de 0.3% por ejemplo). Por otro lado, también son consistentes valores muy altos de seroprevalencia, de manera que este estudio resultó ser poco informativo de la IFR del COVID.\nPodemos hacer diagnósticos adicionales acerca de la razón de esta variabilidad alta, si graficamos la relación entre especificidad de la prueba y estimación de prevalencia:\n\nggplot(sims, aes(x = esp, y = theta)) + geom_point() +\n  xlab(\"Especificidad del kit\") + ylab(\"Prevalencia\") + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nLa asociación entre estas dos cantidades es interesante porque conceptualmente (y desde punto de vista del modelo), no hay relación entre estas dos variables: su asociación aparece porque son causas que compiten para explicar una observación.\nNótese que dada la prevalencia baja, la especificidad del kit es un factor importante para explicar la prevalencia observada, pero si no pensamos con cuidado podríamos concluir que los falsos positivos no deberían ser problema por que la especificidad para ser muy buena.\nY notamos que aún con una muestra relativamente grande, el rango de \\(\\theta\\) es considerable: va desde valores cercanos a 0 hasta valores alrededor de 0.025-0.03."
  }
]