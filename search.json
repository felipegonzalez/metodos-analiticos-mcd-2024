[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos analíticos",
    "section": "",
    "text": "Temario y referencias\nEste es un curso de estadística bayesiana con énfasis en inferencia causal y flujos de trabajo robustos para análisis de datos. Está basado en el material de McElreath (2020).\nTodas las notas y material del curso estarán en este repositorio.\n\nModelos estadísticos e inferencia causal\nBásicos del flujo de trabajo para inferencia bayesiana\nBásicos de modelación\nModelos gráficos (DAGS) y efectos causales\nExperimentos. Buenos y malos controles\nMCMC, Monte Carlo Hamiltoniano y Stan\nFlujo de trabajo bayesiano avanzado\nModelos jerárquicos\nError de medición y clasificación incorrecta\nDatos faltantes\nOtros métodos de inferencia causal\n\n\nEvaluación\n\nTareas semanales (20%)\nExamen parcial (40% teórico)\nUn examen final (40% práctico)\n\n\n\nMaterial\nCada semestre las notas cambian, en algunas partes considerablemente. Las de este semestre están en este repositorio, incluyendo ejemplos, ejercicios y tareas.\n\n\nReferencias principales\nEste curso sigue aproximadamente la primera referencia (Statistical Rethinking).\n\nStatistical Rethinking\nCausal Inference in Statistics: a primer\nCounterfactuals and Causal Inference: Methods and Principles for Social Research\nBayesian workflow]\nTowards a principled Bayesian workflow\n\n\n\nOtras referencias\n\nThe Book of Why\nCausal Inference: The Mixtape\nData Analysis Using Regression and Multilevel/Hierarchical Models\nPattern Recognition and Machine Learning\n\n\n\nSoftware: R y Rstudio\nPara hacer las tareas y exámenes pueden usar cualquier lenguaje de programación que les convenga (R o Python, por ejemplo) - el único requisito esté basado en código y no point-and-click. Adicionalmente usaremos Stan:\n\nStan: a state-of-the-art platform for statistical modeling and high-performance statistical computation, que tiene interfaces en R, Python, Julia, etc.\n\n\n\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ."
  },
  {
    "objectID": "01-introduccion.html#diagramas-causales",
    "href": "01-introduccion.html#diagramas-causales",
    "title": "1  Introducción",
    "section": "1.1 Diagramas causales",
    "text": "1.1 Diagramas causales\nEn primer lugar, observamos (McElreath (2020)):\n\n\n\n\n\n\nCausas y mecanismos\n\n\n\nLas razones de cómo hacemos análisis estadístico (que procedimiento o algoritmo seleccionamos, por ejemplo) en un problema dado no están en los datos observados, las causas de los datos.\n\n\nLas causas de los datos no pueden extrarse de los datos solamente. Muchas veces nos referimos a las causas de los datos como el proceso generador de los datos: esto incluye aspectos del fenómeno que nos interesa (ciencia o proceso de negocios, etc.), así como el proceso de observación (muestras, valores no observados, etc.).\nConsideremos un ejemplo simple para ilustrar este primer principio:\n\nEjemplo (cálculos renales)\nEste es un estudio real acerca de tratamientos para cálculos renales (Julious y Mullee (1994)). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.\nLa tabla original tiene 700 renglones (cada renglón es un paciente)\n\ncalculos &lt;- read_csv(\"../datos/kidney_stone_data.csv\")\nnames(calculos) &lt;- c(\"tratamiento\", \"tamaño\", \"éxito\")\ncalculos &lt;- calculos |&gt; \n   mutate(tamaño = ifelse(tamaño == \"large\", \"grandes\", \"chicos\")) |&gt; \n   mutate(resultado = ifelse(éxito == 1, \"mejora\", \"sin_mejora\")) |&gt; \n   select(tratamiento, tamaño, resultado)\nnrow(calculos)\n\n[1] 700\n\n\ny se ve como sigue (muestreamos algunos renglones):\n\ncalculos |&gt; \n   sample_n(10) |&gt; kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nresultado\n\n\n\n\nA\nchicos\nmejora\n\n\nB\ngrandes\nmejora\n\n\nB\nchicos\nmejora\n\n\nB\nchicos\nmejora\n\n\nA\nchicos\nmejora\n\n\nA\ngrandes\nmejora\n\n\nB\ngrandes\nmejora\n\n\nB\nchicos\nmejora\n\n\nB\ngrandes\nmejora\n\n\nA\ngrandes\nmejora\n\n\n\n\n\n\n\nAunque estos datos contienen información de 700 pacientes, los datos pueden resumirse sin pérdida de información contando como sigue:\n\ncalculos_agregada &lt;- calculos |&gt; \n   group_by(tratamiento, tamaño, resultado) |&gt; \n   count()\ncalculos_agregada |&gt; kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nresultado\nn\n\n\n\n\nA\nchicos\nmejora\n81\n\n\nA\nchicos\nsin_mejora\n6\n\n\nA\ngrandes\nmejora\n192\n\n\nA\ngrandes\nsin_mejora\n71\n\n\nB\nchicos\nmejora\n234\n\n\nB\nchicos\nsin_mejora\n36\n\n\nB\ngrandes\nmejora\n55\n\n\nB\ngrandes\nsin_mejora\n25\n\n\n\n\n\n\n\nComo en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:\n\ncalculos_agregada |&gt; pivot_wider(names_from = resultado, values_from = n) |&gt; \n   mutate(total = mejora + sin_mejora) |&gt; \n   mutate(prop_mejora = round(mejora / total, 2)) |&gt; \n   select(tratamiento, tamaño, total, prop_mejora) |&gt; \n   arrange(tamaño) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\ntotal\nprop_mejora\n\n\n\n\nA\nchicos\n87\n0.93\n\n\nB\nchicos\n270\n0.87\n\n\nA\ngrandes\n263\n0.73\n\n\nB\ngrandes\n80\n0.69\n\n\n\n\n\n\n\nEsta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Pero es apropiada para empezar a contestar la pregunta:\n\n¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?\n\nSupongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:\n\ncalculos |&gt; group_by(tratamiento) |&gt; \n   summarise(prop_mejora = mean(resultado == \"mejora\") |&gt; round(2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\nprop_mejora\n\n\n\n\nA\n0.78\n\n\nB\n0.83\n\n\n\n\n\n\n\ny parece ser que el tratamiento \\(B\\) es mejor que el \\(A\\). Esta es una paradoja (un ejemplo de la paradoja de Simpson) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar \\(B\\)? ¿Si sabe debería recetar \\(A\\)? Esta discusión parece no tener mucho sentido.\nPodemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:\n\ncalculos |&gt; group_by(tratamiento, tamaño) |&gt; count() |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nn\n\n\n\n\nA\nchicos\n87\n\n\nA\ngrandes\n263\n\n\nB\nchicos\n270\n\n\nB\ngrandes\n80\n\n\n\n\n\n\n\nNuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos. En este caso, hay una decisión pues A es una cirugía y B es un procedimiento menos invasivo, y se prefiere utilizar el tratamiento \\(A\\) para cálculos grandes, y \\(B\\) para cálculos chicos. Esto quiere decir que en la tabla total el tratamiento \\(A\\) está en desventaja porque se usa en casos más difíciles, pero el tratamiento \\(A\\) parece ser en general mejor. La razón es probablemente un proceso de optimización de recursos y riesgo que hacen los doctores.\n\nEn este caso, una mejor respuesta a la pregunta de qué tratamiento es mejor es la que presenta los datos desagregados.\nLa tabla desagregada de asignación del tratamiento nos informa acerca de cómo se está distribuyendo el tratamiento en los pacientes.\n\n\n\n\n\n\n\nNota\n\n\n\nLos resúmenes descriptivos acompañados de hipótesis causales acerca del proceso generador de datos, nos guía hacia descripciones interpretables de los datos.\n\n\nLas explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos.\nPodemos codificar la información causal con un diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    T \n    M \n    C\n  edge [minlen = 3]\n    T -&gt; M\n    C -&gt; T\n    C -&gt; M\n{ rank = same; M; T }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEs decir, el tamaño de los cálculos es una causa común de tratamiento (T) y resultado (M). Veremos más adelante que la decisión de condicionar a el tipo de cálculos proviene de un análisis relativamente simple de este diagrama causal, independientemente de los métodos que usemos para estimar las proporciones de interés (en este ejemplo, examinar las tablas cruzadas es equivalente a hacer estimaciones de máxima verosimlitud).\n\n\nEjemplo (cálculos renales 2)\nContrastemos el ejemplo anterior usando exactamente la misma tabla de datos, pero con el supuesto de un proceso generador diferente. En este caso, los tratamientos son para mejorar alguna enfermedad del corazón. Sabemos que parte del efecto de este tratamiento ocurre gracias a una baja en presión arterial de los pacientes, así que después de administrar el tratamiento, se toma la presión arterial de los pacientes. Ahora tenemos la tabla agregada y desagregada como sigue:\n\ncorazon &lt;- calculos |&gt; \n  select(tratamiento, presión = tamaño, resultado) |&gt; \n  mutate(presión = ifelse(presión == \"grandes\", \"alta\", \"baja\"))\ncorazon_agregada &lt;- corazon |&gt; \n   group_by(tratamiento, presión, resultado) |&gt; \n   count()\ncorazon_agregada |&gt; pivot_wider(names_from = resultado, values_from = n) |&gt; \n   mutate(total = mejora + sin_mejora) |&gt; \n   mutate(prop_mejora = round(mejora / total, 2)) |&gt; \n   select(tratamiento, presión, total, prop_mejora) |&gt; \n   arrange(presión) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\npresión\ntotal\nprop_mejora\n\n\n\n\nA\nalta\n263\n0.73\n\n\nB\nalta\n80\n0.69\n\n\nA\nbaja\n87\n0.93\n\n\nB\nbaja\n270\n0.87\n\n\n\n\n\n\n\n\ncorazon |&gt; group_by(tratamiento) |&gt; \n   summarise(prop_mejora = mean(resultado == \"mejora\") |&gt; round(2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\nprop_mejora\n\n\n\n\nA\n0.78\n\n\nB\n0.83\n\n\n\n\n\n\n\n¿Cuál creemos que es el mejor tratamiento en este caso? ¿Deberíamos usar la tabla agregada o la desagregada por presión?\n\nEn este caso, la tabla agregada es más apropiada (B es mejor tratamiento).\nLa razón es que presión en este caso es una consecuencia de tomar el tratamiento, y como las tablas muestran, B es más exitoso en bajar la presión de los pacientes.\nSi sólo comparamos dentro de los grupos de presión baja o de presión alta, ignoramos lo más importante del tratamiento en la probabilidad de mejorar.\n\nNuestros supuestos causales podemos mostrarlos con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    P\n    T \n    M \n  edge [minlen = 3]\n    T -&gt; P\n    P -&gt; M\n    T -&gt; M\n{ rank = same; M; T}\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nNótese que el análisis más apropiado no está en los datos: en ambos casos la tabla de datos es exactamente la misma. Los supuestos acerca del proceso que genera los datos sin embargo nos lleva a respuestas opuestas."
  },
  {
    "objectID": "01-introduccion.html#diagramas-causales-1",
    "href": "01-introduccion.html#diagramas-causales-1",
    "title": "1  Introducción",
    "section": "Diagramas causales",
    "text": "Diagramas causales\nLos diagramas de arriba se llaman DAGs (Gráficas dirigidas acíclicas), y no son generadas por datos observados, sino que codifican conocimiento acerca del fenómenos y los datos observados. Nos ayudan a (McElreath (2020)):\n\nPensar claramente en términos científicos/de negocio acerca de nuestro problema\nExpresar los supuestos que hacemos que soportan nuestro análisis\nEntender qué podemos entender o explicar, sin hacer supuestos adicionales acerca de las relaciones particulares entre las variables.\nGuiar el análisis para decidir que modelos o procedimientos usar para contestar preguntas de interés.\n\nLos DAGs se construyen con causas, e implican asociaciones observables, pero no se construyen con asociaciones simplemente. El pensamiento causal es útil siempre que queremos responder preguntas acerca de un fenómeno de interés. En particular nos asisten en :\n\nAnálisis descriptivo\n\nComo vimos en el ejemplo anterior, incluso el análisis descriptivo (qué tabla usar, qué gráfica usar) de datos requiere de un análisis causal.\nMuchas veces los datos que tenemos, por distintas razones, tienen características que requieren procesarlos (por ejemplo ponderarlos) para que nos den respuestas entendibles.\n\n\n\nInferencia causal\n\nEfectos de intervenciones: En algunos casos, queremos saber consecuencias de una intervención sobre un sistema o proceso dados (por ejemplo, ¿cuántos accidentes graves habría si pusiéramos una multa por no usar cinturón de seguridad?). Esto requiere utilizar pensamiento causal.\nContrafactuales: También es usual necesitar pensar cómo serían las cosas si el pasado se hubiera desarrollado de manera distinta (por ejemplo, ¿cómo serían las ventas si no se hubiera gastado en publicidad?) en publicidad ?).\n\n\n\nDiseño de estudios o experimentos\n\nSi queremos recolectar datos acerca de un fenómeno particular (por ejemplo, ¿cómo debo seleccionar una muestra para medir orientación política de una población?), diseños eficientes requieren tener conocimiento de dominio acerca de las causas de las variables que nos interesa medir. Por ejemplo, si queremos tomar una muestra de casillas para estimar el resultado de una votación, deberíamos considerar variables geográficas como distrito electoral, grado de urbanización, etc.\n\n\n\nPredicción\n\nIncluso en problemas de predicción, modelos útiles resultan de pensar en la estructura causal del problema. Ignorar estos aspectos puede llevar fácilmente a evaluación incorrecta del desempeño, filtración de datos, o modelos que no pueden implementarse en la práctica.\n\n\n\nOtro ejemplo (admisiones de Berkeley)\nUna ejemplo al que regresaremos más adelante es el siguiente: en 1973 se recolectaron datos agregados de solicitantes para estudiar en Berkeley para los 6 departamentos más grandes, clasificados por sexo del solicitante y si fue admitido o no. Los resultados se muestran a continuación:\n\ndata(\"UCBAdmissions\")\nadm_original &lt;- UCBAdmissions |&gt; as_tibble() |&gt; \n   pivot_wider(names_from = Admit, values_from = n) \nadm_original |&gt; knitr::kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nGender\nDept\nAdmitted\nRejected\n\n\n\n\nMale\nA\n512\n313\n\n\nFemale\nA\n89\n19\n\n\nMale\nB\n353\n207\n\n\nFemale\nB\n17\n8\n\n\nMale\nC\n120\n205\n\n\nFemale\nC\n202\n391\n\n\nMale\nD\n138\n279\n\n\nFemale\nD\n131\n244\n\n\nMale\nE\n53\n138\n\n\nFemale\nE\n94\n299\n\n\nMale\nF\n22\n351\n\n\nFemale\nF\n24\n317\n\n\n\n\n\n\n\ny las proporciones de admisión por sexo y departamente son las siguientes:\n\nadm_tbl &lt;- adm_original |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected), 2), total = Admitted + Rejected) |&gt; \n   select(Gender, Dept, prop_adm, total) |&gt; \n   pivot_wider(names_from = Gender, values_from = prop_adm:total)\nadm_tbl |&gt; knitr::kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nDept\nprop_adm_Male\nprop_adm_Female\ntotal_Male\ntotal_Female\n\n\n\n\nA\n0.62\n0.82\n825\n108\n\n\nB\n0.63\n0.68\n560\n25\n\n\nC\n0.37\n0.34\n325\n593\n\n\nD\n0.33\n0.35\n417\n375\n\n\nE\n0.28\n0.24\n191\n393\n\n\nF\n0.06\n0.07\n373\n341\n\n\n\n\n\n\n\nComplementamos con las tasas de aceptación a total por género, y tasas de aceptación por departamento:\n\nadm_original |&gt; group_by(Gender) |&gt; \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nGender\nAdmitted\nRejected\nprop_adm\n\n\n\n\nFemale\n557\n1278\n0.30\n\n\nMale\n1198\n1493\n0.45\n\n\n\n\n\n\n\nLa pregunta que queremos hacer es: ¿existe discriminación por sexo en la selección de candidatos? Examinando las tablas no está clara cuál es la respuesta.\n\nadm_original |&gt; group_by(Dept) |&gt; \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nDept\nAdmitted\nRejected\nprop_adm\n\n\n\n\nA\n601\n332\n0.64\n\n\nB\n370\n215\n0.63\n\n\nC\n322\n596\n0.35\n\n\nD\n269\n523\n0.34\n\n\nE\n147\n437\n0.25\n\n\nF\n46\n668\n0.06\n\n\n\n\n\n\n\nDiscutiremos este ejemplo con más detalle más adelante. La interpretación debe ser hecha con cuidado, y debemos establecer claramente los supuestos que fundamentan nuestra decisión de mostrar cada tabla y de qué forma mostrarlas."
  },
  {
    "objectID": "01-introduccion.html#modelos-y-algoritmos",
    "href": "01-introduccion.html#modelos-y-algoritmos",
    "title": "1  Introducción",
    "section": "1.2 Modelos y algoritmos",
    "text": "1.2 Modelos y algoritmos\nEn muchos cursos introductorios de estadística se muestran distintos tipos de procedimientos, que aplican según el tipo de datos (por ejemplo, categóricos o numéricos, pareados, no pareados, etc), generalmente con el propósito de evaluar evidencia en contra de una hipótesis nula. Por ejemplo, de McElreath (2020):\n\n\n\nEjemplo de proceso de decisión para procedimientos estadísticos\n\n\nEste enfoque puede ser confuso en un principio (¿cómo se relacionan todos estos procedimientos?), y también restringir nuestra capacidad para analizar datos: ¿qué hacemos cuando no se cumplen los supuestos de un procedimiento? Adicionalmente si no tenemos mucha experiencia, la manera en que fallan estas herramientas puede ser poco intuitiva y difícil de descubrir.\nY aunque son herramientas poderosas, no sustituyen el pensamiento científico o de proceso de negocios. Estas herramientas no generan hallazgos si no están acompañados de pensamiento causal.\nBuscamos entonces:\n\nDar herramientas (bayesianas) para analizar datos que son más flexibles, y se puedan adaptar a distintas situaciones.\nProponer un proceso para analizar datos, que sea más sistemático, robusto, y maneras de checar que el proceso es correcto o hace lo que pensamos que tiene qué hacer.\nLigar 1 y 2 con supuestos causales claros para proponer una interpretación sólida de nuestros resultados."
  },
  {
    "objectID": "01-introduccion.html#análisis-como-proceso",
    "href": "01-introduccion.html#análisis-como-proceso",
    "title": "1  Introducción",
    "section": "1.3 Análisis como proceso",
    "text": "1.3 Análisis como proceso\nIremos refinando nuestro poco a poco, conforme veamos distintas herramientas y problemas. El más básico es el siguiente (McElreath (2020)):\n\nDefinir un modelo generativo para la muestra de datos.\nDefinir la cantidad que queremos estimar en relación al fenómeno de interés.\nDefinir un proceso estadístico para hacer una estimación.\nProbar el proceso 3 usando 1 y 2.\n(Usar datos) Analizar los datos, resumir resultados.\nChecar cómputos y desempeño del modelo.\n\nEste proceso no es exclusivo de los modelos bayesianos, pero quizá es más natural, como veremos, cuando adoptamos el punto de vista bayesiano. Su propósito es múltiple: verificar que nuestros modelos están estimando las cantidades que realmente nos interesan, según nuestros supuestos, verificar los programas y cómputos con los que se obtienen resultados, y checar la adecuación del modelo a datos reales, cuestionando supuestos teóricos y supuestos de modelación.\nFinalmente, quisiéramos llegar a un proceso como el que se describe en Towards a Principled Bayesian Workflow, e incorporar el que se detalla en Gelman et al. (2020):\n\n\n\nGelman et al, Bayesian Workflow"
  },
  {
    "objectID": "01-introduccion.html#modelación-y-análisis-ingeniería",
    "href": "01-introduccion.html#modelación-y-análisis-ingeniería",
    "title": "1  Introducción",
    "section": "1.4 Modelación y análisis: ingeniería",
    "text": "1.4 Modelación y análisis: ingeniería\nCualquier proceso de análisis de datos se beneficia de muchos aspectos de ingenería de software. Parte de la profesionalización del análisis de datos que observamos en ciencia de datos es utilizar las herramientas reconocidas para resolver problemas de desarrollo y calidad de código, así como su documentación.\n\nAnálisis como software: Una parte de este proceso está relacionado con la reproducibilidad y documentación del trabajo, y su objetivo es evitar errores de programación y de organización (esta parte hablaremos menos: es necesario seguir los estándares de la industria para obtener resultados más confiables).\nOtra parte es el proceso con el cual construimos y contrastamos modelos para contestar preguntas, verificamos los modelos y sus respuestas y checamos resultados de cómputos.\n\n\n\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C. Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, y Martin Modrák. 2020. «Bayesian Workflow». https://arxiv.org/abs/2011.01808.\n\n\nJulious, Steven A, y Mark A Mullee. 1994. «Confounding and Simpson’s paradox». BMJ 309 (6967): 1480-81. https://doi.org/10.1136/bmj.309.6967.1480.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ."
  },
  {
    "objectID": "02-flujo-basico.html#paso-1-modelo-generativo",
    "href": "02-flujo-basico.html#paso-1-modelo-generativo",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.1 Paso 1: Modelo generativo",
    "text": "2.1 Paso 1: Modelo generativo\nConsideremos primero qué variables de interés tenemos: \\(p\\), la proporción de seropositivos en la población, \\(N\\) que es el número de personas a las que les hicimos la prueba, y \\(N_{+}\\) y \\(N_{-}\\) que cuentan el número de positivos y seronegativos en la muestra. Supondremos que la prueba da resultados exactos. Denotaremos por \\(\\theta\\) a la proporción de seropositivos en la muestra.\nComenzamos construyendo el diagrama que indica cómo influye cada variable en otra (nota: no son asociaciones, sino que indican qué variables “escuchan” a otras para determinar su valor). En este caso, \\(N\\) y \\(\\theta\\) son variable que no depende de ninguna otra, mientras que \\(N_{+}\\) y \\(N_{-}\\) dependen de \\(N\\) y \\(\\theta\\). Como \\(\\theta\\) es una cantidad que no observamos directamente, mostramos su nodo como un círculo.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta [label = &lt;&theta;&gt;]\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    theta -&gt; Npos\n    theta -&gt; Nneg\n    N -&gt; Npos\n    N -&gt; Nneg\n    #esp -&gt; Pos\n    #sens -&gt; Pos\n    #esp -&gt; Neg\n    #sens -&gt; Neg\n{ rank = same; theta; N }\n{ rank = same; Npos; Nneg}\n#{ rank = max; sens; esp}\n\n  \n}\n\", width = 300, height = 100)\n\n\n\n\n\n\nQue también podríamos simplificar (suponiendo la \\(N\\) fija y conocida, pues \\(N_+\\) y \\(M\\) dan \\(N_{-}\\)) como:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta [label = &lt;&theta;&gt;]\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    theta -&gt; Npos\n    N -&gt; Npos\n    #esp -&gt; Pos\n    #sens -&gt; Pos\n    #esp -&gt; Neg\n    #sens -&gt; Neg\n{ rank = same; theta; N }\n{ rank = same; Npos}\n#{ rank = max; sens; esp}\n\n  \n}\n\", width = 300, height = 100)\n\n\n\n\n\n\nY ahora construimos el modelo generativo. Supondremos que la muestra de \\(N\\) personas se toma de manera aleatoria de la población (una población grande, así que podemos ignorar el efecto de muestreo). Supondremos provisionalmente, además, que la prueba es perfecta, es decir, no hay falsos positivos o negativos.\nLa siguiente función simula una muestra de \\(N\\) personas, y regresa el número de Positivos y Negativos en la muestra.\n\nsim_pos_neg &lt;- function(theta = 0.01, N = 20, sens = 1, esp = 1) {\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, theta)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra\n  Pos &lt;- Pos_verdadero\n  Neg &lt;- 1 - Pos\n  # Observaciones\n  tibble(Pos = Pos, Neg = Neg)\n}\n\nPodemos hacer algunas pruebas del modelo generativo en casos extremos:\n\nset.seed(8212)\nsim_pos_neg(theta = 1.0, N = 10)\n\n# A tibble: 10 × 2\n     Pos   Neg\n   &lt;int&gt; &lt;dbl&gt;\n 1     1     0\n 2     1     0\n 3     1     0\n 4     1     0\n 5     1     0\n 6     1     0\n 7     1     0\n 8     1     0\n 9     1     0\n10     1     0\n\nsim_pos_neg(theta = 0.0, N = 10)\n\n# A tibble: 10 × 2\n     Pos   Neg\n   &lt;int&gt; &lt;dbl&gt;\n 1     0     1\n 2     0     1\n 3     0     1\n 4     0     1\n 5     0     1\n 6     0     1\n 7     0     1\n 8     0     1\n 9     0     1\n10     0     1\n\nsim_pos_neg(theta = 0.1, N = 1e7) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.1001\n\n\nEn la práctica podemos definir pruebas más exhaustivas si es necesario. En este caso, se trata principalmente de pruebas unitarias que se utilizan comunmente en desarrollo de software.\n\n\n\n\n\n\nPruebas unitarias\n\n\n\nLa práctica estándar de pruebas unitarias consiste en probar unidades relativamente pequeñas de código (por ejemplo funciones) para verificar que funcionan correctamente.\nEsta estrategia debe utilizarse también, en la medida de los posible, en estadística."
  },
  {
    "objectID": "02-flujo-basico.html#paso-2-definir-estimando",
    "href": "02-flujo-basico.html#paso-2-definir-estimando",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.2 Paso 2: Definir estimando",
    "text": "2.2 Paso 2: Definir estimando\nAhora podemos definir en términos de nuestro modelo el valor que queremos estimar. En este caso, coincide con un párametro del modelo \\(\\theta\\), pero no necesariamente es así siempre: como veremos más adelante, puede ser una cantidad que se deriva de otras variables y parámetros del modelo."
  },
  {
    "objectID": "02-flujo-basico.html#paso-3-definir-un-proceso-estadístico",
    "href": "02-flujo-basico.html#paso-3-definir-un-proceso-estadístico",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.3 Paso 3: definir un proceso estadístico",
    "text": "2.3 Paso 3: definir un proceso estadístico\nDada la información limitada que tenemos acerca de la población, esperamos tener cierta incertidumbre en nuestra estimación del valor de \\(\\theta\\). En estadística bayesiana esta incertidumbre la expresamos mediante una distribución de probabilidades sobre posibles valores del \\(\\theta\\). Si denotamos por \\(D\\) a los datos observados, nuestro objetivo es calcular o aproximar\n\\[p(\\theta|D)\\] que es una distribución sobre los posibles valores de \\(\\theta\\), una vez que tenemos información de la muestra, y que pone más masa de probabilidad sobre las conjeturas de \\(\\theta\\) que son más probables o creíbles. A esta distribución le llamamos la distribución posterior de \\(\\theta\\).\nCon esta posterior podemos hacer afirmaciones probabilísticas de la forma:\n\n¿Cuál es la probabilidad de que \\(\\theta\\) sea menor a 1%? (Muy pocos seropositivos)\n¿Cuál es la probabildad de que \\(\\theta\\) sea mayor a 80%? (Población cerca de saturación)\n\nEstas cantidades se calculan, al menos teóricamente, integrando \\(p(\\theta|D)\\) sobre los valores de \\(\\theta\\) que nos interesan, por ejemplo,\n\\[P(\\theta &lt;= 0.01) = \\int_0^{0.01} p(\\theta|D) d\\theta\\] Nota: la integral la interpretamos como suma en el caso discreto.\nSupongamos entonces una \\(\\theta\\) dada, y que observamos la muestra \\(1,0,0,1,0\\). La probabilidad de observar esta muestra es (suponiendo observaciones independientes):\n\\[\\theta(1-\\theta)(1-\\theta)\\theta(1-\\theta) = \\theta^2(1-\\theta)^3\\] Para algunos valores de \\(\\theta\\) (posibles conjeturas acerca del valor de \\(\\theta\\)) podemos escribir una tabla como sigue (Nota: discretizamos por el momento a un número finito de valores de \\(\\theta\\) para hacer el argumento más simple):\n\ntheta &lt;- seq(0, 1, length.out = 11)\ntibble(conjetura_theta = theta, verosimiltud = theta^2 * (1 - theta)^3) |&gt; \n  kbl(col.names = c(\"Conjetura θ\", \"p(D|θ)\"),\n      escape = FALSE) \n\n\n\n\nConjetura θ\np(D|θ)\n\n\n\n\n0.0\n0.00000\n\n\n0.1\n0.00729\n\n\n0.2\n0.02048\n\n\n0.3\n0.03087\n\n\n0.4\n0.03456\n\n\n0.5\n0.03125\n\n\n0.6\n0.02304\n\n\n0.7\n0.01323\n\n\n0.8\n0.00512\n\n\n0.9\n0.00081\n\n\n1.0\n0.00000\n\n\n\n\n\n\n\nEn la tabla vemos que hay algunas conjeturas, o posibles valores de \\(\\theta\\), que tienen probabilidad considerablemente más alta que otra. La notación\n\\[p(D|\\theta)\\] significa: la probabilidad de los datos \\(D\\) dado el valor de \\(\\theta\\). Nótese que esta distribución no es la posterior que describimos arriba, y no es una distribución de probabilidad sobre \\(\\theta\\) (las probabilidades no suman uno). Esta función se llama usualmente verosimilitud de los datos, e incorpora supuestos concretos del proceso generador de los datos.\nUsando reglas de probabilidad (en particular la regla de Bayes), observamos que\n\\[p(\\theta | D) = \\frac{p(D|\\theta)p(\\theta)} { p(D)}.\\] Como \\(p(\\theta|D)\\) debe dar una distribución de probabilidad (suma o integra a 1), entonces \\(p(D)\\) debe ser una constante de normalización para el numerador de la derecha, es decir, basta escribir\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta) \\] Ahora es donde encontramos que tenemos que tener \\(p(\\theta)\\) para poder calcular la cantidad que nos interesa, que es la distribución posterior \\(p(\\theta|D)\\). \\(p(\\theta)\\), la distribución a priori o distribución inicial es simplemente una afirmación de dónde puede estar \\(\\theta\\), antes de observar ningún dato.\nPor el momento, podríamos poner \\(p(\\theta)\\) constante, de manera que es parte de la constante de normalización, y sólo tendríamos que normalizar como sigue:\n\ntheta &lt;- seq(0, 1, length.out = 11)\nprob_post &lt;- tibble(conjetura = theta, probablidad = theta^2 * (1 - theta)^3) |&gt; \n  mutate(prob_posterior = probablidad / sum(probablidad)) \nprob_post |&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(D|θ)\",\"p(θ|D)\")) |&gt;\n  kable_paper()\n\n\n\n\nConjetura θ\np(D|θ)\np(θ|D)\n\n\n\n\n0.0\n0.00000\n0.0000000\n\n\n0.1\n0.00729\n0.0437444\n\n\n0.2\n0.02048\n0.1228923\n\n\n0.3\n0.03087\n0.1852385\n\n\n0.4\n0.03456\n0.2073807\n\n\n0.5\n0.03125\n0.1875188\n\n\n0.6\n0.02304\n0.1382538\n\n\n0.7\n0.01323\n0.0793879\n\n\n0.8\n0.00512\n0.0307231\n\n\n0.9\n0.00081\n0.0048605\n\n\n1.0\n0.00000\n0.0000000\n\n\n\n\n\n\n\nCon esto, expresamos nuestro conocimiento acerca de \\(\\theta\\), después de observar los datos, con una distribución posterior de probabilidad sobre las posibles conjecturas. Este es el resultado principal de inferencia bayesiana, y es la base para tomar decisiones relativas a \\(\\theta\\).\n\nUsando información adicional\nSupongamos que tenemos información adicional acerca de \\(\\theta\\), por ejemplo, que en un experimento similar anterior alguien tomó una muestra de dos personas, y encontraron dos negativos. Tenemos entonces como creencias inciales:\n\ntheta &lt;- seq(0, 1, length.out = 11)\nprob_priori &lt;- tibble(conjetura = theta) |&gt; \n  mutate(prob_priori = (1 - theta) * (1 - theta)) |&gt; \n  mutate(prob_priori = prob_priori / sum(prob_priori)) \nprob_priori |&gt;\n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\")) |&gt; kable_paper()\n\n\n\n\nConjetura θ\np(θ)\n\n\n\n\n0.0\n0.2597403\n\n\n0.1\n0.2103896\n\n\n0.2\n0.1662338\n\n\n0.3\n0.1272727\n\n\n0.4\n0.0935065\n\n\n0.5\n0.0649351\n\n\n0.6\n0.0415584\n\n\n0.7\n0.0233766\n\n\n0.8\n0.0103896\n\n\n0.9\n0.0025974\n\n\n1.0\n0.0000000\n\n\n\n\n\n\n\nPor ejemplo, al probabilidad inicial de que \\(\\theta\\) sea muy grande es cercana a cero, pues observamos dos negativos y ningún positivo. Ahora regresamos a considerar nuestra fórmula\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta), \\]\nEn este caso, la apriori o inicial tiene un efecto sobre la posterior. Reconsideramos entonces la posterior de nuestra muestra de 5 personas, y calculamos el producto de \\(P(D|\\theta)\\) por \\(p(\\theta)\\):\n\nprob_post &lt;- prob_priori |&gt; \n  mutate(verosimilitud = theta^2 * (1 - theta)^3) |&gt; \n  mutate(prod = verosimilitud * prob_priori)\n\nprob_post|&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\", \"p(D|θ)\",\n                      \"p(D|θ)p(θ)\")) |&gt; kable_paper()\n\n\n\n\nConjetura θ\np(θ)\np(D|θ)\np(D|θ)p(θ)\n\n\n\n\n0.0\n0.2597403\n0.00000\n0.0000000\n\n\n0.1\n0.2103896\n0.00729\n0.0015337\n\n\n0.2\n0.1662338\n0.02048\n0.0034045\n\n\n0.3\n0.1272727\n0.03087\n0.0039289\n\n\n0.4\n0.0935065\n0.03456\n0.0032316\n\n\n0.5\n0.0649351\n0.03125\n0.0020292\n\n\n0.6\n0.0415584\n0.02304\n0.0009575\n\n\n0.7\n0.0233766\n0.01323\n0.0003093\n\n\n0.8\n0.0103896\n0.00512\n0.0000532\n\n\n0.9\n0.0025974\n0.00081\n0.0000021\n\n\n1.0\n0.0000000\n0.00000\n0.0000000\n\n\n\n\n\n\n\nY finalmente, normalizamos para encontrar la probabilidad posterior:\n\nprob_post &lt;- prob_post |&gt; \n  mutate(prob_posterior = prod / sum(prod))\n\nprob_post|&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\", \"p(D|θ)\",\n    \"p(D|θ)p(θ)\", \"p(θ|D)\"), escape = FALSE) |&gt; kable_paper()\n\n\n\n\nConjetura θ\np(θ)\np(D|θ)\np(D|θ)p(θ)\np(θ|D)\n\n\n\n\n0.0\n0.2597403\n0.00000\n0.0000000\n0.0000000\n\n\n0.1\n0.2103896\n0.00729\n0.0015337\n0.0992712\n\n\n0.2\n0.1662338\n0.02048\n0.0034045\n0.2203539\n\n\n0.3\n0.1272727\n0.03087\n0.0039289\n0.2542983\n\n\n0.4\n0.0935065\n0.03456\n0.0032316\n0.2091640\n\n\n0.5\n0.0649351\n0.03125\n0.0020292\n0.1313412\n\n\n0.6\n0.0415584\n0.02304\n0.0009575\n0.0619745\n\n\n0.7\n0.0233766\n0.01323\n0.0003093\n0.0200177\n\n\n0.8\n0.0103896\n0.00512\n0.0000532\n0.0034430\n\n\n0.9\n0.0025974\n0.00081\n0.0000021\n0.0001362\n\n\n1.0\n0.0000000\n0.00000\n0.0000000\n0.0000000\n\n\n\n\n\n\n\nLa última columna nos da el resultado final de la inferencia bayesiana. Podemos resumir algunas de sus características, por ejemplo:\n\nEs muy poco probable que la seropositividad sea mayor o igual a 0.7\nUn intervalo de 90% de probabilidad para la seropositividad es \\([0.1, 0.5]\\)\n\nLa gráfica de la posterior es:\n\nprob_post |&gt;\n  ggplot(aes(x = conjetura, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") \n\n\n\n\nAhora podemos definir, para nuestro ejemplo discretizado, la función que calcula la posterior dados los pasos 1 y 2:\n\ncalcular_posterior &lt;- function(muestra, prob_priori){\n  # distribución inicial o a prior\n  theta &lt;- seq(0, 1, length.out = 11)\n  priori &lt;- tibble(theta = theta, prob_priori = (1 - theta) * (1 - theta)) |&gt; \n    mutate(prob_priori = prob_priori / sum(prob_priori))\n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post &lt;- tibble(theta = theta) |&gt; \n      left_join(priori, by = \"theta\") |&gt; \n      mutate(prob_posterior = theta ^ Npos * (1 - theta)^(N - Npos) * prob_priori) |&gt; \n    mutate(prob_posterior = prob_posterior / sum(prob_posterior)) \n  prob_post |&gt; select(theta, prob_posterior)\n}\n\n\nmuestra &lt;- c(1,0,0,1,0)\n\n\ncalcular_posterior(muestra, prob_priori) \n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0         0       \n 2   0.1       0.0993  \n 3   0.2       0.220   \n 4   0.3       0.254   \n 5   0.4       0.209   \n 6   0.5       0.131   \n 7   0.6       0.0620  \n 8   0.7       0.0200  \n 9   0.8       0.00344 \n10   0.9       0.000136\n11   1         0       \n\n\nProcedemos ahora a hacer algunas pruebas simples de nuestra función:\n\ncalcular_posterior(rep(0, 50)) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0.996\n 2   0.1          0.004\n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0    \n 6   0.5          0    \n 7   0.6          0    \n 8   0.7          0    \n 9   0.8          0    \n10   0.9          0    \n11   1            0    \n\ncalcular_posterior(rep(1, 50)) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0    \n 2   0.1          0    \n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0    \n 6   0.5          0    \n 7   0.6          0    \n 8   0.7          0    \n 9   0.8          0.011\n10   0.9          0.989\n11   1            0    \n\ncalcular_posterior(c(rep(0, 100), rep(1, 100))) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0    \n 2   0.1          0    \n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0.023\n 6   0.5          0.966\n 7   0.6          0.01 \n 8   0.7          0    \n 9   0.8          0    \n10   0.9          0    \n11   1            0    \n\n\n\n\nMás verificaciones a priori\nOtra verificación útil que podemos hacer es, una vez que hemos definido nuestro modelo generativo y un modelos estadístico asociado, generar bajo simulación datos que podríamos observar. Esto tiene como fin verificar que nuestro modelo generativo y nuestro modelo estadístico producen datos que están de acuerdo con el conocimiento experto (teoría científica o conocimiento de negocio).\nAsí que simulamos datos del modelo:\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\n\nPodemos ver por ejemplo dónde esperamos ver el número de positivos a lo largo de distintas muestras, cuando \\(N=30\\):\n\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos), .groups = \"drop\") |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n\n\n\nObservamos que con nuestros supuestos, hay una probabilidad alta de observar 0 positivos (alrededor de 0.30). Esto se debe en parte a la discretización que hicimos, y que nuestra apriori pone peso considerable en prevalencia igual a cero, lo que quizá no es muy realista, y probablemente deberíamos escoger al menos una discretización más fina.\nTambién, si consideramos los supuestos como correctos, esto puede indicar el riesgo de usar una muestra chica para estimar prevalencia si esta es muy baja: es probable que obtengamos 0 observaciones positivas.\n\n\n\n\n\n\nVerificación predictiva a priori\n\n\n\nCon este tipo de verificaciones podemos detectar las consecuencias de nuestros supuestos (incluyendo la elección de distribuciones a priori), así como otras decisiones de modelado (como la discretización).\nConflictos con el conocimiento del área deben ser explorados para entenderlos y si es necesario corregir nuestros supuestos.\n\n\nEste tipo de verificaciones es muy flexible, y debe adaptarse a los aspectos del conocimiento del área que son importantes para los expertos. Podemos usar todos nuestros recursos analíticos (tablas, resúmenes, gráficas) para producir estos chequeos."
  },
  {
    "objectID": "02-flujo-basico.html#paso-4-probar-el-proceso-de-estimación",
    "href": "02-flujo-basico.html#paso-4-probar-el-proceso-de-estimación",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.4 Paso 4: Probar el proceso de estimación",
    "text": "2.4 Paso 4: Probar el proceso de estimación\nAntes de utilizar datos, verificamos cómo se comporta nuestro proceso de estimación de acuerdo a los supuestos de nuestro modelo generativo.\n\n\n\n\n\n\nVerificación a priori\n\n\n\nLo mínimo que esperamos de nuestro método es que, bajo nuestros propios supuestos acerca del proceso generador de datos y nuestro procedimiento de estimación definido, nuestra función de estimación no tenga problemas numéricos o de programación, y que las estimaciones que arroja son apropiadas para la cantidad que nos interesa estimar. El procedimiento a grandes rasgos es:\n\nEstablecer valores de los parámetros a estimar\nSimular datos observados (con una \\(N\\) apropiada, dependiendo del tamaño de muestra que esperamos, aunque se puede explorar hacer más grande o más chico este valor).\nCalcular posterior de las cantidades de interés\nCompara los valores de 1) con la posterior de 3)\n\n\n\nDefinir que las posteriores son apropiadas para la cantidad que nos interesa estimar es delicado, y más adelante veremos algunos criterios para evaluar este aspecto. Por lo pronto, haremos algunas pruebas simples que pueden diagnosticar errores graves:\n\ntheta &lt;- 0.2\nN &lt;- 30\n# simular\nset.seed(9914)\ndatos_sim &lt;- sim_pos_neg(theta = theta, N = N)\nposterior &lt;- calcular_posterior(datos_sim$Pos)\nggplot(posterior, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(xintercept = theta, color = \"red\", linetype = \"dashed\")\n\n\n\n\nEn este caso, la estimación parece correcta. Podemo repetir el proceso con distintos valores de \\(\\theta\\):\n\nset.seed(21)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      posterior &lt;- calcular_posterior(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\nY vemos que en general nuestro método parece funcionar correctamente.\n\n\n\n\n\n\nObservaciones\n\n\n\n\nMás adelante veremos cómo comparar valores a estimar con la posterior a través de varias simulaciones de manera más rigurosa. Por el momento, recuerda que incluso pruebas simples o limitadas son mejores que ninguna prueba.\nTípicamente los valores iniciales se toman de la distribución a priori, como hicimos arriba. Esta prueba es en general más apropiada, pues no nos interesan configuración de parámetros con probabilidad inicial extremadamente baja (imposibles según nuestros supuestos), pero también es posible tomar algunos valores fijos de interés.\nVeremos más de chequeos o pruebas predictivas a priori, que en general también sirven para entender la adecuación del modelo y supuestos en términos de como coinciden o no datos generados con la teoría.\n\n\n\nEste paso también es importante para entender si, bajo nuestros propios supuestos, es factible obtener información útil bajo el diseño que propongamos. Por ejemplo, alguien podría proponer un diseño de muestra que sólo tome 5 personas. Podemos probar cómo se comportan nuestras estimaciones:\n\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 3)\n      posterior &lt;- calcular_posterior(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\nNuestra respuesta en este caso es que quizá con 3 personas la información obtenida no será suficiente para tomar decisiones útiles: nótese que la posterior está muy poco concentrada alrededor del verdadero valor de \\(\\theta\\).\n\n2.4.1 Introduciendo un bug\nSupongamos que tenemos un error en el cálculo de la posterior:\n\ncalcular_posterior_bug &lt;- function(muestra, prob_priori){\n  # distribución inicial o a prior\n  theta &lt;- seq(0, 1, length.out = 11)\n  priori &lt;- tibble(theta = theta, prob_priori = (1 - theta) * (1 - theta)) |&gt; \n    mutate(prob_priori = prob_priori / sum(prob_priori))\n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post &lt;- tibble(theta = theta) |&gt; \n      left_join(priori, by = \"theta\") |&gt; \n    # la siguiente línea tiene un error!\n      mutate(prob_posterior = theta ^ Npos * (1 - theta)^((N - Npos * prob_priori))) |&gt; \n    mutate(prob_posterior = prob_posterior / sum(prob_posterior)) \n  prob_post |&gt; select(theta, prob_posterior)\n}\n\nNuestro chequeo apriori se ve entonces:\n\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      posterior &lt;- calcular_posterior_bug(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\nDonde vemos en varios casos que la “posterior” está lejos de ser consistente con los valores simulados de prueba para \\(\\theta\\).\n\n\n\n\n\n\nAspectos numéricos\n\n\n\nEs importante notar que los cálculos que hicimos arriba ingoran un principio importante al hacer cálculos de productos de probabilidades: generalmente es mejor utilizar la escala logarítmica para hacer los cálculos, y sólo al final convertir a probabilidades. Esto es porque es fácil tener subflujos numéricos al multiplicar muchas probabilidades pequeñas.\n\n\nAunque en este caso no es crítico, la siguiente función sigue esta práctica que en general es necesario seguir:\n\n# Evitar desbordes al sumar exponenciales\nlog_sum_exp &lt;- function(x){\n  max_x &lt;- max(x)\n  max_x + log(sum(exp(x - max_x)))\n}\ncalcular_posterior &lt;- function(muestra, prob_priori){\n  # evitar 0 o 1 exactos\n  theta &lt;- seq(1e-12, 1 - 1e-12, length.out = 11)\n  # no es necesario normalizar esta distribución apriori\n  log_priori &lt;- tibble(theta = theta, log_prob_priori = 2 * log(1 - theta)) \n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post_tbl &lt;- tibble(theta = theta) |&gt; \n    left_join(log_priori, by = \"theta\") |&gt; \n    # log verosimilitud\n    mutate(log_prob_posterior = \n        Npos * log(theta) + log(1 - theta) * (N - Npos)) |&gt; \n    # sumar log apriori\n    mutate(log_prob_posterior = log_prob_posterior + log_prob_priori) |&gt; \n    mutate(log_prob_posterior_norm = \n      log_prob_posterior - log_sum_exp(log_prob_posterior)) |&gt; \n    mutate(prob_posterior = exp(log_prob_posterior_norm))\n  prob_post_tbl |&gt; select(theta, prob_posterior)\n}\n\nEjercicio: corre las pruebas para esta versión de la función como hicimos arriba. Este es un cambio correcto, y desde el punto de vista de desarrollo, si nuestra batería de pruebas es apropiado podemos hacerlo con más confianza."
  },
  {
    "objectID": "02-flujo-basico.html#paso-5-analizar-los-datos-y-resumir-resultados.",
    "href": "02-flujo-basico.html#paso-5-analizar-los-datos-y-resumir-resultados.",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.5 Paso 5: Analizar los datos y resumir resultados.",
    "text": "2.5 Paso 5: Analizar los datos y resumir resultados.\nCon este trabajo hecho (ojo: para modelos grandes es un trabajo considerable, pero importante), podemos proceder a analizar los datos.\nSupongamos que se tomó una muestra de \\(N=20\\) personas, con 17 negativos y 3 positivos. Calculamos la posterior:\n\n# en nuestro modelo *no* importa el orden, verifica:\ndatos_tbl &lt;- tibble(Pos = c(rep(1, 3), rep(0, 17)))\nposterior &lt;- calcular_posterior(muestra = datos_tbl$Pos)\nggplot(posterior, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") \n\n\n\n\nY hay varias maneras de resumir esta posterior. Por ejemplo, podemos calcular (ojo: veremos más detalles de esto más adelante):\n\n# Media\nposterior |&gt; \n  mutate(theta = theta) |&gt; \n  summarise(media = sum(theta * prob_posterior))\n\n# A tibble: 1 × 1\n  media\n  &lt;dbl&gt;\n1 0.166\n\n# Intervalo de alta probabilidad 90%\nposterior |&gt; \n  mutate(theta = theta) |&gt; \n  arrange(desc(prob_posterior)) |&gt; \n  mutate(cumsum = cumsum(prob_posterior)) |&gt; \n  filter(cumsum &lt;= 0.9) |&gt; \n  pull(theta) |&gt; \n  range()\n\n[1] 0.1 0.2"
  },
  {
    "objectID": "02-flujo-basico.html#paso-6-evaluar-el-modelo-y-cómputos",
    "href": "02-flujo-basico.html#paso-6-evaluar-el-modelo-y-cómputos",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.6 Paso 6: Evaluar el modelo y cómputos",
    "text": "2.6 Paso 6: Evaluar el modelo y cómputos\nEn este ejemplo, el modelo es muy simple, y los cómputos son sencillos. Para modelos más complejos es necesario checar que los cómputos sean correctos, y que el modelo ajusta razonablemente bien a los datos en los aspectos que nos interesan, de modo que dejaremos esta discusión cuando veamos el flujo bayesiano más avanzado."
  },
  {
    "objectID": "02-flujo-basico.html#versión-continua",
    "href": "02-flujo-basico.html#versión-continua",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.7 Versión continua",
    "text": "2.7 Versión continua\nEn el ejemplo anterior utilizamos una variable aleatoria discreta para modelar la seroprevalencia, pero esto generalmente no es conveniente. Ahora repetimos el ejercicio considerando más naturalmente que \\(\\theta\\) puede tomar cualquier valor en \\([0,1]\\).\nPara el paso 1 y 2 (definir modelo generativo y cantidad a estimar), utilizamos el mismo diagrama de arriba y la misma función que simula datos. Igual que antes, para cualquier muestra \\(D\\) compuesta de 0 y 1’s (negativos y positivos), la probabilidad de observar la muestra \\(D\\) dada una conjetura \\(\\theta\\) es:\n\\[ p(D|\\theta) = \\theta^{N_+}(1-\\theta)^{N_-}\\] Y recordamos que desde el punto de vista bayesiano, queremos resumir nuestra información obtenida con la distribución posterior \\(p(\\theta|D)\\), e igual que antes tenemos que:\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta).\\] Por el momento pondremos la densidad continua uniforme \\(p(\\theta) = 1\\) para \\(\\theta\\in [0,1]\\) (densidad uniforme), entonces\n\\[p(\\theta|D) \\propto \\theta^{N_+}(1-\\theta)^{N_-}\\]\nEn este caso, para normalizar tenemos que hacer la integral de la expresión de la derecha, y dividir por el resultado. En general, escribiremos\n\\[B(a,b) = \\int_{0}^1 \\theta^{a-1}(1-\\theta)^{b-1} d\\theta\\] así que en nuestro caso, la posterior es:\n\\[p(\\theta|D) = \\frac{1}{B(N_{+} + 1,N_{-}+1)} \\theta^{N_+}(1-\\theta)^{N_-}\\] Es posible demostrar con cálculo que \\(B(a,b) = \\frac{(a-1)!(b-1)!}{(a+b-1)!}\\), pero eso no es importante ahora. Este tipo de densidades pertenecen a la familia beta con parámetros \\((a,b)\\), donde \\(a&gt;0, b&gt;0\\).\nPor ejemplo, si observamos 2 positivos y tres negativos, nuestra posterior es una beta con parámetros \\((3,4)\\), y se ve así:\n\nlibrary(tidyverse)\ntheta &lt;- seq(0,1, 0.01)\ntibble(theta = theta, densidad = dbeta(theta, 3, 4)) |&gt; \n  ggplot(aes(x = theta, y = densidad)) +\n  geom_line() +\n  labs(x = \"theta\", y = \"Densidad posterior\") \n\n\n\n\nNotamos adicionalmente que es posible seleccionar otra distribución inicial que no sea la uniforme. En este caso particular es conveniente (aunque no siempre tiene sentido) usar una distribución beta, de manera que es fácil ver que si ponemos por ejemplo\n\\[p(\\theta) \\propto \\theta^{a-1}(1-\\theta)^{b-1}\\]\nentonces la posterior, por la fórmula de Bayes, es:\n\\[p(\\theta|D) \\propto \\theta^{N_+ +a -1 }(1-\\theta)^{N_{-}+b-1}\\] que también es de la familia beta, pero con parámetros \\((N_{+} +a, N_{-} +b)\\).\n\n2.7.1 Ejercicio: actualizaciones de posterior\nPodemos examinar la posterior para dados distintos datos. Supondremos que la distribución a priori es uniforme.\n\nset.seed(92192)\ntheta_seq &lt;- seq(0,1, 0.001)\ndatos_sim &lt;- sim_pos_neg(theta = 0.25, N = 12) |&gt; \n  mutate(obs = ifelse(Pos==1, \"P\", \"N\")) |&gt; \n  mutate(n = 1:12)\n# graficar posteriores para cada n\ndatos_graf &lt;- datos_sim |&gt; \n  mutate(n_pos = cumsum(Pos), n_neg = cumsum(Neg)) |&gt; \n  mutate(muestra = accumulate(obs, ~ paste0(.x, .y))) |&gt; \n  group_by(n) |&gt;\n  mutate(dens_graf = \n    list(tibble(theta = theta_seq, \n      densidad = dbeta(theta_seq, n_pos + 1, n_neg + 1)))) |&gt; \n  unnest(dens_graf)\nggplot(datos_graf, aes(x=theta, y = densidad, group = n)) +\n  geom_line() + \n  facet_wrap(~ muestra) +\n  geom_abline(slope = 0, intercept = 1, color = \"gray\") \n\n\n\n\nAhora repetimos con una inicial beta \\((0,2)\\) (que equivale a observar dos negativos y ningún positivo en una muestra de 3 personas), de modo que \\(p(\\theta) = 2(1-\\theta)\\):\n\nset.seed(92192)\ntheta_seq &lt;- seq(0,1, 0.001)\ndatos_sim &lt;- sim_pos_neg(theta = 0.25, N = 12) |&gt; \n  mutate(obs = ifelse(Pos==1, \"P\", \"N\")) |&gt; \n  mutate(n = 1:12)\n# graficar posteriores para cada n\ndatos_graf &lt;- datos_sim |&gt; \n  mutate(n_pos = cumsum(Pos), n_neg = cumsum(Neg)) |&gt; \n  mutate(muestra = accumulate(obs, ~ paste0(.x, .y))) |&gt; \n  group_by(n) |&gt;\n  mutate(dens_graf = \n    list(tibble(theta = theta_seq, \n                densidad = dbeta(theta_seq, n_pos + 1, n_neg + 3)))) |&gt; \n  unnest(dens_graf)\nggplot(datos_graf, aes(x=theta, y = densidad, group = n)) +\n  geom_line() + \n  facet_wrap(~ muestra) +\n  geom_abline(slope = -2, intercept = 2, color = \"gray\") \n\n\n\n\n\nEn este punto, podríamos ir al siguiente paso, que es escribir una función para calcular la posterior. En realidad ya sabemos su función de densidad, pero cualquier resumen que hagamos de esta distribución requerirá de integrales (¿por qué? piensa en cómo calcular la probabilidad de ser menor que un valor, o cómo se calcula la media).\nAunque en este ejemplo simple la posterior tiene una forma conocida y hay manera de calcular (analíticamente o con rutinas numéricas ya implementadas) esos resúmenes de interés (media, cuantiles, etc.), en general calcular integrales no es una estrategia que podamos llevar muy lejos.\n\n\nMás de verificaciones apriori\nAntes de continuar, sin embargo, veremos cómo se veo el chequeo predictivo a priori que consideramos en la sección de arriba.\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # apriori seleccionada\n      theta_sim &lt;- rbeta(1, 1, 3)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\n\nPodemos ver por ejemplo dónde esperamos ver el número de positivos a lo largo de distintas muestras, cuando \\(N=30\\):\n\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos)) |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n`summarise()` has grouped output by 'rep'. You can override using the `.groups`\nargument.\n\n\n\n\n\nEste resultado es consecuencia de nuestros supuestos, antes de ver los datos, y resume que esperamos con mayor probabilidad un número bajo de positivos (en una muestra de N=30), y que es muy poco probable que observemos prevalencias muy altas. Dependiendo de la situación, este puede ser un resultado aceptable.\nUn resultado no aceptable para una enfermedad que sabemos que es relativamente rara (aunque tenemos incertidumbre), por ejemplo, podría ser el siguiente:\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # apriori seleccionada\n      theta_sim &lt;- rbeta(1, 30, 3)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos)) |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n`summarise()` has grouped output by 'rep'. You can override using the `.groups`\nargument.\n\n\n\n\n\nEste resultado no es aceptable cuando sabemos que es prácticamente imposible que la mayoría de la población está infectada. Debemos entonces regresar y ajustar nuestros supuestos: el problema en este caso es la elección de la distribución a priori para \\(\\theta\\).\nObservación: la crítica es sobre el conjunto completo de supuestos iniciales que hacemos acerca del problema. Cuando los diagnósticos no son aceptables desde el punto de vista teórico es necesario investigar dónde está el problema. Las distribuciones apriori que usamos, igual que cualquier supuesto, están sujetas a esta crítica. Nótese que esta crítica la estamos haciendo sin ver los datos que esperamos observar: es una crítica de supuestos.\n\n\n2.7.2 Métodos Monte Carlo\nUna vez que tenemos la densidad posterior podemos mostrarla o resumirla de varias maneras. Si tenemos una expresión analítica, esos resúmen típicamente consisten de integrales, por ejemplo:\n\nLa media o mediana posterior\nDeciles o u otro tipo de percentiles de la posterior\nIntervalos de probabilidad posterior\n\nEste proceso puede ser no trivial incluso para densidades posteriores conocidas. La alternativa a integrar es simular de la posterior y calcular las cantidades de interés a partir de las simulaciones. En general, esto es más fácil que integrar. En nuestro ejemplo, en lugar de usar una función de calcular_posterior, construimos una que es simular_posterior.\nEsta función será simple porque simular de una beta es un problema estándar, y existen muchas implementaciones. Podríamos escribir, por ejemplo:\n\nsimular_posterior &lt;- function(muestra, n){\n  tibble(theta = \n    rbeta(n, sum(muestra) + 1, length(muestra) - sum(muestra) + 1))\n}\n\n\nmuestra\n\n[1] 1 0 0 1 0\n\nsims_post &lt;- simular_posterior(muestra, 10000)\n\n\nsims_post |&gt; \n  ggplot(aes(x = theta)) +\n  geom_histogram(bins = 50)\n\n\n\n\nSi queremos calcular la media, por ejemplo, hacemos\n\n sims_post |&gt; pull(theta) |&gt;  mean()\n\n[1] 0.4280916\n\n\nSi queremos la probabilidad de que la prevalencia esté por debajo de 20% hacemos:\n\nsims_post |&gt; \n  summarise(prob = mean(theta &lt; 0.2))\n\n# A tibble: 1 × 1\n    prob\n   &lt;dbl&gt;\n1 0.0961\n\n\nMuchas veces se presentan intervalos de probabilidad posterior, por ejemplo, podríamos reportar que con 90% de probabilidad la prevalencia está en el siguiente intervalo:\n\nsims_post |&gt; \n  summarise(inf = quantile(theta, 0.05),\n            sup = quantile(theta, 0.95)) |&gt; \n  mutate(inf = round(inf, 2),\n         sup = round(sup, 2))\n\n# A tibble: 1 × 2\n    inf   sup\n  &lt;dbl&gt; &lt;dbl&gt;\n1  0.16  0.73\n\n\nObservación: No hay un intervalo mágico que debe reportarse (por ejemplo 95% de probabilidad es una costumbre o superstición). Hay varias maneras de construir intervalos de probabilidad. Dejaremos esta discusión para más adelante.\n\n\n\n\n\n\nMétodos Monte Carlo\n\n\n\nLos métodos Monte Carlo están basados en simulación de variables aleatorias. Las cantidades que nos interesan son integrales bajo una densidad de probabilidad. Si queremos calcular en general \\[I = \\int f(x)p(x)dx,\\] simulamos una gran cantidad de observaciones \\(x_1,\\ldots, x_M\\) bajo \\(p(x)\\), y entonces (Ley de los grandes números):\n\\[\\frac{1}{M} \\sum_{i=1}^{M} x_i \\to I\\] cuando \\(M\\to \\infty\\). De este modo, podemos aproximar con la precisión que requiramos la integral \\(I\\).\n\n\nNota 1: Sin más información del proceso de simulación, no es posible demostrar que una aproximación es “suficientemente” buena, no importa que tan grande sea \\(M\\). Más adelante veremos una batería de diagnósticos para al menos excluir los casos comunes en los que la aproximación es mala.\nNota 2: En nuestro caso, las integrales de interés usualmente son de la forma \\[I = \\int f(\\theta)p(\\theta|D) d\\theta,\\] donde \\(D\\) es la información de la muestra, \\(\\theta\\) en general es un vector de parámetros del modelo, y \\(f(\\theta)\\) es una función de \\(\\theta\\) que nos interesa. Por ejemplo, para la media posterior de \\(\\theta\\), usaríamos \\(f(\\theta) = \\theta\\). Podemos aproximar cualquier integral si tenemos simulaciones de la posterior:\n\\[\\theta_i \\sim p(\\theta|D) \\implies \\frac{1}{M} \\sum_{i=1}^{M} f(\\theta_i) \\to I.\\]\n\nFinalmente, checamos todo nuestra construcción de estimación como hicimos arriba, la diferencia es que ahora usamos simulaciones para entender el comportamiento de la posterior. En este caso, el proceso es como sigue:\n\nGeneramos un valor de la apriori \\(\\theta_{sim} \\sim \\text{Beta}(1,3)\\)\nSimulamos datos de la muestra (\\(N=25\\)) con el valor simulado de \\(\\theta\\)\nSimulamos un número grande \\(M\\) de valores de la posterior (aquí usaremos \\(M=10000\\))\nRepetimos 1-3\n\n\nset.seed(812)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 25)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior(datos_sim$Pos, 10000)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\nsimular_posterior &lt;- function(muestra, n){\n  tibble(theta = \n    rbeta(n, sum(muestra) + 1, \n             length(muestra) - sum(muestra) + 3))\n}\n\nAhora usamos histogramas por ejemplo para mostrar cómo luce la posterior, y comparamos con los valores de la simulación:\n\nggplot(simulacion_rep, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)"
  },
  {
    "objectID": "02-flujo-basico.html#observaciones-1",
    "href": "02-flujo-basico.html#observaciones-1",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.8 Observaciones",
    "text": "2.8 Observaciones\nEl proceso de arriba lo refinaremos considerablemente en el resto del curso.\n\nEn primer lugar, los modelos generativos serán más complicados, y estarán basados en teoría más compleja (que expresamos con diagramas causales)\nUsaremos más herramientas y componentes para construir modelos estadísticos apropiados, ya sea que construyamos un modelo completo para todo el proceso de generación de datos, o que usemos modelos estándar como regresión para aproximar respuestas, cuando es apropiado\nRefinaremos el proceso de checar que el cómputo (checar Monte Carlo) y la inferencia (verificación apriori) es correcta bajo nuestros supuestos.\nFinalmente, veremos qué hacer después de hacer la estimación y que los puntos de arriba están resueltos, para tener confianza en nuestras conclusiones.\n\n\n2.8.1 Resumen\nAquí juntamos algunas observaciones que se derivan de lo que hemos visto (flujo de trabajo y estimación bayesiana):\n\nTodo nuestro trabajo está fundamentado en entender qué es lo que queremos estimar dentro de un modelo generativo. Los diagramas causales nos ayudan a conectar el problema de interés con nuestros modelos, a construir modelos generativos y hacer explícitos nuestros supuestos.\nEl proceso de estimación siempre es el mismo: nuestro estimador es la distribución posterior, que se construye a partir de la verosimilitud y la apriori (modelo generativo). Nuestro estimador es la posterior de las cantidades de interés, que pueden resumirse de distintas maneras. Cualquier cálculo derivado de otras cantidades de interés debe considerar toda la posterior (no solo la media o la moda, etc. posterior).\nNuestro proceso incluye los chequeos predictivos a priori (basados en simulación de datos). Esto son cruciales para detectar problemas en nuestros supuestos (vs teoría) y que nuestro proceso sea internamente consistente. Esto también es una verificación de la información a priori.\nGeneralmente es más conveniente y práctico hacer simulaciones que calcular analíticamente la posterior o sus integrales."
  },
  {
    "objectID": "02-flujo-basico-2.html#prevalencia-con-error-conocido",
    "href": "02-flujo-basico-2.html#prevalencia-con-error-conocido",
    "title": "3  Flujo de trabajo básico: refinando el modelo",
    "section": "3.1 Prevalencia con error conocido",
    "text": "3.1 Prevalencia con error conocido\nNuestro ejemplo de la sección anterior es poco realista pues usualmente las pruebas que son utilizadas para medir la prevalencia no son perfectas. Bajo condiciones muy controladas, el perfil de desempeño de las pruebas se mide, obteniendo resultados son del siguiente tipo:\n\nEn pruebas de gold standard, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas.\nSin considerar la incertidumbre, esto implica que la prueba tiene una sensibilidad de 84% y una especificidad de 99.5%.\n\n\n3.1.1 Paso 1: modelo generativo\nPrimero supondremos que estos porcentajes de error son fijos. Nuestro modelo que incluye el error de medición se como sigue:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    p\n    Npos\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    Nobs [label = &lt;N&lt;SUB&gt;obs&lt;/SUB&gt;&gt;]\n    #Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    p -&gt; Npos\n    #p -&gt; Nneg\n    N -&gt; Npos\n    Npos -&gt; Nobs\n    #N -&gt; Nneg\n    esp -&gt; Nobs\n    sens -&gt; Nobs\n    #esp -&gt; Nneg\n    #sens -&gt; Nneg\n{ rank = same; p; N }\n{ rank = same; Npos}\n{ rank = max; sens; esp}\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nDonde vemos ahora que el estado real de cada persona de la prueba es desconocido, aunque el resultado de la prueba depende de ese estado, y la cantidad de positivos que observamos es ahora \\(N_{obs}\\), que depende también de la sensibilidad y especificidad de la prueba.\nY para constuir el modelo generativo notamos que la probabilidad de que un individuo infectado salga positivo es \\(\\text{sens}\\), y la probabilidad de que un individuo no infectado salga positivo es \\((1-\\text{esp})\\). De este modo, el modelo generativo es:\n\nsim_pos_neg &lt;- function(theta = 0.01, N = 20, sens = 0.84, esp = 0.995) {\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, theta)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra: si es positivo, calculamos\n  # la probabilidad de que realmente sea positivo\n  sim_tbl &lt;- tibble(Pos_verdadero, Neg_verdadero) |&gt; \n    mutate(Pos = rbinom(N, 1, Pos_verdadero * sens + Neg_verdadero * (1-esp))) |&gt; \n    mutate(Neg = 1 - Pos)\n  # Observaciones\n  sim_tbl |&gt; select(Pos, Neg)\n}\n\nHacemos unas pruebas:\n\nset.seed(8212)\nsim_pos_neg(theta = 0.3, N = 1e7, sens = 0.7, esp = 1) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.2099\n\nsim_pos_neg(theta = 0.3, N = 1e7, sens = 1, esp = 1) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.3001\n\n\n\n\n3.1.2 Paso 2: cantidad a estimar\nEn este punto hay que tener cuidado, porque no queremos estimar la proporción de positivos potenciales en la población (pues la prueba es imperfecta), sino la proporción de verdaderos positivos en la población. Esta cantidad sigue siendo representada por \\(\\theta\\) en nuestro modelo generativo.\n\n\n3.1.3 Paso 3: modelo estadístico\nEl modelo estadístico es ahora diferente. Vamos a plantear primero \\(p(D|\\theta, sens, esp)\\), que es la probabilidad de observar los datos \\(D\\) dado que \\(\\theta\\) es el parámetro de interés, y \\(sens\\) y \\(esp\\) (que en este caso suponemos conocidos). Es fácil ver que la probabilidad de obtener un positivo ahora es:\n\\(\\theta_{obs} = P(Positivo | \\theta, sens, esp) = \\theta \\cdot sens + (1-\\theta) \\cdot (1-esp)\\)\nSi llamamos a esta cantidad \\(\\theta_{obs}\\), de forma que dada una muestra de 0’s y 1’s, tenemos que la verosimilitud de la muestra dada cada conjetura \\(\\theta\\), y con \\(sens\\) y \\(esp\\) fijas, es:\n\\[p(D|\\theta, sens, esp) = \\theta_{obs}^{N_{+}}(1-\\theta_{obs})^{N_{-}}\\] Suponiendo que la distribución apriori de \\(\\theta\\) es uniforme, tenemos entonces que la distribución posterior cumple:\n\\[p(\\theta|D, sens, esp) \\propto \\theta_{obs}^{N_{+}}(1-\\theta_{obs})^{N_{-}}\\] donde \\(\\theta_{obs}\\) está dada por la fórmula de arriba. Sustituyendo:\n\\[p(\\theta|D, sens, esp) \\propto (\\theta \\cdot sens + (1-\\theta) \\cdot (1-esp))^{N_{+}}(\\theta(1-sens) + (1-\\theta)esp)^{N_{-}}\\]\nEsta posterior tiene la estructura de una distribución beta, pero es un poco más complicada. En este punto, utilizaremos una técnica que funciona para problemas chicos (de unos cuantos parámetros), y que consiste en hacer una aproximación discreta de la distribución posterior:\n\n\n\n\n\n\nMétodo de aproximación de rejilla\n\n\n\n\nDividimos el intervalo \\([0,1]\\) en \\(m\\) partes iguales, y calculamos el valor de la expresión proporcional a la posterior en cada uno de estos intervalos (por ejemplo en los puntos medios).\nNormalizamos estos valores para que sumen 1, y obtenemos una distribución discreta que aproxima la posterior.\nMuestreamos de esta distribución discreta para obtener una muestra de la posterior.\n\nEste método sólo es factible en modelos simples cuando hay solamente unos cuantos parámetros por estimar, pues su complejidad crece exponencialmente con el número de parámetros. Rara vez se usa en la práctica por esta razón.\n\n\nAquí implementamos esta técnica de aproximación por rejilla. Incluimos también una Beta(1,3) como a priori:\n\nsimular_posterior_error &lt;- function(muestra, n, sens = 1, esp = 1){\n    theta &lt;- seq(1e-12, 1-1e-12, by = 0.0001)\n    p_obs &lt;- theta * sens + (1 - theta) * (1 - esp)\n    # verosimilitud (en logaritmo)\n    log_dens_sin_norm &lt;- log(p_obs) * sum(muestra) +  \n      log(1-p_obs) * (length(muestra) - sum(muestra))\n    # a priori\n    log_dens_sin_norm &lt;- log_dens_sin_norm + dbeta(theta, 1, 3, log = TRUE)\n    # normalizar\n    log_dens_norm &lt;- log_dens_sin_norm - log_sum_exp(log_dens_sin_norm)\n    densidad_post &lt;- exp(log_dens_norm)\n    tibble(theta = sample(theta, size = n, replace = TRUE, prob = densidad_post))\n}\n\nY ahora podemos ver cómo se ve la posterior:\n\nset.seed(328)\nuna_muestra &lt;- sim_pos_neg(theta = 0.2, N = 600, sens = 0.6, esp = 0.999)\nmean(una_muestra$Pos)\n\n[1] 0.1233333\n\nsims_post_error &lt;- \n  simular_posterior_error(una_muestra$Pos, 5000, sens = 0.6, esp = 0.999) \nsims_post_error |&gt;\n  ggplot(aes(x = theta)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nAhora seguimos el flujo. Agregaremos la verificación a priori para entender si nuestro modelo recupera los parámetros.\n\nset.seed(8112)\nsimulacion_rep_error &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 150, sens = 0.6, esp = 0.999)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior_error(datos_sim$Pos, 10000, sens = 0.6, esp = 0.999)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\n\nAhora usamos histogramas por ejemplo para mostrar cómo luce la posterior, y comparamos con los valores de la simulación:\n\nggplot(simulacion_rep_error, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\nFigura 3.1: Verificación a priori\n\n\n\n\nContrasta con lo que pasaría si usaramos el modelo sin considerar fuentes de error:\n\nset.seed(812)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 150, sens = 0.6, esp = 0.999)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior_error(datos_sim$Pos, 10000, 1, 1)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\n\n\nggplot(simulacion_rep, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\nFigura 3.2: Verificación a priori fallida (modelo incorrecto)\n\n\n\n\nEste resultado está lejos de ser aceptable.\nComparamos esta densidad con lo que obtendríamos sin considerar el error de medición, con los mismos datos:\n\nset.seed(8)\nsims_post &lt;- \n  simular_posterior_error(una_muestra$Pos, 5000, 1, 1)\nambas_sims_tbl &lt;- \n  sims_post_error |&gt;\n  mutate(tipo = \"Con error\") |&gt;\n  bind_rows(sims_post |&gt;\n              mutate(tipo = \"Sin error\"))\nambas_sims_tbl |&gt; ggplot(aes(x = theta, fill = tipo)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 50) +\n  scale_fill_manual(values = c(\"red\", \"blue\")) +\n  geom_vline(xintercept = 0.2, linetype = \"dashed\", color = \"black\")\n\n\n\n\nY vemos que la diferencia entre las distribuciones es considerable. En primer lugar, la distribución con error de medición es más ancha (hay más incertidumbre). En segundo lugar, como estimador de el parámetro de interés, nuestro modelo que no considera el error parece dar estimaciones sesgadas hacia abajo. Esto es porque la prevalencia no es tan baja, y la sensibilidad de la prueba no es muy buena, de manera que con el modelo con error inferimos correctamente que hay más prevalencia que lo que indicaría la proporción de positivos en las pruebas.\nAunque este ejemplo es claro, prevalencia, sensibilidad y especificidad interactúan de maneras a veces poco intuitivas."
  },
  {
    "objectID": "02-flujo-basico-2.html#prevalencia-con-datos-de-referencia",
    "href": "02-flujo-basico-2.html#prevalencia-con-datos-de-referencia",
    "title": "3  Flujo de trabajo básico: refinando el modelo",
    "section": "3.2 Prevalencia con datos de referencia",
    "text": "3.2 Prevalencia con datos de referencia\nAhora haremos un paso adicional: los valores de sensibilidad y especificidad generalmente no son conocidos con certeza, sino que son estimados a partir de una muestra de “estándar de oro”. En esta prueba particular, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas. Consideraremos 122 y 401 como tamaños de muestra fijos y conocidos (las personas fueron extraídas de otra población).\nDenotamos como \\(Ref\\) a los datos de referencia de “estándar de oro”.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta\n    esp\n    sens\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n  node [shape=plaintext]\n    Nobs [label = &lt;N&lt;SUB&gt;obs&lt;/SUB&gt;&gt;]\n   # Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n  edge [minlen = 3]\n    theta -&gt; Npos\n    #p -&gt; Nneg\n    N -&gt; Npos\n    Npos -&gt; Nobs\n    #N -&gt; Nneg\n    esp -&gt; Nobs\n    sens -&gt; Nobs\n    #esp -&gt; Nneg\n    #sens -&gt; Nneg\n    esp -&gt; Ref\n    sens -&gt; Ref\n{ rank = same; theta; N }\n#{ rank = same; Npos; Nneg}\n{ rank = max; sens; esp}\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nUsando argumentos como los del modelo original, las distribuciones de esp y sens son beta y podemos incorporarlas en la simulación de la posterior. Nuestra nueva función para simular el proceso generativo es:\n\nsim_pos_neg &lt;- function(p = 0.01, N = 20, pos_gold = c(103,122), neg_gold = c(399,401)) {\n  # Simular especificidad y sensibilidad\n  sens &lt;- rbeta(1, pos_gold[1] + 1, pos_gold[2] - pos_gold[1] + 1)\n  esp &lt;- rbeta(1, neg_gold[1] + 1, neg_gold[2] - neg_gold[1] + 1)\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, p)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra: si es positivo, calculamos\n  # la probabilidad de que realmente sea positivo\n  sim_tbl &lt;- tibble(Pos_verdadero, Neg_verdadero) |&gt; \n    mutate(Pos = rbinom(N, 1, Pos_verdadero * sens + Neg_verdadero * (1-esp))) |&gt; \n    mutate(Neg = 1 - Pos)\n  # Observaciones\n  sim_tbl |&gt; select(Pos, Neg)\n}\n\nConsiderando que tenemos tres parámetros, en este punto decidimos no hacer la aproximación de rejilla. Es posible hacer otro tipo de aproximaciones (por ejemplo cuadráticas), pero en lugar de esto veremos cómo lo haríamos con Stan. Más adelante discutiremos los algoritmos que Stan utiliza para simular de la posterior de modelos muy generales. Por el momento, notamos que está basado en un algoritmo de simulación MCMC (Markov Chain Montecarlo), que es el estándar para modelos que no son muy simples. Este ejemplo es para ilustrar cómo resolveríamos el problema más general, no es necesario que en este punto entiendas cómo funciona o los detalles de la implementación.\n\nlibrary(cmdstanr)\nmod_sc &lt;- cmdstan_model(\"./src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; n;\n  int&lt;lower=0&gt; kit_pos;\n  int&lt;lower=0&gt; n_kit_pos;\n  int&lt;lower=0&gt; kit_neg;\n  int&lt;lower=0&gt; n_kit_neg;\n}\n\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; //seroprevalencia\n  real&lt;lower=0, upper=1&gt; sens; //sensibilidad\n  real&lt;lower=0, upper=1&gt; esp; //especificidad\n}\n\ntransformed parameters {\n  real&lt;lower=0, upper=1&gt; prob_pos;\n\n  prob_pos = theta * sens + (1 - theta) * (1 - esp);\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  // modelos para resultados del kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales para cantidades no medidas\n  theta ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\n\nn &lt;- 50\nN &lt;- 3300\ndatos_lista &lt;- list(N = 3300, n = 50,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste &lt;- mod_sc$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\nsims &lt;- ajuste$draws(c(\"theta\", \"sens\", \"esp\"), format = \"df\")\nresumen &lt;- ajuste$summary(c(\"theta\"))\n\n\nresumen |&gt; select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean      q5    q95\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 theta    0.0104 0.00243 0.0174\n\n\nY podemos graficar la posterior de la seroprevalencia:\n\nggplot(sims, aes(x = theta)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nY vemos que los datos son consistentes con el dato reportado por los autores (alrededor de 1.2%), pero que no podemos excluir valores de prevalencia muy bajos (por abajo de 0.3% por ejemplo). Por otro lado, también son consistentes valores muy altos de seroprevalencia, de manera que este estudio resultó ser poco informativo de la IFR del COVID.\nPodemos hacer diagnósticos adicionales acerca de la razón de esta variabilidad alta, si graficamos la relación entre especificidad de la prueba y estimación de prevalencia:\n\nggplot(sims, aes(x = esp, y = theta)) + geom_point() +\n  xlab(\"Especificidad del kit\") + ylab(\"Prevalencia\") + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nLa asociación entre estas dos cantidades es interesante porque conceptualmente (y desde punto de vista del modelo), no hay relación entre estas dos variables: su asociación aparece porque son causas que compiten para explicar una observación.\nNótese que dada la prevalencia baja, la especificidad del kit es un factor importante para explicar la prevalencia observada, pero si no pensamos con cuidado podríamos concluir que los falsos positivos no deberían ser problema por que la especificidad para ser muy buena.\nY notamos que aún con una muestra relativamente grande, el rango de \\(\\theta\\) es considerable: va desde valores cercanos a 0 hasta valores alrededor de 0.025-0.03."
  },
  {
    "objectID": "03-modelos-genericos.html#predicciones-sin-explicación",
    "href": "03-modelos-genericos.html#predicciones-sin-explicación",
    "title": "4  Componentes básicas de modelación 1",
    "section": "4.1 Predicciones sin explicación",
    "text": "4.1 Predicciones sin explicación\nEs posible obtener buenas predicciones con modelos estadísticos genéricos sin tener una explicación de cómo funciona el fenómeno que estamos modelando. Estos modelos, aunque pueden resultar en predicciones muy buenas y ser útiles, pueden ser riesgosos si se interpretan fuera de un contexto teórico con supuestos claros.\nEl primer ejemplo es de nuestra referencia de McElreath (2020): los epicilos planetarios del modelo geocéntrico para explicar el movimiento retrógrado de planetas en el cielo. Este modelo fue exitoso y muy preciso para calcular las posiciones futuras de los planetas en el cielo, pero sus fundamentos eran incorrectos: no es posible interpretar este modelo por sí solo para entender cómo funciona el sistema solar.\nModelos genéricos como regresión lineal o logística, métodos basados en árboles, redes neuronales típicamente caen en esta categoría de modelos de tipo “geocéntrico”: aunque pueden ser efectivos para predecir, debemos ser cuidadosos en su interpretación en términos de causas, efectos, y mecanismos del fenómeno que nos interesa.\nPodemos aplicar con éxito estas componentes de modelación si entendemos su papel: estos modelos genéricos no contienen o nos dan causas o mecanismos por sí solos, pero pueden ayudarnos extraer información causal bajo los supuestos apropiados."
  },
  {
    "objectID": "03-modelos-genericos.html#ejemplo-regresión-lineal",
    "href": "03-modelos-genericos.html#ejemplo-regresión-lineal",
    "title": "4  Componentes básicas de modelación 1",
    "section": "4.2 Ejemplo: regresión lineal",
    "text": "4.2 Ejemplo: regresión lineal\nEn este ejemplo, introducimos notación para representar modelos, usaremos posteriores con varios parámetros, y veremos cómo construir y aplicar modelos lineales, todo desde el punto de vista de nuestro flujo de trabajo.\nEn este ejemplo de McElreath (2020) queremos describir la relación entre peso y estatura de adultos de una población relativamente homogénea. Nuestro modelo causal es como sigue:\n\nEn primer lugar, la estatura (\\(H\\)) de las personas adultas influye en su peso (\\(W\\)). El peso, sin embargo, está influenciado también por otras variables no observadas:\n\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    U\n  node [shape=plaintext]\n    H\n    W\n  edge [minlen = 3]\n    H -&gt; W\n    U -&gt; W\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nNótese que no consideramos \\(W\\to H\\), porque podemos pensar en varias intervenciones que podrían cambiar el peso por no cambian la estatura. Por otro lado, es difícil pensar en alguna intervención que cambie la estatura pero no cambie el peso de una persona. Adicionalmente, hay otros factores desconocidos no observados \\(U\\) que afectan el peso de cada persona adicionalmente a su estatura.\nAhora pasamos la modelo generativo. Supondremos que el peso de una persona adulta depende de su estatura de manera lineal, de forma que podemos escribir:\n\\[W = \\alpha + \\beta H + U\\] Como \\(U\\) no es observada, tenemos que definir cómo generar esta variable. Una distribución natural para esta variable es una distribución normal con media 0 y desviación estándar \\(\\sigma\\) no conocida, que escribimos como $UN(0,). Tenemos entonces que dados los valores \\(\\alpha\\) y \\(\\beta\\),\n\\[E[W|H] = \\alpha + \\beta H,\\] así que el valor esperado del peso de una persona, dada su estatura, es una función lineal de la estatura. La variable \\(U\\) representa la variabilidad en peso alrededor de este valor esperado. Usamos la distribución normal considerando que es una agregación de varias perturbaciones pequeñas, no relacionadas con estatura, que afectan el peso de una persona (aunque este supuesto también tiene que validarse).\nAdicionalmente, tenemos que hacer supuestos acerca del proceso generador para la estatura \\(H\\). Por el momento, y para ejemplificar, supondremos que la estatura es una variable normal con media en 160 cm y desviación estándar de 10cm.\nEmpezamos a escribir nuestro modelo generativo:\n\nsim_peso &lt;- function(n= 10, alpha, beta, sigma){\n  # simular estatura\n  H &lt;- rnorm(n, 160, 10)\n  # simular perturbación de peso\n  U &lt;- rnorm(n, 0, sigma)\n  # regresión lineal de peso dado estatura\n  W &lt;- alpha + beta * H + U\n  tibble(H, W)\n}\n\nPodemos checar nuestro modelo generativo con simulaciones predictivas a priori: generamos una muestra y checamos con el conocimiento del área:\n\nset.seed(9)\nsim_peso(100, alpha = 0, beta = 0.5, sigma = 5) |&gt; \n  ggplot(aes(x = H, y = W)) +\n  geom_point() +\n  labs(x = \"Estatura (cm)\", y = \"Peso (kg)\")\n\n\n\n\nPodemos escribir este generativo siguiendo el código de la función de arriba. Si cada persona la denotamos por un índice \\(i\\) entonces:\n\\[\n\\begin{align}\nW_i &= \\alpha + \\beta H_i + U_i \\\\\nU_i &\\sim N(0,\\sigma) \\\\\nH_i &\\sim N(160, 10)\n\\end{align}\n\\] De lado izquierdo están las variables, del lado derecho las definiciones, igualdad significa una relación determinística y \\(\\sim\\) significa “se distribuye como”.\nAhora podemos plantear nuestra pregunta inicial en términos de este modelo: nos interesa describir cómo cambia el peso esperado de una persona dependiendo de su estatura, es decir, describir la recta\n\\[ \\alpha + \\beta H\\] Con esto hemos terminado los primeros paso de nuestro flujo (modelo causal, modelo generativo, cantidad a estimar).\nNuestro método de estimación es bayesiano, así que podemos ser más específicos y decir que nos interesa la distribución posterior de \\(\\alpha,\\beta\\) dado datos observados. Otra manera de decir esto es que nos interesa describir la posterior de la recta \\(\\alpha + \\beta H\\).\nNótese en particular que en este ejemplo no nos interesa el proceso generador de \\(H\\), y dado nuestro diagrama causa, podemos considerar el análisis condicional a los valores que observamos de estatura.\nAhora podemos plantear nuestra estrategia de modelación estadística. Tenemos tres parámetros desconocidos \\(\\alpha,\\beta,\\sigma\\), y tenemos por la regla de bayes la posterior está dada por:\n\\[p(\\alpha,\\beta,\\sigma|W_i,H_i)\\propto p(W_i|H_i, \\alpha,\\beta,\\sigma)p(\\alpha,\\beta,\\sigma)\\] De modo que sólo nos interesa entender como es el peso condicional a la estatura, y por eso nuestra verosimilitud sólo considera \\(W_i\\) condicional a \\(H_i\\) (desde el punto de vista del diagrama, nos interesa modelar el nodo \\(W\\). En otros casos, quizá buscaríamos modelar la distribución conjunta de \\(W_i,H_i\\).\nAhora tenemos que poner distribuciones a priori \\(p(\\alpha, \\beta,\\sigma)\\) para los parámetros desconocidos, y continuar con nuestro flujo de modelación haciendo verificaciones a priori.\n\n\n\n\n\n\nDistribuciones a priori\n\n\n\nLa propuesta de distribuciones a priori depende de manera cercana de nuestras verificaciones a prior, como veremos más adelante. En general no existen distribuciones a priori “correctas”, sino justificables desde el punto de vista del conocimiento del área.\nLos chequeos a priori nos permite entender las consecuencias de nuestras decisiones acerca de las iniciales. Nótese que todo este trabajo se hace antes de ver los datos, lo que implica que no estamos buscando “sacar el resultado que queremos” de los datos. S\n\n\n\n4.2.1 Distribuciones a priori\nEn primer lugar, haremos este trabajo más fácil si parametrizamos la recta de regresión de la siguiente manera, donde restamos a la estatura un valor típico de la distribución de estaturas (también puede usarse la media los datos, más comunmente, pero en este ejemplo tomamos un valor fijo para simplificar la explicación):\n\\[E[W|H] =  \\alpha + \\beta (H - 160)\\]\nLas apriori o iniciales expresan conocimiento del área (incluyendo las unidades que se están utilizando), y actúan como restricciones suaves. Supondremos que peso está en kilogramos y estatura en centímetros.\n\nCuando \\(H=160\\) esperamos que \\(W\\) esté alrededor de 50-70 kg, así que podemos centrar \\(\\alpha\\) en 60. Las unidades de \\(\\alpha\\) son kg. Una inicial (verificaremos dentro de un momento esa decisión) puede ser \\(\\alpha\\sim N(60, 10)\\). Recordemos que esto implica que \\(\\alpha\\) están dentre 60 - 2(10) = 40 y 60 + 10(2) = 80 con probabilidad 0.95, lo cual es considerable pero no excesivamente amplio para una persona de estatura 160cm.\nSi \\(\\alpha\\) es está alrededor de 60, la constante de proporcionalidad \\(\\beta\\) debe ser positiva, y no muy lejana de un valor entre 0 y 2. La razón es que no tiene sentido esperar que un aumento de 10 kilos tenga un aumento esperado de peso de 20 kilos, por ejemplo. Podríamos poner una inicial como \\(\\beta\\sim N^+(0, 1)\\) (normal truncada en 0) por ejemplo. Esta distribución tiene los siguientes percentiles:\n\n\nquantile(rnorm(10000, 0, 1) |&gt; abs(), probs = seq(0, 1, 0.1)) |&gt; \n  round(3)\n\n   0%   10%   20%   30%   40%   50%   60%   70%   80%   90%  100% \n0.000 0.124 0.251 0.383 0.518 0.673 0.839 1.032 1.269 1.618 3.818 \n\n\nFinalmente, tenemos que poner una inicial para \\(\\sigma\\). Debe ser positiva, y representa la variabilidad que hay en el peso que no se debe a la estatura. Una inicial razonable es \\(\\sigma\\sim N^+(0, 20)\\), por ejemplo.\nQuedamos entonces con:\n\\[\n\\begin{align}\nW_i &= \\alpha + \\beta H_i + U_i \\\\\nU_i &\\sim N(0,\\sigma) \\\\\n\\alpha &\\sim N(60, 10) \\\\\n\\beta &\\sim N^+(0, 1) \\\\\n\\sigma &\\sim N^+(0, 20) \\\\\n\\end{align}\n\\]\n\n\nChequeo predictivo a priori\nAhora podemos simular de la a priori cuáles son las posibilidades que estamos considerando. Utilizaremos valores razonables simulados de \\(H\\) para hacer el análisis.\n\nsim_peso_mod &lt;- function(n= 10){\n  alpha &lt;- rnorm(1, 60, 10)\n  beta &lt;- rnorm(1, 0, 1) |&gt; abs()\n  sigma &lt;- rnorm(1, 0, 20) |&gt; abs()\n  \n  # simular estaturas y pesos\n  H &lt;- rnorm(n, 160, 10)\n  mu_W = alpha + beta * (H - 160)\n  # simular perturbación de peso\n  U &lt;- rnorm(n, 0, sigma)\n  # regresión lineal de peso dado estatura\n  W &lt;- mu_W + U\n  tibble(alpha, beta, sigma, H, W)\n}\n\nY hacemos varias replicaciones:\n\nsims_tbl &lt;- map_df(1:20, function(rep) {\n  sim_peso_mod(100) |&gt; mutate(rep = rep)\n})\n\nNuestros supuestos actuales se ven como sigue:\n\nsims_tbl |&gt; \n  ggplot(aes(x = H, y = W)) +\n  geom_point() +\n  geom_abline(aes(intercept = alpha - 160 * beta, slope = beta), data = sims_tbl, color = \"red\") +\n  labs(x = \"Estatura (cm)\", y = \"Peso (kg)\") +\n  facet_wrap(~rep)\n\n\n\n\nSimulaciones predictivas a priori\n\n\n\n\n**Observación*: Esto parece ser razonable, aunque algunas replicaciones son algo extremas (muy poca variabilidad de peso, una relación muy débil o. muy fuerte entre estatura y peso). Comenzaremos con este modelo y seguiremos explorando sus consecuencias.\nNótese que en esta situación, un punto de vista que aparentemente es “conservador” en efecto pone peso en resultados que son infactibles del todo. Por ejemplo, si pusiéramos \\(\\beta\\sim N^+(0,100)\\) y \\(\\sigma\\sim N^+(0, 1000)\\), bajo el argumento de que no tenemos información acerca de \\(\\beta\\) o \\(\\sigma\\), obtendríamos:\n\n\nCódigo\nsim_peso_mod_mal &lt;- function(n= 10){\n  alpha &lt;- rnorm(1, 60, 10)\n  beta &lt;- rnorm(1, 0, 100) |&gt; abs()\n  sigma &lt;- rnorm(1, 0, 1000) |&gt; abs()\n  \n  # simular estaturas y pesos\n  H &lt;- rnorm(n, 160, 10)\n  mu_W = alpha + beta * (H - 160)\n  # simular perturbación de peso\n  U &lt;- rnorm(n, 0, sigma)\n  # regresión lineal de peso dado estatura\n  W &lt;- mu_W + U\n  tibble(alpha, beta, sigma, H, W)\n}\nsims_tbl &lt;- map_df(1:20, function(rep) {\n  sim_peso_mod_mal(100) |&gt; mutate(rep = rep)\n})\nsims_tbl |&gt; \n  ggplot(aes(x = H, y = W)) +\n  geom_point() +\n  geom_abline(aes(intercept = alpha - 160 * beta, slope = beta), data = sims_tbl, color = \"red\") +\n  labs(x = \"Estatura (cm)\", y = \"Peso (kg)\") +\n  facet_wrap(~rep)\n\n\n\n\n\nModelo no realista\n\n\n\n\nEsta es una prueba inicial fallida. Regresaremos a este ejemplo más adelante. En este ejemplo particular que es muy simple y como veremos no es grave permitir algunos resultados algo extremos.\n\n\n\n\n\n\nTip\n\n\n\nEs riesgoso permitir valores de las apriori que no son consistentes con el conocimiento del área. Cuando tenemos muchos datos y relativamente pocos parámetros no es muy importante, pero conforme vayamos avanzando veremos que utilizar supuestos no realistas (como distribuiciones no informativas para los parámetros) tiene consecuencias considerables.\n\n\n\n\nModelo en Stan\nAunque en este punto es posible todavía hacer una aproximación por rejilla (sólo tenemos tres parámetros), escribiremos el modelo en Stan y simularemos de la posterior con MCMC (recuerda que más tarde explicaremos este proceso).\n\nNuestro objetivo ahora es calcular la posterior bajo los supuestos de arriba para datos generados de nuestro modelo, y ver si los cálculos funcionan apropiadamente.\n\nEl modelo en Stan se puede escribir como sigue:\n\nlibrary(cmdstanr)\nmod_peso &lt;- cmdstan_model(\"./src/peso-estatura-1.stan\")\nprint(mod_peso)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  h;\n  vector[N]  w;\n}\n\nparameters {\n  real alpha;\n  real &lt;lower=0&gt; beta;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  vector[N] w_media;\n  // determinístico dado parámetros\n  w_media = alpha + beta * (h - 160);\n}\n\nmodel {\n  // partes no determinísticas\n  w ~ normal(w_media, sigma);\n  alpha ~ normal(60, 10);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 20);\n}\n\n\nUna vez que escribimos nuestro modelo, hacemos nuestra siguiente verificación a priori: dados los supuestos del modelo generativo, ¿nuestro estimador funciona apropiadamente para responder la pregunta de interés?\nUtilizaremos una muestra de 350 personas simulada de nuestro proceso generador de datos. En cada caso, buscamos correr nuestro modelo y checar que nuestra estimación de la recta de regresión es consistente con los valores que utilizamos para generar los datos.\n\nset.seed(881)\nsims_inicial_check_tbl &lt;- map_df(1:10, function(rep) {\n  sim_peso_mod(352) |&gt; mutate(rep = rep)\n}) |&gt; nest(datos_sim = c(H, W))\nsims_tbl\n\n# A tibble: 2,000 × 6\n   alpha  beta sigma     H      W   rep\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;\n 1  65.4  129. 2466.  149. -3240.     1\n 2  65.4  129. 2466.  168.  1084.     1\n 3  65.4  129. 2466.  178.  -624.     1\n 4  65.4  129. 2466.  155. -2217.     1\n 5  65.4  129. 2466.  167. -1553.     1\n 6  65.4  129. 2466.  160.  -959.     1\n 7  65.4  129. 2466.  162. -6882.     1\n 8  65.4  129. 2466.  156.  2700.     1\n 9  65.4  129. 2466.  145.  2422.     1\n10  65.4  129. 2466.  161. -1013.     1\n# ℹ 1,990 more rows\n\n\nEn la siguiente gráfica vemos un comportamiento razonable de nuestro proceso de estimación. Recuerda que cada punto negro representa una simulación de la posterior, y el punto rojo es el valor que usamos para hacer la simulación de cada recuadro:\nOjo: los ejes de los recuadros varían con la simulación\n\n# fig-cap: Posterior para datos simulados\ndatos_check_tbl &lt;- sims_inicial_check_tbl |&gt; \n  select(rep, post_tbl) |&gt; \n  unnest(post_tbl)\nggplot(datos_check_tbl, aes(x = alpha, y = beta)) +\n  geom_point(alpha = 0.2) +\n  labs(x = \"alpha\", y = \"beta\") +\n  geom_point(data = sims_inicial_check_tbl, color = \"red\", size = 3) +\n  facet_wrap(~ rep, scales = \"free\") \n\n\n\n\nEsta gráfica también podemos hacerla como sigue, usando rectas:\n\n# nota: el intercept en geom_abline es la ordenada al origen\n# mientras que la alpha es valor de la recta para h = 160\ndatos_check_tbl |&gt; \n  ggplot() +\n  geom_abline(aes(intercept = alpha - beta * 160, slope = beta),\n              alpha = 0.5, colour = \"gray\") +\n  facet_wrap(~ rep, scales = \"free\") +\n  scale_x_continuous(limits = c(130, 200)) + \n  scale_y_continuous(limits = c(0, 200)) +\n  geom_abline(data = sims_inicial_check_tbl, \n    aes(intercept = alpha - beta * 160, \n      slope = beta), color = \"red\", linewidth = 1.05)\n\n\n\n\nEsta prueba computacional tiene buenos resultados: en general, la posterior se concentra alrededor del valor verdadero de cada simulación. Ahora podemos proceder a cargar los datos reales y hacer una simulación de la posterior.\n\n\n4.2.2 Ajustando el modelo a los datos reales\nCargamos los datos y producimos simulaciones de la posterior.\n\nset.seed(81)\ndatos_tbl &lt;- read_delim(\"../datos/Howell1.csv\", delim = \";\") |&gt; \n  filter(age &gt;= 18)\n\nRows: 544 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (4): height, weight, age, male\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndata_list &lt;- list(\n  N = nrow(datos_tbl),\n  h = datos_tbl$height,\n  w = datos_tbl$weight\n)\n# correr modelo en Stan\nmod_peso_ajuste &lt;- mod_peso$sample(\n  data = data_list,\n  iter_sampling = 2000,\n  refresh = 0)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.4 seconds.\nChain 3 finished in 0.4 seconds.\nChain 4 finished in 0.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 1.7 seconds.\n\n\nLa posterior de los parámetros de la recta se ve como siguen:\n\nsims_peso_post_tbl &lt;- mod_peso_ajuste |&gt; \n  as_draws_df() |&gt; \n  select(.draw, alpha, beta, sigma) \n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n\nggplot(sims_peso_post_tbl)+\n  geom_point(aes(x = alpha, y = beta)) \n\n\n\n\nY un resumen simple está dado por:\n\nmod_peso_ajuste$summary(c(\"alpha\", \"beta\", \"sigma\")) |&gt; \n  mutate(across(where(is.numeric),  ~ round(.x, 2)))\n\n# A tibble: 3 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 alpha    48.4   48.4   0.28  0.28 47.9  48.8      1    4900.    5333.\n2 beta      0.63   0.63  0.03  0.03  0.58  0.68     1    4700.    5066.\n3 sigma     4.26   4.25  0.16  0.16  4     4.53     1    5690.    5133.\n\n\n\n\n\n\n\n\nSimulaciones conjuntas\n\n\n\nObserva que los resúmenes marginales (variable por variable) no cuentan la historia completa de la posterior. En nuestro ejemplo, \\(\\alpha\\) y \\(\\beta\\) están correlacionadas en la posterior como muestra la gráfica anterior. Por eso cuando queremos calcular resúmenes de cantidades en las que influyen varios parámetros, es importante trabajar con las simulaciones conjuntas de los parámetros.\n\n\nPuedes ver que en realidad no es posible calcular la distribución de cantidades como \\(\\alpha + 10\\beta\\), por ejemplo, a partir de la información de la tabla de arriba: por ejemplo, la varianza de esta suma no es simplemente la suma de las varianzas"
  },
  {
    "objectID": "03-modelos-genericos.html#distribución-predictiva-posterior",
    "href": "03-modelos-genericos.html#distribución-predictiva-posterior",
    "title": "4  Componentes básicas de modelación 1",
    "section": "4.3 Distribución predictiva posterior",
    "text": "4.3 Distribución predictiva posterior\nDado nuestro modelo, ahora podemos generar cómo se verían observaciones nuevas: en este caso, si tuviéramos una estatura, ¿cómo sería el peso de esa persona? Para esto tenemos que tener en cuenta tanto la posterior de los parámetros como el modelo de los datos.\nEn primer lugar, la posterior de la relación lineal es (cada línea de esta gráfica es una simulación de la posterior):\n\nggplot(sims_peso_post_tbl) +\n  geom_abline(aes(intercept = alpha - beta * 160, slope = beta),\n              colour = \"gray\", alpha = 0.1) +\n  scale_x_continuous(limits = c(130, 180)) +\n  scale_y_continuous(limits = c(20, 70)) \n\n\n\n\nEsto nos indican los valores esperados para estatura. Para la predictiva posterior, también tenemos que considerar dónde pueden aparecer individuos. Para simular a una estatura fija, por ejemplo, hacemos lo sugiente:\n\nsim_pred_post &lt;- function(n, sims_peso_post_tbl, h) {\n  # extraer parámetros de la posterior\n  pars &lt;- slice_sample(sims_peso_post_tbl, n = n, replace = TRUE) \n  # simular pesos\n  sims_tbl &lt;- map_df(h, function(h){\n    w_media &lt;- pars$alpha + pars$beta * (h - 160)\n    w &lt;- rnorm(n, w_media, pars$sigma)\n    tibble(rep = 1:n, h = h, w_media = w_media, w = w)\n  })\n  sims_tbl\n}\n\nLas predictivas posteriores para las estaturas \\(h = 160\\) y \\(h=150\\) son:\n\ncomp_ppost_tbl &lt;- sim_pred_post(5000, sims_peso_post_tbl, c(150, 160))\nggplot(comp_ppost_tbl, aes(x =  w, fill = factor(h))) +\n  geom_histogram(bins = 50, alpha = 0.5, position = \"identity\") \n\n\n\n\nque como vemos presentan variabilidad considerable más allá de la diferencia de valores esperados. Podemos calcular por ejemplo cuál es la probabilidad de que una persona de 150 cm sea más alta que una de 170 cm:\n\ncomp_ppost_tbl |&gt; \n  select(-w_media) |&gt; \n  pivot_wider(names_from = h, values_from = w) |&gt; \n  summarise(prop = mean(`150` &gt; `160`))\n\n# A tibble: 1 × 1\n   prop\n  &lt;dbl&gt;\n1 0.143\n\n\nY también es más útil calcular la distribución de la diferencia de pesos entre personas de 150 y 160 cm:\n\ncomp_ppost_tbl |&gt; \n  select(-w_media) |&gt; \n  pivot_wider(names_from = h, values_from = w) |&gt; \n  mutate(diferencia = `160` - `150`) |&gt; \nggplot(aes(x = diferencia)) +\n  geom_histogram(bins = 50, alpha = 0.5, position = \"identity\") +\n  labs(x = \"Diferencia de pesos 160 - 150cm\")\n\n\n\n\nEn contraste, si comparamos las estaturas medias de cada grupo, que no incluyen variabilidad individual más allá de la producida por la estatura:\n\nggplot(comp_ppost_tbl, aes(x =  w_media, fill = factor(h))) +\n  geom_histogram(bins = 100, alpha = 0.5, position = \"identity\") +\n  labs(x = \"Media de pesos\")\n\n\n\n\nPrácticamente tenemos seguridad que la media de pesos de los individuos de 150 cm es menor que la de los de 160 cm.\n\n\n\n\n\n\nTip\n\n\n\nEs importante no confundir el contraste a nivel individuo que hicimos arriba, y el que hicimos a nivel de medias de grupos. Los grupos tienen claramente medias diferentes, pero las distribuciones de individuos tienen traslape considerable.\n\n\nPodemos también resumir la distribución predictiva para distintas estaturas:\n\nresumen_ppost_tbl &lt;- sim_pred_post(20000, sims_peso_post_tbl, \n                                   h = seq(130, 180, 2.5)) |&gt; \n  group_by(h) |&gt; \n  summarise(q5 = quantile(w, 0.05), \n            q95 = quantile(w, 0.95),\n            q_media_5 = quantile(w_media, 0.05),\n            q_media_95 = quantile(w_media, 0.95)) \n\nEn nuestra gráfica anterior tendríamos entonces nuestra recta junto con rangos de 90% para la estatura de los individuos:\n\nggplot(sims_peso_post_tbl) +\n  geom_abline(aes(intercept = alpha - beta * 160, slope = beta),\n              colour = \"gray\", alpha = 0.01) +\n  scale_x_continuous(limits = c(130, 180)) +\n  scale_y_continuous(limits = c(10, 80)) + \n  geom_ribbon(data = resumen_ppost_tbl,\n    aes(x = h, ymin = q_media_5, ymax = q_media_95),\n      fill = NA, colour = \"gray\") + \n  geom_ribbon(data = resumen_ppost_tbl,\n    aes(x = h, ymin = q5, ymax = q95), fill = NA, colour = \"red\")\n\n\n\n\n\n4.3.1 Verificaciones de predictiva posterior\nAdemás de ser útil para calcular cantidades de interés de manera natural, la predictiva posterior también está sujeta a crítica y validación. Veremos más de este punto, pero la idea básica es la siguiente:\n\n\n\n\n\n\nVerificaciones de predictiva posterior\n\n\n\nUna vez que tenemos la posterior dados los datos:\n\nTomamos una simulación de todos los parámetros del modelo.\nSimulamos nuevas observaciones (una muestra del mismo tamaño) a partir de los parámetros simulados.\nComparamos los datos simulados con los datos observados (gráficas u otros resúmenes apropiados).\nRepetimos para varias simulaciones.\n\nDiferencias sistemáticas entre datos observados y datos simulados de la predictiva posterior indican fallas del modelo o áreas donde puede mejorar.\n\n\nHay muchas variaciones de este tipo de verificaciones. En nuestro caso podemos hacer manualmente este proceso una vez que tenemos simulaciones de la posterior, tomando las mismas estaturas de los datos y simulando datos del modelo para el peso.\n\nsims_check_post &lt;- sim_pred_post(10, sims_peso_post_tbl, \n                                 h = datos_tbl$height) |&gt; \n  select(-w_media)\nsims_check_post &lt;- bind_rows(sims_check_post, \n   datos_tbl |&gt; mutate(rep = 11) |&gt; select(rep, h = height, w = weight)) |&gt; \n  mutate(rep = digest::digest2int(as.character(rep), seed = 992)) \nggplot(sims_check_post) +\n  geom_point(aes(x = h, y = w), alpha = 0.2) + facet_wrap(~ rep)\n\n\n\n\n¿Puedes reconocer dónde están los datos? Si hay desajustes graves y sistemáticas, deberías poder detectarlos en una gráfica de este tipo. Veremos más de este tipo de verificaciones en el curso.\n\n# Respuesta\ndigest::digest2int(\"11\", seed = 992)"
  },
  {
    "objectID": "03-modelos-genericos.html#ampliando-el-modelo",
    "href": "03-modelos-genericos.html#ampliando-el-modelo",
    "title": "4  Componentes básicas de modelación 1",
    "section": "4.4 Ampliando el modelo",
    "text": "4.4 Ampliando el modelo\nEntre los adultos humanos, hombres y mujeres tienen distintas distribuciones de peso y estatura. La variable \\(S\\) (sexo) influye tanto en estatura como en peso. La relación la consideramos causalmente partiendo en \\(S\\):\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    U\n    V\n    Z\n  node [shape=plaintext]\n    H\n    W\n    S\n  edge [minlen = 3]\n    H -&gt; W\n    U -&gt; W\n    S -&gt; H\n    S -&gt; W\n    V -&gt; H\n    Z -&gt; S\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nOmitiendo del diagrama las variables no observadas que también son causas únicamente de \\(S\\) y \\(W, H\\):\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n  \n  node [shape=plaintext]\n    H\n    W\n    S\n  edge [minlen = 3]\n    H -&gt; W\n    S -&gt; H\n    S -&gt; W\n\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nSi queremos saber cómo influye el sexo en el peso, este diagrama indica que hay dos tipos de preguntas que podemos hacer:\n\n¿Cuál es el efecto causal de \\(S\\) sobre \\(W\\) (efecto total) ?\n¿Cuál es el efecto causal directo de \\(S\\) sobre \\(W\\)? Es decir, que no actúa a través de \\(H\\).\n\nAunque tenemos un solo modelo causal, pueden construirse distintos modelos estadísticos para contestar cada pregunta. El modelo causal nos dice que si no tenemos causas comunes de \\(S\\) y \\(H\\) y \\(W\\), entonces podemos estimar el efecto total de \\(S\\) sobre \\(W\\) (esto lo formalizaremos más adelante).\nEmpezamos con el efecto total. Para esto, podemos usar el modelo lineal e ignorar la estatura, donde \\(S_i=2\\) si el individuo \\(i\\) es hombre y \\(S_i=1\\) si el individuo \\(i\\) es mujer.\n\\[\n\\begin{align}\nW_i &\\sim N(\\alpha_{S_i}, \\sigma)\\\\\n\\alpha_1,\\alpha_2 &\\sim N(60, 10) \\\\\n\\sigma &\\sim N^+(0, 20) \\\\\n\\end{align}\n\\] Nótese que tenemos dos posibles medias para el peso, una para hombres y otra para mujeres. La estatura no nos importa porque la pregunta es acerca del efecto total de sexo sobre estatura. Para las iniciales podemos seguir un argumento similar al de arriba.\nNota: esta parametrización es más conveniente que utilizar un indicador (o dummy) de sexo en términos de interpetación y en términos de poner iniciales acordes con el conocimiento del área, aunque estadísticamente son equivalentes.\nEl modelo generador simplificado para este caso puede ser:\n\nsim_peso_mod_s &lt;- function(S, alpha, sigma){\n  n &lt;- length(S)\n  W &lt;- rnorm(n, alpha[S], sigma)\n  tibble(alpha_1 = alpha[1], alpha_2 = alpha[2], \n         sigma, S = S, W = W)\n}\n\nDado este modelo generador, ¿cuál es el efecto causal de sexo? Tenemos que definir esta cantidad en términos del modelo. En nuestro caso, definiremos el efecto causal promedio sobre la población, que definimos como la diferencia promedio de estaturas de dos poblaciones: una compuesta enteramente por hombres y otra por mujeres.\n\nset.seed(2021)\n# Fjamos mismos valores de los parámetros para simular dos\n# poblaciones\nsim_hombres &lt;-  sim_peso_mod_s(rep(2, 1000), c(55, 70), 10)\nsim_mujeres &lt;-  sim_peso_mod_s(rep(1, 1000), c(55, 70), 10)\nmean(sim_hombres$W - sim_mujeres$W)\n\n[1] 14.75203\n\n\n\nVerificación a priori\nAhora generamos una población con estos parámetros y vemos si podemos recuperar el efecto causal promedio sobre la población. Nuestro modelo es como definimos arriba:\n\nlibrary(cmdstanr)\nmod_peso &lt;- cmdstan_model(\"./src/peso-estatura-2.stan\")\nprint(mod_peso)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  w;\n  array[N] int s;\n}\n\nparameters {\n  array[2] real alpha;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n\n}\n\nmodel {\n  // modelo para peso\n  w ~ normal(alpha[s], sigma);\n  // también se puede escribir como\n  // for (i in 1:N) {\n  //   w[i] ~ normal(alpha[s[i]], sigma);\n  // }\n  // iniciales\n  alpha ~ normal(60, 10);\n  sigma ~ normal(0, 20);\n}\n\n\nSimulamos datos y ajustamos el modelo, usando los mismos parámetros fijos:\n\nS_sim &lt;- sample(c(1,2), 1000, replace = TRUE)\ndatos_sim_tbl &lt;- sim_peso_mod_s(S_sim, c(55, 70), 10)\n\n\nmod_2_fit &lt;- mod_peso$sample(\n  data = list(N = nrow(datos_sim_tbl), \n              s = datos_sim_tbl$S, \n              w = datos_sim_tbl$W),\n  refresh = 0, seed = 221\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.7 seconds.\n\n\n\nmod_2_fit$summary(c(\"alpha\", \"sigma\"))\n\n# A tibble: 3 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 alpha[1] 55.0   55.0  0.435 0.429 54.2   55.7  1.00    4611.    2866.\n2 alpha[2] 70.9   70.9  0.435 0.444 70.2   71.6  1.00    4350.    2891.\n3 sigma     9.77   9.76 0.223 0.227  9.41  10.1  1.00    4210.    3013.\n\n\nNótese que la diferencia de medias poblacionales es de alrededor de 15 cm, que es lo que esperábamos según el cálculo de arriba. Podemos replicar el cálculo que hicimos arriba directamente usando simulación:\n\nPara cada simulación de la posterior calculamos una población hipotética de hombres y otras de mujeres (mismos parámetros)\nCalculamos la diferencia de medias poblacionales\nResumimos con la posterior.\n\nEsto es fácil hacerlo directamente en Stan, pero en este ejemplo lo calcularemos manualmente:\n\nsims_post_tbl &lt;- mod_2_fit$draws() |&gt; as_draws_df() |&gt; \n  as_tibble()\nsimular_diferencia_post &lt;- function(sims_post_tbl){\n  pars &lt;- sample_n(sims_post_tbl, 1) |&gt; \n    select(starts_with(\"alpha\"), sigma)\n  # Simulamos datos\n  sims_hombres &lt;- sim_peso_mod_s(rep(2, 1000), \n      alpha = c(pars$`alpha[1]`, pars$`alpha[2]`), pars$sigma)\n  sims_mujeres &lt;- sim_peso_mod_s(rep(1, 1000), \n      c(pars$`alpha[1]`, pars$`alpha[2]`), pars$sigma)\n  diferencia &lt;- mean(sims_hombres$W - sims_mujeres$W)\n  # Calculamos la diferencia de medias\n  tibble(diferencia = diferencia) |&gt; bind_cols(pars)\n}\n\n\nsimular_diferencia_post(sims_post_tbl)\n\n# A tibble: 1 × 4\n  diferencia `alpha[1]` `alpha[2]` sigma\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1       15.3       55.5       70.4  9.60\n\n\nY ahora calculamos el resumen de interés, que es la posterior del contraste o diferencia entre las dos poblaciones simuladas. Comparamos con la línea en rojo que es la cantidad que establecimos a estimar:\n\nmap_df(1:4000, ~ simular_diferencia_post(sims_post_tbl) |&gt; \n         mutate(rep = .x)) |&gt;  \nggplot(aes(x = diferencia)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"Efecto de sexo en estatura hombres vs mujeres (cm)\") +\n  geom_vline(xintercept = mean(sim_hombres$W - sim_mujeres$W), \n             color = \"red\", linewidth = 1.5)\n\n\n\n\nPuedes repetir este ejercicio para distintos valores de los parámetros, como hicimos en los ejemplos de arriba."
  },
  {
    "objectID": "03-modelos-genericos.html#ajustar-a-los-datos-observados-y-resumir",
    "href": "03-modelos-genericos.html#ajustar-a-los-datos-observados-y-resumir",
    "title": "4  Componentes básicas de modelación 1",
    "section": "4.5 Ajustar a los datos observados y resumir",
    "text": "4.5 Ajustar a los datos observados y resumir\nAhora usamos los datos reales y calculamos el estimador que probamos arriba.\n\nmod_2_fit &lt;- mod_peso$sample(\n  data = list(N = nrow(datos_tbl), \n              s = datos_tbl$male + 1, \n              w = datos_tbl$weight),\n  refresh = 0, seed = 221\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.5 seconds.\n\n\nY repetimos exactamente el proceso que probamos arriba:\n\nsims_post_tbl &lt;- mod_2_fit$draws() |&gt; as_draws_df() |&gt; \n  as_tibble()\ndif_tbl &lt;- map_df(1:4000, ~ simular_diferencia_post(sims_post_tbl) |&gt; \n         mutate(rep = .x)) \ndif_tbl |&gt; \nggplot(aes(x = diferencia)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"Efecto de sexo en peso hombres vs mujeres (kg)\") \n\n\n\n\nConcluimos que el efecto total de sexo sobre peso está entre unos 5.5 y 8 kg de diferencia de hombres vs mujeres.\nEjercicio: explica porqué mostrar por separado las distribuciones de poblaciones de hombres vs la de poblaciones de mujeres no da la respuesta que buscamos."
  },
  {
    "objectID": "03-modelos-genericos.html#efecto-directo-de-sexo",
    "href": "03-modelos-genericos.html#efecto-directo-de-sexo",
    "title": "4  Componentes básicas de modelación 1",
    "section": "4.6 Efecto directo de sexo",
    "text": "4.6 Efecto directo de sexo\nAhora pensemos cómo podemos calcular el efecto directo de sexo sobre peso, sin tomar en cuente su influencia en la estatura. En nuestro diagrama, nos interesa sólo considerar la influencia que va directamente de sexo a peso, y no la que pasa por el camino que va a través de la estatura. Este tipo de análisis se llama a veces análisis de mediación.\nLa idea es bloquear el camino que va de sexo a estatura, y esto podemos hacer condicionando o estratificando por los valores de \\(H\\). Es decir, para cada valor de \\(H\\), queremos calcular cuál es la diferencia entre una población de hombres y de mujeres (con la misma estatura \\(H\\)). Las diferencias que encontremos no puede deberse a estatura, pues esta valor es fijo. Al estratificar por \\(H\\), decimos que el camino \\(S\\to H\\to W\\) está bloqueado, y refinaremos esta idea más adelante.\nEn términos de cantidad a estimar, quisiéramos, para cada estatura \\(H\\), calcular la diferencia de una población de hombres vs una de mujeres. La diferencia es el efecto directo a la estatura \\(H\\).\nEl modelo estadístico que proponemos para estimar el efecto directo es entonces:\n\\[\n\\begin{align}\nW_i &\\sim N(\\mu_i, \\sigma)\\\\\n\\mu_i &= \\alpha_{S_i} + \\beta_{S_i} (H_i - \\bar{H})\\\\\n\\alpha_1,\\alpha_2 &\\sim N(60, 10) \\\\\n\\beta_1,\\beta_2 &\\sim N^+(0, 1) \\\\\n\\sigma &\\sim N^+(0, 20) \\\\\n\\end{align}\n\\]\nEl contraste que queremos calcular lo podemos identificar con parámetros en el modelo. Por ejemplo, si \\(\\beta_1 = \\beta_2\\), el efecto directo, para cualquier estatura, debería ser \\(\\alpha_2 - \\alpha_1\\). Sin embargo, seguimos con nuestro camino de hacer simulación para mantener más flexibilidad y simplicidad.\nEjercicio: Haz verificaciones a priori: genera datos sintéticos, examínalos, y verifica que el modelo es capaz de recuperar el contraste de interés.\n\n4.6.1 Ajuste a datos reales y resumen\n\nmod_peso_2 &lt;- cmdstan_model(\"./src/peso-estatura-3.stan\")\nprint(mod_peso_2)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  w;\n  vector[N]  h;\n  array[N] int s;\n}\n\ntransformed data {\n  real h_media;\n  h_media = mean(h);\n}\n\nparameters {\n  array[2] real alpha;\n  array[2] real&lt;lower=0&gt; beta;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  array[N] real mu;\n  for (i in 1:N) {\n    mu[i] = alpha[s[i]] + beta[s[i]] * (h[i] - h_media);\n  }\n}\n\nmodel {\n  // modelo para peso\n  w ~ normal(mu, sigma);\n  // también se puede escribir:\n  //for (i in 1:N) {\n  //  w[i] ~ normal(mu[i], sigma);\n  //}\n  alpha ~ normal(60, 10);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 20);\n}\n\ngenerated quantities {\n\n}\n\n\n\nmod_3_fit &lt;- mod_peso_2$sample(\n  data = list(N = nrow(datos_tbl), \n              s = datos_tbl$male + 1, \n              h = datos_tbl$height,\n              w = datos_tbl$weight),\n  init = 0.01, step_size = 0.01, refresh = 0, seed = 221\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.3 seconds.\nChain 2 finished in 0.3 seconds.\nChain 3 finished in 0.3 seconds.\nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 1.3 seconds.\n\n\n\nmod_3_fit$summary(c(\"alpha\", \"beta\", \"sigma\")) |&gt; \n  knitr::kable(digits = 2)\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nalpha[1]\n45.17\n45.17\n0.45\n0.45\n44.45\n45.91\n1\n2270.19\n2455.26\n\n\nalpha[2]\n45.09\n45.10\n0.47\n0.45\n44.31\n45.83\n1\n2822.98\n2524.93\n\n\nbeta[1]\n0.66\n0.66\n0.06\n0.06\n0.55\n0.76\n1\n2109.75\n2083.05\n\n\nbeta[2]\n0.61\n0.61\n0.06\n0.06\n0.52\n0.70\n1\n2737.57\n2646.95\n\n\nsigma\n4.27\n4.26\n0.16\n0.16\n4.02\n4.55\n1\n4090.86\n2699.93\n\n\n\n\n\n\n\nLa diferencia entre las dos rectas parece ser chica. Eso implicaría que el efecto directo de sexo en peso es débil. Sin embargo, es mejor calcular y resumir el contraste como hemos hecho en otros ejemplos.\nRepetimos exactamente el proceso que probamos arriba. Haremos los cálculos manualmente otra vez (aunque conviene más hacerlos dentro de stan):\n\nsims_post_tbl &lt;- mod_3_fit$draws() |&gt; as_draws_df() |&gt; \n  as_tibble()\nh_media &lt;- mean(datos_tbl$height)\n# función para simular pesos\nsim_peso_mod_sh &lt;- function(S, H, alpha, beta, sigma, h_media){\n  n &lt;- length(S)\n  W &lt;- rnorm(n, alpha[S] + beta[S] * (H - h_media), sigma)\n  tibble(W = W)\n}\nsimular_diferencia_post_2 &lt;- function(sims_post_tbl, h){\n  pars &lt;- sample_n(sims_post_tbl, 1) |&gt; \n    select(starts_with(c(\"alpha\", \"beta\")), sigma)\n  alpha &lt;- c(pars$`alpha[1]`, pars$`alpha[2]`)\n  beta &lt;- c(pars$`beta[1]`, pars$`beta[2]`)\n  diferencia &lt;- numeric(length(h))\n  # para cada nivel de estatura especificado\n  for(i in seq_along(h)){\n    # Simulamos poblaciones\n    sims_hombres &lt;- sim_peso_mod_sh(rep(2, 1000), h[i],\n      alpha = alpha, beta = beta, pars$sigma, h_media = h_media)\n    sims_mujeres &lt;- sim_peso_mod_sh(rep(1, 1000), h[i],\n      alpha = alpha, beta = beta, pars$sigma, h_media = h_media)\n    diferencia[i] &lt;- mean(sims_hombres$W - sims_mujeres$W)\n  }\n  tibble(diferencia = diferencia, h = h) |&gt; bind_cols(pars)\n}\n\nPor ejemplo:\n\nsimular_diferencia_post_2(sims_post_tbl, h = c(150, 170))\n\n# A tibble: 2 × 7\n  diferencia     h `alpha[1]` `alpha[2]` `beta[1]` `beta[2]` sigma\n       &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1      1.38    150       45.2       45.9     0.610     0.502  4.25\n2     -0.836   170       45.2       45.9     0.610     0.502  4.25\n\n\n\nh &lt;- seq(130, 190, by = 5)\ndif_tbl &lt;- map_df(1:1000, \n    ~ simular_diferencia_post_2(sims_post_tbl, h) |&gt; \n         mutate(rep = .x))\n\n\ndif_tbl |&gt; \nggplot(aes(x = h, y = diferencia, group = rep)) +\n  geom_line(alpha = 0.1) +\n  labs(x = \"Contraste de peso hombres vs mujeres (kg)\") +\n  geom_hline(yintercept = 0, colour = \"red\") \n\n\n\n\nEsto muestra que el efecto directo de sexo en peso es relativamente chico: la mayor parte del efecto es a través de la estatura. Existe una ligera tendencia a que los hombre de menos estatura sean más pesados, y las mujeres de más estatura sean relativamente menos pesadas, pero realmente no podemos afirmar con confianza ningún efecto claro."
  },
  {
    "objectID": "03-modelos-genericos.html#regresión-logística-tiros-de-golf",
    "href": "03-modelos-genericos.html#regresión-logística-tiros-de-golf",
    "title": "4  Componentes básicas de modelación 1",
    "section": "4.7 Regresión logística: tiros de golf",
    "text": "4.7 Regresión logística: tiros de golf\nEste caso está basado en Gelman and Nolan (2002) y Gelman (n.d.). Usamos el flujo de trabajo bayesiano tomado del documento de Michael Betancourt Betancourt (2020).\nQueremos entender modelar la probabilidad de éxito de putts de Golf (putts: tiros relativamente cerca del hoyo que buscan que la pelota ruede al hoyo o muy cerca de él), y cómo depende el éxito de la distancia del tiro. Quisiéramos inferir qué tan precisos son los profesionales en sus tiros.\nEn este caso, el modelo conceptual es simple \\(D-&gt;Y\\), donde \\(D\\) es la distancia del tiro y \\(Y\\) es el resultado del tiro (1 si es exitoso, 0 si no). Nótese que no escribiríamos \\(Y-&gt;D\\), porque cambiar la distancia del tiro si cambia las probabilidades de éxito, pero no a la inversa.\nNuestro interés principal es modelar cómo cambia la probabilidad de éxito de un tiro (para profesionales) con la distancia al hoyo. Si tomamos un punto de vista de modelos genéricos, podríamos proponer regresión logística:\n\\(p(Y = 1| D = d) = \\frac{1}{1 + \\exp(-\\alpha - \\beta d)}\\)\nY nuestra cantidad a estimar es la curva \\(p(Y=1|D=d)\\), que es una función de \\(d\\). Esto lo haremos estimando los parámetros \\(\\alpha\\) y \\(beta\\).\nAhora construimos un modelo generativo, donde \\(D\\) está dada en centímetros:\n\nsimular_putts &lt;- function(distancias, alpha, beta) {\n  p &lt;- 1 / (1 + exp(-alpha - beta * distancias))\n  tibble(y = rbinom(length(distancias), 1, p), d = distancias) |&gt; \n    select(d, y)\n}\n\nFijamos parámetros y simulamos datos:\n\nset.seed(22)\ndistancias &lt;- seq(0, 1000, 5) |&gt; rep(each = 5)\nsimular_putts(distancias, 3, -0.005) |&gt; \n  ggplot(aes(x = d, y = y)) +\n  geom_jitter(height = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Éxito\") +\n  geom_smooth(span = 0.5)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nNótese que para este ejemplo utilizamos valores de \\(\\alpha\\) y \\(\\beta\\) fijos. Podríamos poner valores imposibles para golfistas profesionales, por ejemplo:\n\nset.seed(22)\ndistancias &lt;- seq(0, 1000, 5) |&gt; rep(each = 5)\nsimular_putts(distancias, 10, -1) |&gt; \n  ggplot(aes(x = d, y = y)) +\n  geom_jitter(height = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Éxito\") +\n  geom_smooth(span = 0.5)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nEsta configuración de parámetros no es razonable, pues implicaría que sólo pueden completar los tiros a unos cuantos centímetros del hoyo. Sabemos que esto no es cierto.\nPara completar nuestro modelo generativo, es necesario especificar los valores que pueden tomar estas variables, y entonces podremos ver cómo se comporta nuestra cantidad a estimar.\nPondremos distribuciones iniciales o a priori para los parámetros. En este punto no hemos visto ningún dato, así que podemos experimentar para hacer una selección apropiada desde el punto de vista del conocimiento del área que tenemos actualmente.\nPodemos poner por ejemplo \\[\\alpha \\sim \\text{Normal}(5, 2),\\] pues sabemos a que distancias de casi cero, es muy seguro lograr el tiro (no lejos de 100% de éxito). Para la \\(\\beta\\), consideramos que a unos 100 cm es muy probable hacer el tiro, pero a 1000 cm (10 m) la probabilidad baja considerablemente. Experimentaremos poniendo (debe ser negativa)\n\\[\\beta \\sim \\text{Normal}^-(0, 0.02).\\]\ny ahora reescribimos nuestra función de simulación:\n\nsimular_putts &lt;- function(distancias) {\n  alpha &lt;- rnorm(1, 5, 2)\n  beta &lt;-  - abs(rnorm(1, 0, 0.015))\n  p &lt;- 1 / (1 + exp(-alpha - beta * distancias))\n  tibble(y = rbinom(length(distancias), 1, p), p = p, d = distancias) |&gt; \n    select(d, p, y) |&gt; \n    mutate(alpha = alpha, beta = beta)\n}\n\nY podemos ver cómo se ven diversas curvas que incluye nuestro modelo:\n\ndistancias &lt;- seq(0, 3000, 1) \nmap_df(1:100,  \\(x) simular_putts(distancias) |&gt; mutate(id = x)) |&gt; \n  ggplot(aes(x = d, y = p, group = id)) +\n  geom_line(alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\")\n\n\n\n\nLos casos extremos son poco creíbles (0 probabilidad a 5 metros o 100% de probabilidad a 20 metros), pero el grueso de las curvas son razonables. Podemos ver la curva promedio:\n\nreps_sim &lt;- map_df(1:1000,  \\(x) simular_putts(distancias) |&gt; mutate(id = x)) \nresumen &lt;- reps_sim |&gt; group_by(d) |&gt; summarise(p_5 = quantile(p, 0.10),\n                                                p95 = quantile(p, 0.90),\n                                                p = mean(p))\nreps_sim |&gt; \n  ggplot(aes(x = d, y = p)) +\n  #geom_line(aes(group = id), alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  geom_ribbon(data = resumen, aes(ymin = p_5, ymax = p95), alpha = 0.2) +\n  geom_line(data = resumen, color = \"red\", size = 2) \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nUna vez que estamos satisfechos con nuestro modelo (nótese que hay lugar para varias críticas), podemo proceder a calcular la distribución posterior, primero con datos simulados.\nLa posterior en este caso es más complicada y no tenemos una manera simple de simularla. Explicaremos más adelante cómo hacer esto (usando MCMC). Por ahora, escribiremos un programa de Stan que nos da simulaciones de la posterior. Tomaremos por el momento Stan como una caja negra, y después justificaremos este procedimiento.\n\n#! message: false\nlibrary(cmdstanr)\nmod_logistica &lt;- cmdstan_model(\"./src/golf-logistico.stan\")\nprint(mod_logistica)\n\ndata {\n  int&lt;lower=0&gt; N;\n  array[N] int n;\n  vector[N] d;\n  array[N] int y;\n}\nparameters {\n  real alpha;\n  real&lt;upper = 0&gt; beta;\n}\nmodel {\n  y ~ binomial_logit(n, alpha + beta * d);\n  alpha ~ normal(5, 2);\n  beta ~ normal(0, 0.02);\n}\n\n\n\nset.seed(1225)\ndistancias &lt;- rnorm(100, 0, 2000) |&gt; abs() \ndatos &lt;- simular_putts(distancias)\ndatos_mod &lt;- datos |&gt; group_by(d) |&gt; \n  summarise(n = n(), y = sum(y)) |&gt; \n  ungroup()\najuste &lt;- mod_logistica$sample(\n  data = list(N = nrow(datos_mod), \n              d = datos_mod$d, y = datos_mod$y, n = datos_mod$n), \n                        refresh = 1000, init = 10, step_size = 0.01)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.9 seconds.\n\nsims &lt;- ajuste$draws(c(\"alpha\", \"beta\"), format = \"df\")\nresumen &lt;- ajuste$summary()\n\n\nresumen\n\n# A tibble: 3 × 10\n  variable      mean    median      sd     mad        q5      q95  rhat ess_bulk\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__     -29.7     -29.4     0.996   0.723   -31.8     -2.88e+1  1.00    1148.\n2 alpha      5.51      5.46    1.05    1.04      3.89     7.28e+0  1.00     696.\n3 beta      -0.00634  -0.00628 0.00120 0.00118  -0.00838 -4.46e-3  1.01     666.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n\ndatos$alpha[1]\n\n[1] 5.766646\n\ndatos$beta[1]\n\n[1] -0.006834248\n\n\n\nggplot(sims, aes(alpha, beta)) + geom_point() +\n  geom_point(data = datos |&gt; first(), aes(alpha, beta), color = \"red\", size = 3)\n\n\n\n\nY podemos graficar la posterior de interés, que se construye con todas las curvas simuladas:\n\ngrafs_tbl &lt;- sims |&gt;\n  rowwise() |&gt;\n  mutate(graf = list(tibble(d = seq(0, 3000, 10)) |&gt; \n           mutate(p = 1 / (1 + exp(-alpha - beta * d)))\n  )) |&gt; \n  ungroup() |&gt; \n  slice_sample(n = 100) |&gt; \n  select(.draw, graf) |&gt; \n  unnest(graf) \n\nY graficamos:\n\ngrafs_tbl |&gt; \n  ggplot(aes(x = d, y = p, group = .draw)) +\n  geom_line(alpha = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\")\n\n\n\n\nVeremos cómo formalizar este proceso de chequeo a priori más adelante: por el momento, podríamos hacer unas cuantas simulaciones distintas, y ver que las curvas obtenidas son las que esperaríamos. También podríamos hacer simulaciones con distintos tamaños de muestra, y entender cuánta incertidumbre en la estimación de las curvas podríamos tener.\nAhora llegamos al siguiente paso, que tomar los datos y estimar nuestra curva de desempeño según la distancia.\n\ndatos_golf &lt;- read_delim(\"../datos/golf.csv\", delim = \" \")\n\nRows: 19 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\ndbl (3): x, n, y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(datos_golf)\n\n# A tibble: 6 × 3\n      x     n     y\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     2  1443  1346\n2     3   694   577\n3     4   455   337\n4     5   353   208\n5     6   272   149\n6     7   256   136\n\n\n\nset.seed(1225)\najuste &lt;- mod_logistica$sample(\n  data = list(N = nrow(datos_golf), \n              d = 100 * datos_golf$x / 0.3048, y = datos_golf$y, n = datos_golf$n), \n                        refresh = 1000, init = 10, step_size = 0.01)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims &lt;- ajuste$draws(c(\"alpha\", \"beta\"), format = \"df\")\nresumen &lt;- ajuste$summary()\n\n\nresumen\n\n# A tibble: 3 × 10\n  variable        mean   median      sd     mad       q5      q95  rhat ess_bulk\n  &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__        -3.03e+3 -3.03e+3 1.01e+0 7.12e-1 -3.03e+3 -3.03e+3  1.00    1300.\n2 alpha        2.23e+0  2.23e+0 5.75e-2 5.73e-2  2.14e+0  2.33e+0  1.00    1146.\n3 beta        -7.80e-4 -7.79e-4 2.03e-5 2.05e-5 -8.13e-4 -7.48e-4  1.00    1152.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nAhora simulamos la posterior y la contrastamos con los datos:\n\ngrafs_tbl &lt;- sims |&gt;\n  rowwise() |&gt;\n  mutate(graf = list(tibble(d = 100 * datos_golf$x / 0.3048) |&gt; \n           mutate(p = 1 / (1 + exp(-alpha - beta * d)))\n  )) |&gt; \n  ungroup() |&gt; \n  slice_sample(n = 100) |&gt; \n  select(.draw, graf) |&gt; \n  unnest(graf) \n\n\nresumen_golf &lt;- datos_golf |&gt;\n  mutate(d = 100 * x / 0.3048, p = y / n)\n\n\ngrafs_tbl |&gt; \n  ggplot(aes(x = d, y = p)) +\n  geom_line(aes(group = .draw), alpha = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  geom_point(data = resumen_golf, color = \"red\") +\n  geom_linerange(data = resumen_golf, \n    aes(ymin = p - 2 * sqrt(p * (1 - p) / n),  \n        ymax = p + 2 * sqrt(p * (1 - p) / n)),\n    color = \"red\")\n\n\n\n\nVemos que la curva estimada desajusta. Este tipo de análisis se llama chequeo a posteriori, y mas frecuentemente se hace un chequeo predictivo posterior, que veremos más adelante. Por el momento, nos quedamos con la conclusión de que el modelo no es apropiado para estos datos.\nEn este punto veremos dos caminos:\n\nEl primero es continuar con modelos genéricos que no toman en cuenta mecanismos específicos de los datos. Por ejemplo, podríamos poner más terminos derivados de la distancia (polinomios o splines)\nEl segundo camino, que exploramos primero, es utilizar más información acerca del fenómeno de interés. Sabemos como funciona básicamente el golf, y también sabemos geometría y física que determina el proceso generador de datos. Podemos utilizar esta información para construir un modelo más apropiado."
  },
  {
    "objectID": "03-modelos-genericos.html#usando-teoría-para-construir-modelos",
    "href": "03-modelos-genericos.html#usando-teoría-para-construir-modelos",
    "title": "4  Componentes básicas de modelación 1",
    "section": "4.8 Usando teoría para construir modelos",
    "text": "4.8 Usando teoría para construir modelos\n\n\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ."
  }
]