[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos analíticos",
    "section": "",
    "text": "Temario y referencias\nEste es un curso de estadística bayesiana con énfasis en inferencia causal y flujos de trabajo robustos para análisis de datos. Está basado en el material de McElreath (2020).\nTodas las notas y material del curso estarán en este repositorio.\n\nModelos estadísticos e inferencia causal\nBásicos del flujo de trabajo para inferencia bayesiana\nBásicos de modelación\nModelos gráficos (DAGS) y efectos causales\nExperimentos. Buenos y malos controles\nMCMC, Monte Carlo Hamiltoniano y Stan\nFlujo de trabajo bayesiano avanzado\nModelos jerárquicos\nError de medición y clasificación incorrecta\nDatos faltantes\nOtros métodos de inferencia causal\n\n\nEvaluación\n\nTareas semanales (20%)\nExamen parcial (40% teórico)\nUn examen final (40% práctico)\n\n\n\nMaterial\nCada semestre las notas cambian, en algunas partes considerablemente. Las de este semestre están en este repositorio, incluyendo ejemplos, ejercicios y tareas.\n\n\nReferencias principales\nEste curso sigue aproximadamente la primera referencia (Statistical Rethinking).\n\nStatistical Rethinking\nCausal Inference in Statistics: a primer\nCounterfactuals and Causal Inference: Methods and Principles for Social Research\nBayesian workflow]\nTowards a principled Bayesian workflow\n\n\n\nOtras referencias\n\nThe Book of Why\nCausal Inference: The Mixtape\nData Analysis Using Regression and Multilevel/Hierarchical Models\nPattern Recognition and Machine Learning\n\n\n\nSoftware: R y Rstudio\nPara hacer las tareas y exámenes pueden usar cualquier lenguaje de programación que les convenga (R o Python, por ejemplo) - el único requisito esté basado en código y no point-and-click. Adicionalmente usaremos Stan:\n\nStan: a state-of-the-art platform for statistical modeling and high-performance statistical computation, que tiene interfaces en R, Python, Julia, etc.\n\n\n\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ."
  },
  {
    "objectID": "01-introduccion.html#diagramas-causales",
    "href": "01-introduccion.html#diagramas-causales",
    "title": "1  Introducción",
    "section": "1.1 Diagramas causales",
    "text": "1.1 Diagramas causales\nEn primer lugar, observamos (McElreath (2020)):\n\n\n\n\n\n\nCausas y mecanismos\n\n\n\nLas razones de cómo hacemos análisis estadístico (que procedimiento o algoritmo seleccionamos, por ejemplo) en un problema dado no están en los datos observados, las causas de los datos.\n\n\nLas causas de los datos no pueden extrarse de los datos solamente. Muchas veces nos referimos a las causas de los datos como el proceso generador de los datos: esto incluye aspectos del fenómeno que nos interesa (ciencia o proceso de negocios, etc.), así como el proceso de observación (muestras, valores no observados, etc.).\nConsideremos un ejemplo simple para ilustrar este primer principio:\n\nEjemplo (cálculos renales)\nEste es un estudio real acerca de tratamientos para cálculos renales (Julious y Mullee (1994)). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.\nLa tabla original tiene 700 renglones (cada renglón es un paciente)\n\ncalculos &lt;- read_csv(\"../datos/kidney_stone_data.csv\")\nnames(calculos) &lt;- c(\"tratamiento\", \"tamaño\", \"éxito\")\ncalculos &lt;- calculos |&gt; \n   mutate(tamaño = ifelse(tamaño == \"large\", \"grandes\", \"chicos\")) |&gt; \n   mutate(resultado = ifelse(éxito == 1, \"mejora\", \"sin_mejora\")) |&gt; \n   select(tratamiento, tamaño, resultado)\nnrow(calculos)\n\n[1] 700\n\n\ny se ve como sigue (muestreamos algunos renglones):\n\ncalculos |&gt; \n   sample_n(10) |&gt; kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nresultado\n\n\n\n\nA\ngrandes\nmejora\n\n\nB\ngrandes\nsin_mejora\n\n\nA\ngrandes\nmejora\n\n\nA\ngrandes\nmejora\n\n\nB\nchicos\nmejora\n\n\nA\ngrandes\nmejora\n\n\nB\nchicos\nmejora\n\n\nB\nchicos\nmejora\n\n\nA\nchicos\nmejora\n\n\nB\nchicos\nmejora\n\n\n\n\n\n\n\nAunque estos datos contienen información de 700 pacientes, los datos pueden resumirse sin pérdida de información contando como sigue:\n\ncalculos_agregada &lt;- calculos |&gt; \n   group_by(tratamiento, tamaño, resultado) |&gt; \n   count()\ncalculos_agregada |&gt; kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nresultado\nn\n\n\n\n\nA\nchicos\nmejora\n81\n\n\nA\nchicos\nsin_mejora\n6\n\n\nA\ngrandes\nmejora\n192\n\n\nA\ngrandes\nsin_mejora\n71\n\n\nB\nchicos\nmejora\n234\n\n\nB\nchicos\nsin_mejora\n36\n\n\nB\ngrandes\nmejora\n55\n\n\nB\ngrandes\nsin_mejora\n25\n\n\n\n\n\n\n\nComo en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:\n\ncalculos_agregada |&gt; pivot_wider(names_from = resultado, values_from = n) |&gt; \n   mutate(total = mejora + sin_mejora) |&gt; \n   mutate(prop_mejora = round(mejora / total, 2)) |&gt; \n   select(tratamiento, tamaño, total, prop_mejora) |&gt; \n   arrange(tamaño) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\ntotal\nprop_mejora\n\n\n\n\nA\nchicos\n87\n0.93\n\n\nB\nchicos\n270\n0.87\n\n\nA\ngrandes\n263\n0.73\n\n\nB\ngrandes\n80\n0.69\n\n\n\n\n\n\n\nEsta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Pero es apropiada para empezar a contestar la pregunta:\n\n¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?\n\nSupongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:\n\ncalculos |&gt; group_by(tratamiento) |&gt; \n   summarise(prop_mejora = mean(resultado == \"mejora\") |&gt; round(2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\nprop_mejora\n\n\n\n\nA\n0.78\n\n\nB\n0.83\n\n\n\n\n\n\n\ny parece ser que el tratamiento \\(B\\) es mejor que el \\(A\\). Esta es una paradoja (un ejemplo de la paradoja de Simpson) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar \\(B\\)? ¿Si sabe debería recetar \\(A\\)? Esta discusión parece no tener mucho sentido.\nPodemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:\n\ncalculos |&gt; group_by(tratamiento, tamaño) |&gt; count() |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nn\n\n\n\n\nA\nchicos\n87\n\n\nA\ngrandes\n263\n\n\nB\nchicos\n270\n\n\nB\ngrandes\n80\n\n\n\n\n\n\n\nNuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos. En este caso, hay una decisión pues A es una cirugía y B es un procedimiento menos invasivo, y se prefiere utilizar el tratamiento \\(A\\) para cálculos grandes, y \\(B\\) para cálculos chicos. Esto quiere decir que en la tabla total el tratamiento \\(A\\) está en desventaja porque se usa en casos más difíciles, pero el tratamiento \\(A\\) parece ser en general mejor. La razón es probablemente un proceso de optimización de recursos y riesgo que hacen los doctores.\n\nEn este caso, una mejor respuesta a la pregunta de qué tratamiento es mejor es la que presenta los datos desagregados.\nLa tabla desagregada de asignación del tratamiento nos informa acerca de cómo se está distribuyendo el tratamiento en los pacientes.\n\n\n\n\n\n\n\nNota\n\n\n\nLos resúmenes descriptivos acompañados de hipótesis causales acerca del proceso generador de datos, nos guía hacia descripciones interpretables de los datos.\n\n\nLas explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos.\nPodemos codificar la información causal con un diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    T \n    M \n    C\n  edge [minlen = 3]\n    T -&gt; M\n    C -&gt; T\n    C -&gt; M\n{ rank = same; M; T }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEs decir, el tamaño de los cálculos es una causa común de tratamiento (T) y resultado (M). Veremos más adelante que la decisión de condicionar a el tipo de cálculos proviene de un análisis relativamente simple de este diagrama causal, independientemente de los métodos que usemos para estimar las proporciones de interés (en este ejemplo, examinar las tablas cruzadas es equivalente a hacer estimaciones de máxima verosimlitud).\n\n\nEjemplo (cálculos renales 2)\nContrastemos el ejemplo anterior usando exactamente la misma tabla de datos, pero con el supuesto de un proceso generador diferente. En este caso, los tratamientos son para mejorar alguna enfermedad del corazón. Sabemos que parte del efecto de este tratamiento ocurre gracias a una baja en presión arterial de los pacientes, así que después de administrar el tratamiento, se toma la presión arterial de los pacientes. Ahora tenemos la tabla agregada y desagregada como sigue:\n\ncorazon &lt;- calculos |&gt; \n  select(tratamiento, presión = tamaño, resultado) |&gt; \n  mutate(presión = ifelse(presión == \"grandes\", \"alta\", \"baja\"))\ncorazon_agregada &lt;- corazon |&gt; \n   group_by(tratamiento, presión, resultado) |&gt; \n   count()\ncorazon_agregada |&gt; pivot_wider(names_from = resultado, values_from = n) |&gt; \n   mutate(total = mejora + sin_mejora) |&gt; \n   mutate(prop_mejora = round(mejora / total, 2)) |&gt; \n   select(tratamiento, presión, total, prop_mejora) |&gt; \n   arrange(presión) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\npresión\ntotal\nprop_mejora\n\n\n\n\nA\nalta\n263\n0.73\n\n\nB\nalta\n80\n0.69\n\n\nA\nbaja\n87\n0.93\n\n\nB\nbaja\n270\n0.87\n\n\n\n\n\n\n\n\ncorazon |&gt; group_by(tratamiento) |&gt; \n   summarise(prop_mejora = mean(resultado == \"mejora\") |&gt; round(2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\nprop_mejora\n\n\n\n\nA\n0.78\n\n\nB\n0.83\n\n\n\n\n\n\n\n¿Cuál creemos que es el mejor tratamiento en este caso? ¿Deberíamos usar la tabla agregada o la desagregada por presión?\n\nEn este caso, la tabla agregada es más apropiada (B es mejor tratamiento).\nLa razón es que presión en este caso es una consecuencia de tomar el tratamiento, y como las tablas muestran, B es más exitoso en bajar la presión de los pacientes.\nSi sólo comparamos dentro de los grupos de presión baja o de presión alta, ignoramos lo más importante del tratamiento en la probabilidad de mejorar.\n\nNuestros supuestos causales podemos mostrarlos con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    P\n    T \n    M \n  edge [minlen = 3]\n    T -&gt; P\n    P -&gt; M\n    T -&gt; M\n{ rank = same; M; T}\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nNótese que el análisis más apropiado no está en los datos: en ambos casos la tabla de datos es exactamente la misma. Los supuestos acerca del proceso que genera los datos sin embargo nos lleva a respuestas opuestas."
  },
  {
    "objectID": "01-introduccion.html#diagramas-causales-1",
    "href": "01-introduccion.html#diagramas-causales-1",
    "title": "1  Introducción",
    "section": "Diagramas causales",
    "text": "Diagramas causales\nLos diagramas de arriba se llaman DAGs (Gráficas dirigidas acíclicas), y no son generadas por datos observados, sino que codifican conocimiento acerca del fenómenos y los datos observados. Nos ayudan a (McElreath (2020)):\n\nPensar claramente en términos científicos/de negocio acerca de nuestro problema\nExpresar los supuestos que hacemos que soportan nuestro análisis\nEntender qué podemos entender o explicar, sin hacer supuestos adicionales acerca de las relaciones particulares entre las variables.\nGuiar el análisis para decidir que modelos o procedimientos usar para contestar preguntas de interés.\n\nLos DAGs se construyen con causas, e implican asociaciones observables, pero no se construyen con asociaciones simplemente. El pensamiento causal es útil siempre que queremos responder preguntas acerca de un fenómeno de interés. En particular nos asisten en :\n\nAnálisis descriptivo\n\nComo vimos en el ejemplo anterior, incluso el análisis descriptivo (qué tabla usar, qué gráfica usar) de datos requiere de un análisis causal.\nMuchas veces los datos que tenemos, por distintas razones, tienen características que requieren procesarlos (por ejemplo ponderarlos) para que nos den respuestas entendibles.\n\n\n\nInferencia causal\n\nEfectos de intervenciones: En algunos casos, queremos saber consecuencias de una intervención sobre un sistema o proceso dados (por ejemplo, ¿cuántos accidentes graves habría si pusiéramos una multa por no usar cinturón de seguridad?). Esto requiere utilizar pensamiento causal.\nContrafactuales: También es usual necesitar pensar cómo serían las cosas si el pasado se hubiera desarrollado de manera distinta (por ejemplo, ¿cómo serían las ventas si no se hubiera gastado en publicidad?) en publicidad ?).\n\n\n\nDiseño de estudios o experimentos\n\nSi queremos recolectar datos acerca de un fenómeno particular (por ejemplo, ¿cómo debo seleccionar una muestra para medir orientación política de una población?), diseños eficientes requieren tener conocimiento de dominio acerca de las causas de las variables que nos interesa medir. Por ejemplo, si queremos tomar una muestra de casillas para estimar el resultado de una votación, deberíamos considerar variables geográficas como distrito electoral, grado de urbanización, etc.\n\n\n\nPredicción\n\nIncluso en problemas de predicción, modelos útiles resultan de pensar en la estructura causal del problema. Ignorar estos aspectos puede llevar fácilmente a evaluación incorrecta del desempeño, filtración de datos, o modelos que no pueden implementarse en la práctica."
  },
  {
    "objectID": "01-introduccion.html#modelos-y-algoritmos",
    "href": "01-introduccion.html#modelos-y-algoritmos",
    "title": "1  Introducción",
    "section": "1.2 Modelos y algoritmos",
    "text": "1.2 Modelos y algoritmos\nEn muchos cursos introductorios de estadística se muestran distintos tipos de procedimientos, que aplican según el tipo de datos (por ejemplo, categóricos o numéricos, pareados, no pareados, etc), generalmente con el propósito de evaluar evidencia en contra de una hipótesis nula. Por ejemplo, de McElreath (2020):\n\n\n\nEjemplo de proceso de decisión para procedimientos estadísticos\n\n\nEste enfoque puede ser confuso en un principio (¿cómo se relacionan todos estos procedimientos?), y también restringir nuestra capacidad para analizar datos: ¿qué hacemos cuando no se cumplen los supuestos de un procedimiento? Adicionalmente si no tenemos mucha experiencia, la manera en que fallan estas herramientas puede ser poco intuitiva y difícil de descubrir.\nY aunque son herramientas poderosas, no sustituyen el pensamiento científico o de proceso de negocios. Estas herramientas no generan hallazgos si no están acompañados de pensamiento causal.\nBuscamos entonces:\n\nDar herramientas (bayesianas) para analizar datos que son más flexibles, y se puedan adaptar a distintas situaciones.\nProponer un proceso para analizar datos, que sea más sistemático, robusto, y maneras de checar que el proceso es correcto o hace lo que pensamos que tiene qué hacer.\nLigar 1 y 2 con supuestos causales claros para proponer una interpretación sólida de nuestros resultados."
  },
  {
    "objectID": "01-introduccion.html#análisis-como-proceso",
    "href": "01-introduccion.html#análisis-como-proceso",
    "title": "1  Introducción",
    "section": "1.3 Análisis como proceso",
    "text": "1.3 Análisis como proceso\nIremos refinando nuestro poco a poco, conforme veamos distintas herramientas y problemas. El más básico es el siguiente (McElreath (2020)):\n\nDefinir un modelo generativo para la muestra de datos.\nDefinir la cantidad que queremos estimar en relación al fenómeno de interés.\nDefinir un proceso estadístico para hacer una estimación.\nProbar el proceso 3 usando 1 y 2.\n(Usar datos) Analizar los datos, resumir resultados.\nChecar cómputos y desempeño del modelo.\n\nEste proceso no es exclusivo de los modelos bayesianos, pero quizá es más natural, como veremos, cuando adoptamos el punto de vista bayesiano. Su propósito es múltiple: verificar que nuestros modelos están estimando las cantidades que realmente nos interesan, según nuestros supuestos, verificar los programas y cómputos con los que se obtienen resultados, y checar la adecuación del modelo a datos reales, cuestionando supuestos teóricos y supuestos de modelación.\nFinalmente, quisiéramos llegar a un proceso como el que se describe en Towards a Principled Bayesian Workflow, e incorporar el que se detalla en Gelman et al. (2020):\n\n\n\nGelman et al, Bayesian Workflow"
  },
  {
    "objectID": "01-introduccion.html#modelación-y-análisis-ingeniería",
    "href": "01-introduccion.html#modelación-y-análisis-ingeniería",
    "title": "1  Introducción",
    "section": "1.4 Modelación y análisis: ingeniería",
    "text": "1.4 Modelación y análisis: ingeniería\nCualquier proceso de análisis de datos se beneficia de muchos aspectos de ingenería de software. Parte de la profesionalización del análisis de datos que observamos en ciencia de datos es utilizar las herramientas reconocidas para resolver problemas de desarrollo y calidad de código, así como su documentación.\n\nAnálisis como software: Una parte de este proceso está relacionado con la reproducibilidad y documentación del trabajo, y su objetivo es evitar errores de programación y de organización (esta parte hablaremos menos: es necesario seguir los estándares de la industria para obtener resultados más confiables).\nOtra parte es el proceso con el cual construimos y contrastamos modelos para contestar preguntas, verificamos los modelos y sus respuestas y checamos resultados de cómputos.\n\n\n\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C. Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, y Martin Modrák. 2020. «Bayesian Workflow». https://arxiv.org/abs/2011.01808.\n\n\nJulious, Steven A, y Mark A Mullee. 1994. «Confounding and Simpson’s paradox». BMJ 309 (6967): 1480-81. https://doi.org/10.1136/bmj.309.6967.1480.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ."
  }
]