[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos analíticos",
    "section": "",
    "text": "Temario y referencias\nEste es un curso de estadística bayesiana con énfasis en inferencia causal y flujos de trabajo robustos para análisis de datos. Está basado en el material de McElreath (2020).\nTodas las notas y material del curso estarán en este repositorio.\n\nModelos estadísticos e inferencia causal\nBásicos del flujo de trabajo para inferencia bayesiana\nBásicos de modelación\nModelos gráficos (DAGS) y efectos causales\nExperimentos. Buenos y malos controles\nMCMC, Monte Carlo Hamiltoniano y Stan\nFlujo de trabajo bayesiano avanzado\nModelos jerárquicos\nError de medición y clasificación incorrecta\nDatos faltantes\nOtros métodos de inferencia causal\n\n\nEvaluación\n\nTareas semanales (20%)\nExamen parcial (40% teórico)\nUn examen final (40% práctico)\n\n\n\nMaterial\nCada semestre las notas cambian, en algunas partes considerablemente. Las de este semestre están en este repositorio, incluyendo ejemplos, ejercicios y tareas.\n\n\nReferencias principales\nEste curso sigue aproximadamente la primera referencia (Statistical Rethinking).\n\nStatistical Rethinking\nCausal Inference in Statistics: a primer\nCounterfactuals and Causal Inference: Methods and Principles for Social Research\nBayesian workflow]\nTowards a principled Bayesian workflow\n\n\n\nOtras referencias\n\nThe Book of Why\nCausal Inference: The Mixtape\nData Analysis Using Regression and Multilevel/Hierarchical Models\nPattern Recognition and Machine Learning\n\n\n\nSoftware: R y Rstudio\nPara hacer las tareas y exámenes pueden usar cualquier lenguaje de programación que les convenga (R o Python, por ejemplo) - el único requisito esté basado en código y no point-and-click. Adicionalmente usaremos Stan:\n\nStan: a state-of-the-art platform for statistical modeling and high-performance statistical computation, que tiene interfaces en R, Python, Julia, etc.\n\n\n\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "Temario y referencias"
    ]
  },
  {
    "objectID": "01-introduccion.html",
    "href": "01-introduccion.html",
    "title": "1  Introducción",
    "section": "",
    "text": "1.1 Diagramas causales\nEn primer lugar, observamos (McElreath (2020)):\nLas causas de los datos no pueden extrarse de los datos solamente. Muchas veces nos referimos a las causas de los datos como el proceso generador de los datos: esto incluye aspectos del fenómeno que nos interesa (ciencia o proceso de negocios, etc.), así como el proceso de observación (muestras, valores no observados, etc.).\nConsideremos un ejemplo simple para ilustrar este primer principio:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#diagramas-causales",
    "href": "01-introduccion.html#diagramas-causales",
    "title": "1  Introducción",
    "section": "",
    "text": "Causas y mecanismos\n\n\n\nLas razones de cómo hacemos análisis estadístico (que procedimiento o algoritmo seleccionamos, por ejemplo) en un problema dado no están en los datos observados, las causas de los datos.\n\n\n\n\n\nEjemplo (cálculos renales)\nEste es un estudio real acerca de tratamientos para cálculos renales (Julious y Mullee (1994)). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.\nLa tabla original tiene 700 renglones (cada renglón es un paciente)\n\ncalculos &lt;- read_csv(\"../datos/kidney_stone_data.csv\")\nnames(calculos) &lt;- c(\"tratamiento\", \"tamaño\", \"éxito\")\ncalculos &lt;- calculos |&gt; \n   mutate(tamaño = ifelse(tamaño == \"large\", \"grandes\", \"chicos\")) |&gt; \n   mutate(resultado = ifelse(éxito == 1, \"mejora\", \"sin_mejora\")) |&gt; \n   select(tratamiento, tamaño, resultado)\nnrow(calculos)\n\n[1] 700\n\n\ny se ve como sigue (muestreamos algunos renglones):\n\ncalculos |&gt; \n   sample_n(10) |&gt; kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\ntratamiento\ntamaño\nresultado\n\n\n\n\nA\ngrandes\nmejora\n\n\nA\ngrandes\nmejora\n\n\nA\ngrandes\nmejora\n\n\nA\nchicos\nmejora\n\n\nA\ngrandes\nmejora\n\n\nA\nchicos\nmejora\n\n\nA\ngrandes\nmejora\n\n\nB\nchicos\nsin_mejora\n\n\nB\nchicos\nmejora\n\n\nB\nchicos\nmejora\n\n\n\n\n\n\n\n\nAunque estos datos contienen información de 700 pacientes, los datos pueden resumirse sin pérdida de información contando como sigue:\n\ncalculos_agregada &lt;- calculos |&gt; \n   group_by(tratamiento, tamaño, resultado) |&gt; \n   count()\ncalculos_agregada |&gt; kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\ntratamiento\ntamaño\nresultado\nn\n\n\n\n\nA\nchicos\nmejora\n81\n\n\nA\nchicos\nsin_mejora\n6\n\n\nA\ngrandes\nmejora\n192\n\n\nA\ngrandes\nsin_mejora\n71\n\n\nB\nchicos\nmejora\n234\n\n\nB\nchicos\nsin_mejora\n36\n\n\nB\ngrandes\nmejora\n55\n\n\nB\ngrandes\nsin_mejora\n25\n\n\n\n\n\n\n\n\nComo en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:\n\ncalculos_agregada |&gt; pivot_wider(names_from = resultado, values_from = n) |&gt; \n   mutate(total = mejora + sin_mejora) |&gt; \n   mutate(prop_mejora = round(mejora / total, 2)) |&gt; \n   select(tratamiento, tamaño, total, prop_mejora) |&gt; \n   arrange(tamaño) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\ntratamiento\ntamaño\ntotal\nprop_mejora\n\n\n\n\nA\nchicos\n87\n0.93\n\n\nB\nchicos\n270\n0.87\n\n\nA\ngrandes\n263\n0.73\n\n\nB\ngrandes\n80\n0.69\n\n\n\n\n\n\n\n\nEsta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Pero es apropiada para empezar a contestar la pregunta:\n\n¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?\n\nSupongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:\n\ncalculos |&gt; group_by(tratamiento) |&gt; \n   summarise(prop_mejora = mean(resultado == \"mejora\") |&gt; round(2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\ntratamiento\nprop_mejora\n\n\n\n\nA\n0.78\n\n\nB\n0.83\n\n\n\n\n\n\n\n\ny parece ser que el tratamiento \\(B\\) es mejor que el \\(A\\). Esta es una paradoja (un ejemplo de la paradoja de Simpson) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar \\(B\\)? ¿Si sabe debería recetar \\(A\\)? Esta discusión parece no tener mucho sentido.\nPodemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:\n\ncalculos |&gt; group_by(tratamiento, tamaño) |&gt; count() |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\ntratamiento\ntamaño\nn\n\n\n\n\nA\nchicos\n87\n\n\nA\ngrandes\n263\n\n\nB\nchicos\n270\n\n\nB\ngrandes\n80\n\n\n\n\n\n\n\n\nNuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos. En este caso, hay una decisión pues A es una cirugía y B es un procedimiento menos invasivo, y se prefiere utilizar el tratamiento \\(A\\) para cálculos grandes, y \\(B\\) para cálculos chicos. Esto quiere decir que en la tabla total el tratamiento \\(A\\) está en desventaja porque se usa en casos más difíciles, pero el tratamiento \\(A\\) parece ser en general mejor. La razón es probablemente un proceso de optimización de recursos y riesgo que hacen los doctores.\n\nEn este caso, una mejor respuesta a la pregunta de qué tratamiento es mejor es la que presenta los datos desagregados.\nLa tabla desagregada de asignación del tratamiento nos informa acerca de cómo se está distribuyendo el tratamiento en los pacientes.\n\n\n\n\n\n\n\nNota\n\n\n\nLos resúmenes descriptivos acompañados de hipótesis causales acerca del proceso generador de datos, nos guía hacia descripciones interpretables de los datos.\n\n\nLas explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos.\nPodemos codificar la información causal con un diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    T \n    M \n    C\n  edge [minlen = 3]\n    T -&gt; M\n    C -&gt; T\n    C -&gt; M\n{ rank = same; M; T }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEs decir, el tamaño de los cálculos es una causa común de tratamiento (T) y resultado (M). Veremos más adelante que la decisión de condicionar a el tipo de cálculos proviene de un análisis relativamente simple de este diagrama causal, independientemente de los métodos que usemos para estimar las proporciones de interés (en este ejemplo, examinar las tablas cruzadas es equivalente a hacer estimaciones de máxima verosimlitud).\n\n\nEjemplo (cálculos renales 2)\nContrastemos el ejemplo anterior usando exactamente la misma tabla de datos, pero con el supuesto de un proceso generador diferente. En este caso, los tratamientos son para mejorar alguna enfermedad del corazón. Sabemos que parte del efecto de este tratamiento ocurre gracias a una baja en presión arterial de los pacientes, así que después de administrar el tratamiento, se toma la presión arterial de los pacientes. Ahora tenemos la tabla agregada y desagregada como sigue:\n\ncorazon &lt;- calculos |&gt; \n  select(tratamiento, presión = tamaño, resultado) |&gt; \n  mutate(presión = ifelse(presión == \"grandes\", \"alta\", \"baja\"))\ncorazon_agregada &lt;- corazon |&gt; \n   group_by(tratamiento, presión, resultado) |&gt; \n   count()\ncorazon_agregada |&gt; pivot_wider(names_from = resultado, values_from = n) |&gt; \n   mutate(total = mejora + sin_mejora) |&gt; \n   mutate(prop_mejora = round(mejora / total, 2)) |&gt; \n   select(tratamiento, presión, total, prop_mejora) |&gt; \n   arrange(presión) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\ntratamiento\npresión\ntotal\nprop_mejora\n\n\n\n\nA\nalta\n263\n0.73\n\n\nB\nalta\n80\n0.69\n\n\nA\nbaja\n87\n0.93\n\n\nB\nbaja\n270\n0.87\n\n\n\n\n\n\n\n\n\ncorazon |&gt; group_by(tratamiento) |&gt; \n   summarise(prop_mejora = mean(resultado == \"mejora\") |&gt; round(2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\ntratamiento\nprop_mejora\n\n\n\n\nA\n0.78\n\n\nB\n0.83\n\n\n\n\n\n\n\n\n¿Cuál creemos que es el mejor tratamiento en este caso? ¿Deberíamos usar la tabla agregada o la desagregada por presión?\n\nEn este caso, la tabla agregada es más apropiada (B es mejor tratamiento).\nLa razón es que presión en este caso es una consecuencia de tomar el tratamiento, y como las tablas muestran, B es más exitoso en bajar la presión de los pacientes.\nSi sólo comparamos dentro de los grupos de presión baja o de presión alta, ignoramos lo más importante del tratamiento en la probabilidad de mejorar.\n\nNuestros supuestos causales podemos mostrarlos con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    P\n    T \n    M \n  edge [minlen = 3]\n    T -&gt; P\n    P -&gt; M\n    T -&gt; M\n{ rank = same; M; T}\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nNótese que el análisis más apropiado no está en los datos: en ambos casos la tabla de datos es exactamente la misma. Los supuestos acerca del proceso que genera los datos sin embargo nos lleva a respuestas opuestas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#diagramas-causales-1",
    "href": "01-introduccion.html#diagramas-causales-1",
    "title": "1  Introducción",
    "section": "Diagramas causales",
    "text": "Diagramas causales\nLos diagramas de arriba se llaman DAGs (Gráficas dirigidas acíclicas), y no son generadas por datos observados, sino que codifican conocimiento acerca del fenómenos y los datos observados. Nos ayudan a (McElreath (2020)):\n\nPensar claramente en términos científicos/de negocio acerca de nuestro problema\nExpresar los supuestos que hacemos que soportan nuestro análisis\nEntender qué podemos entender o explicar, sin hacer supuestos adicionales acerca de las relaciones particulares entre las variables.\nGuiar el análisis para decidir que modelos o procedimientos usar para contestar preguntas de interés.\n\nLos DAGs se construyen con causas, e implican asociaciones observables, pero no se construyen con asociaciones simplemente. El pensamiento causal es útil siempre que queremos responder preguntas acerca de un fenómeno de interés. En particular nos asisten en :\n\nAnálisis descriptivo\n\nComo vimos en el ejemplo anterior, incluso el análisis descriptivo (qué tabla usar, qué gráfica usar) de datos requiere de un análisis causal.\nMuchas veces los datos que tenemos, por distintas razones, tienen características que requieren procesarlos (por ejemplo ponderarlos) para que nos den respuestas entendibles.\n\n\n\nInferencia causal\n\nEfectos de intervenciones: En algunos casos, queremos saber consecuencias de una intervención sobre un sistema o proceso dados (por ejemplo, ¿cuántos accidentes graves habría si pusiéramos una multa por no usar cinturón de seguridad?). Esto requiere utilizar pensamiento causal.\nContrafactuales: También es usual necesitar pensar cómo serían las cosas si el pasado se hubiera desarrollado de manera distinta (por ejemplo, ¿cómo serían las ventas si no se hubiera gastado en publicidad?) en publicidad ?).\n\n\n\nDiseño de estudios o experimentos\n\nSi queremos recolectar datos acerca de un fenómeno particular (por ejemplo, ¿cómo debo seleccionar una muestra para medir orientación política de una población?), diseños eficientes requieren tener conocimiento de dominio acerca de las causas de las variables que nos interesa medir. Por ejemplo, si queremos tomar una muestra de casillas para estimar el resultado de una votación, deberíamos considerar variables geográficas como distrito electoral, grado de urbanización, etc.\n\n\n\nPredicción\n\nIncluso en problemas de predicción, modelos útiles resultan de pensar en la estructura causal del problema. Ignorar estos aspectos puede llevar fácilmente a evaluación incorrecta del desempeño, filtración de datos, o modelos que no pueden implementarse en la práctica.\n\n\n\nOtro ejemplo (admisiones de Berkeley)\nUna ejemplo al que regresaremos más adelante es el siguiente: en 1973 se recolectaron datos agregados de solicitantes para estudiar en Berkeley para los 6 departamentos más grandes, clasificados por sexo del solicitante y si fue admitido o no. Los resultados se muestran a continuación:\n\ndata(\"UCBAdmissions\")\nadm_original &lt;- UCBAdmissions |&gt; as_tibble() |&gt; \n   pivot_wider(names_from = Admit, values_from = n) \nadm_original |&gt; knitr::kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\nGender\nDept\nAdmitted\nRejected\n\n\n\n\nMale\nA\n512\n313\n\n\nFemale\nA\n89\n19\n\n\nMale\nB\n353\n207\n\n\nFemale\nB\n17\n8\n\n\nMale\nC\n120\n205\n\n\nFemale\nC\n202\n391\n\n\nMale\nD\n138\n279\n\n\nFemale\nD\n131\n244\n\n\nMale\nE\n53\n138\n\n\nFemale\nE\n94\n299\n\n\nMale\nF\n22\n351\n\n\nFemale\nF\n24\n317\n\n\n\n\n\n\n\n\ny las proporciones de admisión por sexo y departamente son las siguientes:\n\nadm_tbl &lt;- adm_original |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected), 2), total = Admitted + Rejected) |&gt; \n   select(Gender, Dept, prop_adm, total) |&gt; \n   pivot_wider(names_from = Gender, values_from = prop_adm:total)\nadm_tbl |&gt; knitr::kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\nDept\nprop_adm_Male\nprop_adm_Female\ntotal_Male\ntotal_Female\n\n\n\n\nA\n0.62\n0.82\n825\n108\n\n\nB\n0.63\n0.68\n560\n25\n\n\nC\n0.37\n0.34\n325\n593\n\n\nD\n0.33\n0.35\n417\n375\n\n\nE\n0.28\n0.24\n191\n393\n\n\nF\n0.06\n0.07\n373\n341\n\n\n\n\n\n\n\n\nComplementamos con las tasas de aceptación a total por género, y tasas de aceptación por departamento:\n\nadm_original |&gt; group_by(Gender) |&gt; \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\nGender\nAdmitted\nRejected\nprop_adm\n\n\n\n\nFemale\n557\n1278\n0.30\n\n\nMale\n1198\n1493\n0.45\n\n\n\n\n\n\n\n\nLa pregunta que queremos hacer es: ¿existe discriminación por sexo en la selección de candidatos? Examinando las tablas no está clara cuál es la respuesta.\n\nadm_original |&gt; group_by(Dept) |&gt; \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\n\nDept\nAdmitted\nRejected\nprop_adm\n\n\n\n\nA\n601\n332\n0.64\n\n\nB\n370\n215\n0.63\n\n\nC\n322\n596\n0.35\n\n\nD\n269\n523\n0.34\n\n\nE\n147\n437\n0.25\n\n\nF\n46\n668\n0.06\n\n\n\n\n\n\n\n\nDiscutiremos este ejemplo con más detalle más adelante. La interpretación debe ser hecha con cuidado, y debemos establecer claramente los supuestos que fundamentan nuestra decisión de mostrar cada tabla y de qué forma mostrarlas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#modelos-y-algoritmos",
    "href": "01-introduccion.html#modelos-y-algoritmos",
    "title": "1  Introducción",
    "section": "1.2 Modelos y algoritmos",
    "text": "1.2 Modelos y algoritmos\nEn muchos cursos introductorios de estadística se muestran distintos tipos de procedimientos, que aplican según el tipo de datos (por ejemplo, categóricos o numéricos, pareados, no pareados, etc), generalmente con el propósito de evaluar evidencia en contra de una hipótesis nula. Por ejemplo, de McElreath (2020):\n\n\n\nEjemplo de proceso de decisión para procedimientos estadísticos\n\n\nEste enfoque puede ser confuso en un principio (¿cómo se relacionan todos estos procedimientos?), y también restringir nuestra capacidad para analizar datos: ¿qué hacemos cuando no se cumplen los supuestos de un procedimiento? Adicionalmente si no tenemos mucha experiencia, la manera en que fallan estas herramientas puede ser poco intuitiva y difícil de descubrir.\nY aunque son herramientas poderosas, no sustituyen el pensamiento científico o de proceso de negocios. Estas herramientas no generan hallazgos si no están acompañados de pensamiento causal.\nBuscamos entonces:\n\nDar herramientas (bayesianas) para analizar datos que son más flexibles, y se puedan adaptar a distintas situaciones.\nProponer un proceso para analizar datos, que sea más sistemático, robusto, y maneras de checar que el proceso es correcto o hace lo que pensamos que tiene qué hacer.\nLigar 1 y 2 con supuestos causales claros para proponer una interpretación sólida de nuestros resultados.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#análisis-como-proceso",
    "href": "01-introduccion.html#análisis-como-proceso",
    "title": "1  Introducción",
    "section": "1.3 Análisis como proceso",
    "text": "1.3 Análisis como proceso\nIremos refinando nuestro poco a poco, conforme veamos distintas herramientas y problemas. El más básico es el siguiente (McElreath (2020)):\n\nDefinir un modelo generativo para la muestra de datos.\nDefinir la cantidad que queremos estimar en relación al fenómeno de interés.\nDefinir un proceso estadístico para hacer una estimación.\nProbar el proceso 3 usando 1 y 2.\n(Usar datos) Analizar los datos, resumir resultados.\nChecar cómputos y desempeño del modelo.\n\nEste proceso no es exclusivo de los modelos bayesianos, pero quizá es más natural, como veremos, cuando adoptamos el punto de vista bayesiano. Su propósito es múltiple: verificar que nuestros modelos están estimando las cantidades que realmente nos interesan, según nuestros supuestos, verificar los programas y cómputos con los que se obtienen resultados, y checar la adecuación del modelo a datos reales, cuestionando supuestos teóricos y supuestos de modelación.\nFinalmente, quisiéramos llegar a un proceso como el que se describe en Towards a Principled Bayesian Workflow, e incorporar el que se detalla en Gelman et al. (2020):\n\n\n\nGelman et al, Bayesian Workflow",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#modelación-y-análisis-ingeniería",
    "href": "01-introduccion.html#modelación-y-análisis-ingeniería",
    "title": "1  Introducción",
    "section": "1.4 Modelación y análisis: ingeniería",
    "text": "1.4 Modelación y análisis: ingeniería\nCualquier proceso de análisis de datos se beneficia de muchos aspectos de ingenería de software. Parte de la profesionalización del análisis de datos que observamos en ciencia de datos es utilizar las herramientas reconocidas para resolver problemas de desarrollo y calidad de código, así como su documentación.\n\nAnálisis como software: Una parte de este proceso está relacionado con la reproducibilidad y documentación del trabajo, y su objetivo es evitar errores de programación y de organización (esta parte hablaremos menos: es necesario seguir los estándares de la industria para obtener resultados más confiables).\nOtra parte es el proceso con el cual construimos y contrastamos modelos para contestar preguntas, verificamos los modelos y sus respuestas y checamos resultados de cómputos.\n\n\n\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C. Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, y Martin Modrák. 2020. «Bayesian Workflow». https://arxiv.org/abs/2011.01808.\n\n\nJulious, Steven A, y Mark A Mullee. 1994. «Confounding and Simpson’s paradox». BMJ 309 (6967): 1480-81. https://doi.org/10.1136/bmj.309.6967.1480.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html",
    "href": "02-flujo-basico.html",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "",
    "text": "2.1 Paso 1: Modelo generativo\nConsideremos primero qué variables de interés tenemos: \\(p\\), la proporción de seropositivos en la población, \\(N\\) que es el número de personas a las que les hicimos la prueba, y \\(N_{+}\\) y \\(N_{-}\\) que cuentan el número de positivos y seronegativos en la muestra. Supondremos que la prueba da resultados exactos. Denotaremos por \\(\\theta\\) a la proporción de seropositivos en la muestra.\nComenzamos construyendo el diagrama que indica cómo influye cada variable en otra (nota: no son asociaciones, sino que indican qué variables “escuchan” a otras para determinar su valor). En este caso, \\(N\\) y \\(\\theta\\) son variable que no depende de ninguna otra, mientras que \\(N_{+}\\) y \\(N_{-}\\) dependen de \\(N\\) y \\(\\theta\\). Como \\(\\theta\\) es una cantidad que no observamos directamente, mostramos su nodo como un círculo.\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta [label = &lt;&theta;&gt;]\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    theta -&gt; Npos\n    theta -&gt; Nneg\n    N -&gt; Npos\n    N -&gt; Nneg\n    #esp -&gt; Pos\n    #sens -&gt; Pos\n    #esp -&gt; Neg\n    #sens -&gt; Neg\n{ rank = same; theta; N }\n{ rank = same; Npos; Nneg}\n#{ rank = max; sens; esp}\n\n  \n}\n\", width = 300, height = 100)\nQue también podríamos simplificar (suponiendo la \\(N\\) fija y conocida, pues \\(N_+\\) y \\(M\\) dan \\(N_{-}\\)) como:\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta [label = &lt;&theta;&gt;]\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    theta -&gt; Npos\n    N -&gt; Npos\n    #esp -&gt; Pos\n    #sens -&gt; Pos\n    #esp -&gt; Neg\n    #sens -&gt; Neg\n{ rank = same; theta; N }\n{ rank = same; Npos}\n#{ rank = max; sens; esp}\n\n  \n}\n\", width = 300, height = 100)\nY ahora construimos el modelo generativo. Supondremos que la muestra de \\(N\\) personas se toma de manera aleatoria de la población (una población grande, así que podemos ignorar el efecto de muestreo). Supondremos provisionalmente, además, que la prueba es perfecta, es decir, no hay falsos positivos o negativos.\nLa siguiente función simula una muestra de \\(N\\) personas, y regresa el número de Positivos y Negativos en la muestra.\nsim_pos_neg &lt;- function(theta = 0.01, N = 20, sens = 1, esp = 1) {\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, theta)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra\n  Pos &lt;- Pos_verdadero\n  Neg &lt;- 1 - Pos\n  # Observaciones\n  tibble(Pos = Pos, Neg = Neg)\n}\nPodemos hacer algunas pruebas del modelo generativo en casos extremos:\nset.seed(8212)\nsim_pos_neg(theta = 1.0, N = 10)\n\n# A tibble: 10 × 2\n     Pos   Neg\n   &lt;int&gt; &lt;dbl&gt;\n 1     1     0\n 2     1     0\n 3     1     0\n 4     1     0\n 5     1     0\n 6     1     0\n 7     1     0\n 8     1     0\n 9     1     0\n10     1     0\n\nsim_pos_neg(theta = 0.0, N = 10)\n\n# A tibble: 10 × 2\n     Pos   Neg\n   &lt;int&gt; &lt;dbl&gt;\n 1     0     1\n 2     0     1\n 3     0     1\n 4     0     1\n 5     0     1\n 6     0     1\n 7     0     1\n 8     0     1\n 9     0     1\n10     0     1\n\nsim_pos_neg(theta = 0.1, N = 1e7) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.1001\nEn la práctica podemos definir pruebas más exhaustivas si es necesario. En este caso, se trata principalmente de pruebas unitarias que se utilizan comunmente en desarrollo de software.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-1-modelo-generativo",
    "href": "02-flujo-basico.html#paso-1-modelo-generativo",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "",
    "text": "Pruebas unitarias\n\n\n\nLa práctica estándar de pruebas unitarias consiste en probar unidades relativamente pequeñas de código (por ejemplo funciones) para verificar que funcionan correctamente.\nEsta estrategia debe utilizarse también, en la medida de los posible, en estadística.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-2-definir-estimando",
    "href": "02-flujo-basico.html#paso-2-definir-estimando",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.2 Paso 2: Definir estimando",
    "text": "2.2 Paso 2: Definir estimando\nAhora podemos definir en términos de nuestro modelo el valor que queremos estimar. En este caso, coincide con un párametro del modelo \\(\\theta\\), pero no necesariamente es así siempre: como veremos más adelante, puede ser una cantidad que se deriva de otras variables y parámetros del modelo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-3-definir-un-proceso-estadístico",
    "href": "02-flujo-basico.html#paso-3-definir-un-proceso-estadístico",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.3 Paso 3: definir un proceso estadístico",
    "text": "2.3 Paso 3: definir un proceso estadístico\nDada la información limitada que tenemos acerca de la población, esperamos tener cierta incertidumbre en nuestra estimación del valor de \\(\\theta\\). En estadística bayesiana esta incertidumbre la expresamos mediante una distribución de probabilidades sobre posibles valores del \\(\\theta\\). Si denotamos por \\(D\\) a los datos observados, nuestro objetivo es calcular o aproximar\n\\[p(\\theta|D)\\] que es una distribución sobre los posibles valores de \\(\\theta\\), una vez que tenemos información de la muestra, y que pone más masa de probabilidad sobre las conjeturas de \\(\\theta\\) que son más probables o creíbles. A esta distribución le llamamos la distribución posterior de \\(\\theta\\).\nCon esta posterior podemos hacer afirmaciones probabilísticas de la forma:\n\n¿Cuál es la probabilidad de que \\(\\theta\\) sea menor a 1%? (Muy pocos seropositivos)\n¿Cuál es la probabildad de que \\(\\theta\\) sea mayor a 80%? (Población cerca de saturación)\n\nEstas cantidades se calculan, al menos teóricamente, integrando \\(p(\\theta|D)\\) sobre los valores de \\(\\theta\\) que nos interesan, por ejemplo,\n\\[P(\\theta &lt;= 0.01) = \\int_0^{0.01} p(\\theta|D) d\\theta\\] Nota: la integral la interpretamos como suma en el caso discreto.\nSupongamos entonces una \\(\\theta\\) dada, y que observamos la muestra \\(1,0,0,1,0\\). La probabilidad de observar esta muestra es (suponiendo observaciones independientes):\n\\[\\theta(1-\\theta)(1-\\theta)\\theta(1-\\theta) = \\theta^2(1-\\theta)^3\\] Para algunos valores de \\(\\theta\\) (posibles conjeturas acerca del valor de \\(\\theta\\)) podemos escribir una tabla como sigue (Nota: discretizamos por el momento a un número finito de valores de \\(\\theta\\) para hacer el argumento más simple):\n\ntheta &lt;- seq(0, 1, length.out = 11)\ntibble(conjetura_theta = theta, verosimiltud = theta^2 * (1 - theta)^3) |&gt; \n  kbl(col.names = c(\"Conjetura θ\", \"p(D|θ)\"),\n      escape = FALSE) \n\n\n\n\n\nConjetura θ\np(D|θ)\n\n\n\n\n0.0\n0.00000\n\n\n0.1\n0.00729\n\n\n0.2\n0.02048\n\n\n0.3\n0.03087\n\n\n0.4\n0.03456\n\n\n0.5\n0.03125\n\n\n0.6\n0.02304\n\n\n0.7\n0.01323\n\n\n0.8\n0.00512\n\n\n0.9\n0.00081\n\n\n1.0\n0.00000\n\n\n\n\n\n\n\n\nEn la tabla vemos que hay algunas conjeturas, o posibles valores de \\(\\theta\\), que tienen probabilidad considerablemente más alta que otra. La notación\n\\[p(D|\\theta)\\] significa: la probabilidad de los datos \\(D\\) dado el valor de \\(\\theta\\). Nótese que esta distribución no es la posterior que describimos arriba, y no es una distribución de probabilidad sobre \\(\\theta\\) (las probabilidades no suman uno). Esta función se llama usualmente verosimilitud de los datos, e incorpora supuestos concretos del proceso generador de los datos.\nUsando reglas de probabilidad (en particular la regla de Bayes), observamos que\n\\[p(\\theta | D) = \\frac{p(D|\\theta)p(\\theta)} { p(D)}.\\] Como \\(p(\\theta|D)\\) debe dar una distribución de probabilidad (suma o integra a 1), entonces \\(p(D)\\) debe ser una constante de normalización para el numerador de la derecha, es decir, basta escribir\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta) \\] Ahora es donde encontramos que tenemos que tener \\(p(\\theta)\\) para poder calcular la cantidad que nos interesa, que es la distribución posterior \\(p(\\theta|D)\\). \\(p(\\theta)\\), la distribución a priori o distribución inicial es simplemente una afirmación de dónde puede estar \\(\\theta\\), antes de observar ningún dato.\nPor el momento, podríamos poner \\(p(\\theta)\\) constante, de manera que es parte de la constante de normalización, y sólo tendríamos que normalizar como sigue:\n\ntheta &lt;- seq(0, 1, length.out = 11)\nprob_post &lt;- tibble(conjetura = theta, probablidad = theta^2 * (1 - theta)^3) |&gt; \n  mutate(prob_posterior = probablidad / sum(probablidad)) \nprob_post |&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(D|θ)\",\"p(θ|D)\")) |&gt;\n  kable_paper()\n\n\n\n\n\nConjetura θ\np(D|θ)\np(θ|D)\n\n\n\n\n0.0\n0.00000\n0.0000000\n\n\n0.1\n0.00729\n0.0437444\n\n\n0.2\n0.02048\n0.1228923\n\n\n0.3\n0.03087\n0.1852385\n\n\n0.4\n0.03456\n0.2073807\n\n\n0.5\n0.03125\n0.1875188\n\n\n0.6\n0.02304\n0.1382538\n\n\n0.7\n0.01323\n0.0793879\n\n\n0.8\n0.00512\n0.0307231\n\n\n0.9\n0.00081\n0.0048605\n\n\n1.0\n0.00000\n0.0000000\n\n\n\n\n\n\n\n\nCon esto, expresamos nuestro conocimiento acerca de \\(\\theta\\), después de observar los datos, con una distribución posterior de probabilidad sobre las posibles conjecturas. Este es el resultado principal de inferencia bayesiana, y es la base para tomar decisiones relativas a \\(\\theta\\).\n\nUsando información adicional\nSupongamos que tenemos información adicional acerca de \\(\\theta\\), por ejemplo, que en un experimento similar anterior alguien tomó una muestra de dos personas, y encontraron dos negativos. Tenemos entonces como creencias inciales:\n\ntheta &lt;- seq(0, 1, length.out = 11)\nprob_priori &lt;- tibble(conjetura = theta) |&gt; \n  mutate(prob_priori = (1 - theta) * (1 - theta)) |&gt; \n  mutate(prob_priori = prob_priori / sum(prob_priori)) \nprob_priori |&gt;\n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\")) |&gt; kable_paper()\n\n\n\n\n\nConjetura θ\np(θ)\n\n\n\n\n0.0\n0.2597403\n\n\n0.1\n0.2103896\n\n\n0.2\n0.1662338\n\n\n0.3\n0.1272727\n\n\n0.4\n0.0935065\n\n\n0.5\n0.0649351\n\n\n0.6\n0.0415584\n\n\n0.7\n0.0233766\n\n\n0.8\n0.0103896\n\n\n0.9\n0.0025974\n\n\n1.0\n0.0000000\n\n\n\n\n\n\n\n\nPor ejemplo, al probabilidad inicial de que \\(\\theta\\) sea muy grande es cercana a cero, pues observamos dos negativos y ningún positivo. Ahora regresamos a considerar nuestra fórmula\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta), \\]\nEn este caso, la apriori o inicial tiene un efecto sobre la posterior. Reconsideramos entonces la posterior de nuestra muestra de 5 personas, y calculamos el producto de \\(P(D|\\theta)\\) por \\(p(\\theta)\\):\n\nprob_post &lt;- prob_priori |&gt; \n  mutate(verosimilitud = theta^2 * (1 - theta)^3) |&gt; \n  mutate(prod = verosimilitud * prob_priori)\n\nprob_post|&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\", \"p(D|θ)\",\n                      \"p(D|θ)p(θ)\")) |&gt; kable_paper()\n\n\n\n\n\nConjetura θ\np(θ)\np(D|θ)\np(D|θ)p(θ)\n\n\n\n\n0.0\n0.2597403\n0.00000\n0.0000000\n\n\n0.1\n0.2103896\n0.00729\n0.0015337\n\n\n0.2\n0.1662338\n0.02048\n0.0034045\n\n\n0.3\n0.1272727\n0.03087\n0.0039289\n\n\n0.4\n0.0935065\n0.03456\n0.0032316\n\n\n0.5\n0.0649351\n0.03125\n0.0020292\n\n\n0.6\n0.0415584\n0.02304\n0.0009575\n\n\n0.7\n0.0233766\n0.01323\n0.0003093\n\n\n0.8\n0.0103896\n0.00512\n0.0000532\n\n\n0.9\n0.0025974\n0.00081\n0.0000021\n\n\n1.0\n0.0000000\n0.00000\n0.0000000\n\n\n\n\n\n\n\n\nY finalmente, normalizamos para encontrar la probabilidad posterior:\n\nprob_post &lt;- prob_post |&gt; \n  mutate(prob_posterior = prod / sum(prod))\n\nprob_post|&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\", \"p(D|θ)\",\n    \"p(D|θ)p(θ)\", \"p(θ|D)\"), escape = FALSE) |&gt; kable_paper()\n\n\n\n\n\nConjetura θ\np(θ)\np(D|θ)\np(D|θ)p(θ)\np(θ|D)\n\n\n\n\n0.0\n0.2597403\n0.00000\n0.0000000\n0.0000000\n\n\n0.1\n0.2103896\n0.00729\n0.0015337\n0.0992712\n\n\n0.2\n0.1662338\n0.02048\n0.0034045\n0.2203539\n\n\n0.3\n0.1272727\n0.03087\n0.0039289\n0.2542983\n\n\n0.4\n0.0935065\n0.03456\n0.0032316\n0.2091640\n\n\n0.5\n0.0649351\n0.03125\n0.0020292\n0.1313412\n\n\n0.6\n0.0415584\n0.02304\n0.0009575\n0.0619745\n\n\n0.7\n0.0233766\n0.01323\n0.0003093\n0.0200177\n\n\n0.8\n0.0103896\n0.00512\n0.0000532\n0.0034430\n\n\n0.9\n0.0025974\n0.00081\n0.0000021\n0.0001362\n\n\n1.0\n0.0000000\n0.00000\n0.0000000\n0.0000000\n\n\n\n\n\n\n\n\nLa última columna nos da el resultado final de la inferencia bayesiana. Podemos resumir algunas de sus características, por ejemplo:\n\nEs muy poco probable que la seropositividad sea mayor o igual a 0.7\nUn intervalo de 90% de probabilidad para la seropositividad es \\([0.1, 0.5]\\)\n\nLa gráfica de la posterior es:\n\nprob_post |&gt;\n  ggplot(aes(x = conjetura, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") \n\n\n\n\n\n\n\n\nAhora podemos definir, para nuestro ejemplo discretizado, la función que calcula la posterior dados los pasos 1 y 2:\n\ncalcular_posterior &lt;- function(muestra, prob_priori){\n  # distribución inicial o a prior\n  theta &lt;- seq(0, 1, length.out = 11)\n  priori &lt;- tibble(theta = theta, prob_priori = (1 - theta) * (1 - theta)) |&gt; \n    mutate(prob_priori = prob_priori / sum(prob_priori))\n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post &lt;- tibble(theta = theta) |&gt; \n      left_join(priori, by = \"theta\") |&gt; \n      mutate(prob_posterior = theta ^ Npos * (1 - theta)^(N - Npos) * prob_priori) |&gt; \n    mutate(prob_posterior = prob_posterior / sum(prob_posterior)) \n  prob_post |&gt; select(theta, prob_posterior)\n}\n\n\nmuestra &lt;- c(1,0,0,1,0)\n\n\ncalcular_posterior(muestra, prob_priori) \n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0         0       \n 2   0.1       0.0993  \n 3   0.2       0.220   \n 4   0.3       0.254   \n 5   0.4       0.209   \n 6   0.5       0.131   \n 7   0.6       0.0620  \n 8   0.7       0.0200  \n 9   0.8       0.00344 \n10   0.9       0.000136\n11   1         0       \n\n\nProcedemos ahora a hacer algunas pruebas simples de nuestra función:\n\ncalcular_posterior(rep(0, 50)) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0.996\n 2   0.1          0.004\n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0    \n 6   0.5          0    \n 7   0.6          0    \n 8   0.7          0    \n 9   0.8          0    \n10   0.9          0    \n11   1            0    \n\ncalcular_posterior(rep(1, 50)) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0    \n 2   0.1          0    \n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0    \n 6   0.5          0    \n 7   0.6          0    \n 8   0.7          0    \n 9   0.8          0.011\n10   0.9          0.989\n11   1            0    \n\ncalcular_posterior(c(rep(0, 100), rep(1, 100))) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0    \n 2   0.1          0    \n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0.023\n 6   0.5          0.966\n 7   0.6          0.01 \n 8   0.7          0    \n 9   0.8          0    \n10   0.9          0    \n11   1            0    \n\n\n\n\nMás verificaciones a priori\nOtra verificación útil que podemos hacer es, una vez que hemos definido nuestro modelo generativo y un modelos estadístico asociado, generar bajo simulación datos que podríamos observar. Esto tiene como fin verificar que nuestro modelo generativo y nuestro modelo estadístico producen datos que están de acuerdo con el conocimiento experto (teoría científica o conocimiento de negocio).\nAsí que simulamos datos del modelo:\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\n\nPodemos ver por ejemplo dónde esperamos ver el número de positivos a lo largo de distintas muestras, cuando \\(N=30\\):\n\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos), .groups = \"drop\") |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n\n\n\n\n\n\n\nObservamos que con nuestros supuestos, hay una probabilidad alta de observar 0 positivos (alrededor de 0.30). Esto se debe en parte a la discretización que hicimos, y que nuestra apriori pone peso considerable en prevalencia igual a cero, lo que quizá no es muy realista, y probablemente deberíamos escoger al menos una discretización más fina.\nTambién, si consideramos los supuestos como correctos, esto puede indicar el riesgo de usar una muestra chica para estimar prevalencia si esta es muy baja: es probable que obtengamos 0 observaciones positivas.\n\n\n\n\n\n\nVerificación predictiva a priori\n\n\n\nCon este tipo de verificaciones podemos detectar las consecuencias de nuestros supuestos (incluyendo la elección de distribuciones a priori), así como otras decisiones de modelado (como la discretización).\nConflictos con el conocimiento del área deben ser explorados para entenderlos y si es necesario corregir nuestros supuestos.\n\n\nEste tipo de verificaciones es muy flexible, y debe adaptarse a los aspectos del conocimiento del área que son importantes para los expertos. Podemos usar todos nuestros recursos analíticos (tablas, resúmenes, gráficas) para producir estos chequeos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-4-probar-el-proceso-de-estimación",
    "href": "02-flujo-basico.html#paso-4-probar-el-proceso-de-estimación",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.4 Paso 4: Probar el proceso de estimación",
    "text": "2.4 Paso 4: Probar el proceso de estimación\nAntes de utilizar datos, verificamos cómo se comporta nuestro proceso de estimación de acuerdo a los supuestos de nuestro modelo generativo.\n\n\n\n\n\n\nVerificación a priori\n\n\n\nLo mínimo que esperamos de nuestro método es que, bajo nuestros propios supuestos acerca del proceso generador de datos y nuestro procedimiento de estimación definido, nuestra función de estimación no tenga problemas numéricos o de programación, y que las estimaciones que arroja son apropiadas para la cantidad que nos interesa estimar. El procedimiento a grandes rasgos es:\n\nEstablecer valores de los parámetros a estimar\nSimular datos observados (con una \\(N\\) apropiada, dependiendo del tamaño de muestra que esperamos, aunque se puede explorar hacer más grande o más chico este valor).\nCalcular posterior de las cantidades de interés\nCompara los valores de 1) con la posterior de 3)\n\n\n\nDefinir que las posteriores son apropiadas para la cantidad que nos interesa estimar es delicado, y más adelante veremos algunos criterios para evaluar este aspecto. Por lo pronto, haremos algunas pruebas simples que pueden diagnosticar errores graves:\n\ntheta &lt;- 0.2\nN &lt;- 30\n# simular\nset.seed(9914)\ndatos_sim &lt;- sim_pos_neg(theta = theta, N = N)\nposterior &lt;- calcular_posterior(datos_sim$Pos)\nggplot(posterior, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(xintercept = theta, color = \"red\", linetype = \"dashed\")\n\n\n\n\n\n\n\n\nEn este caso, la estimación parece correcta. Podemo repetir el proceso con distintos valores de \\(\\theta\\):\n\nset.seed(21)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      posterior &lt;- calcular_posterior(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\n\n\n\n\nY vemos que en general nuestro método parece funcionar correctamente.\n\n\n\n\n\n\nObservaciones\n\n\n\n\nMás adelante veremos cómo comparar valores a estimar con la posterior a través de varias simulaciones de manera más rigurosa. Por el momento, recuerda que incluso pruebas simples o limitadas son mejores que ninguna prueba.\nTípicamente los valores iniciales se toman de la distribución a priori, como hicimos arriba. Esta prueba es en general más apropiada, pues no nos interesan configuración de parámetros con probabilidad inicial extremadamente baja (imposibles según nuestros supuestos), pero también es posible tomar algunos valores fijos de interés.\nVeremos más de chequeos o pruebas predictivas a priori, que en general también sirven para entender la adecuación del modelo y supuestos en términos de como coinciden o no datos generados con la teoría.\n\n\n\nEste paso también es importante para entender si, bajo nuestros propios supuestos, es factible obtener información útil bajo el diseño que propongamos. Por ejemplo, alguien podría proponer un diseño de muestra que sólo tome 5 personas. Podemos probar cómo se comportan nuestras estimaciones:\n\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 3)\n      posterior &lt;- calcular_posterior(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\n\n\n\n\nNuestra respuesta en este caso es que quizá con 3 personas la información obtenida no será suficiente para tomar decisiones útiles: nótese que la posterior está muy poco concentrada alrededor del verdadero valor de \\(\\theta\\).\n\n2.4.1 Introduciendo un bug\nSupongamos que tenemos un error en el cálculo de la posterior:\n\ncalcular_posterior_bug &lt;- function(muestra, prob_priori){\n  # distribución inicial o a prior\n  theta &lt;- seq(0, 1, length.out = 11)\n  priori &lt;- tibble(theta = theta, prob_priori = (1 - theta) * (1 - theta)) |&gt; \n    mutate(prob_priori = prob_priori / sum(prob_priori))\n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post &lt;- tibble(theta = theta) |&gt; \n      left_join(priori, by = \"theta\") |&gt; \n    # la siguiente línea tiene un error!\n      mutate(prob_posterior = theta ^ Npos * (1 - theta)^((N - Npos * prob_priori))) |&gt; \n    mutate(prob_posterior = prob_posterior / sum(prob_posterior)) \n  prob_post |&gt; select(theta, prob_posterior)\n}\n\nNuestro chequeo apriori se ve entonces:\n\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      posterior &lt;- calcular_posterior_bug(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\n\n\n\n\nDonde vemos en varios casos que la “posterior” está lejos de ser consistente con los valores simulados de prueba para \\(\\theta\\).\n\n\n\n\n\n\nAspectos numéricos\n\n\n\nEs importante notar que los cálculos que hicimos arriba ingoran un principio importante al hacer cálculos de productos de probabilidades: generalmente es mejor utilizar la escala logarítmica para hacer los cálculos, y sólo al final convertir a probabilidades. Esto es porque es fácil tener subflujos numéricos al multiplicar muchas probabilidades pequeñas.\n\n\nAunque en este caso no es crítico, la siguiente función sigue esta práctica que en general es necesario seguir:\n\n# Evitar desbordes al sumar exponenciales\nlog_sum_exp &lt;- function(x){\n  max_x &lt;- max(x)\n  max_x + log(sum(exp(x - max_x)))\n}\ncalcular_posterior &lt;- function(muestra, prob_priori){\n  # evitar 0 o 1 exactos\n  theta &lt;- seq(1e-12, 1 - 1e-12, length.out = 11)\n  # no es necesario normalizar esta distribución apriori\n  log_priori &lt;- tibble(theta = theta, log_prob_priori = 2 * log(1 - theta)) \n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post_tbl &lt;- tibble(theta = theta) |&gt; \n    left_join(log_priori, by = \"theta\") |&gt; \n    # log verosimilitud\n    mutate(log_prob_posterior = \n        Npos * log(theta) + log(1 - theta) * (N - Npos)) |&gt; \n    # sumar log apriori\n    mutate(log_prob_posterior = log_prob_posterior + log_prob_priori) |&gt; \n    mutate(log_prob_posterior_norm = \n      log_prob_posterior - log_sum_exp(log_prob_posterior)) |&gt; \n    mutate(prob_posterior = exp(log_prob_posterior_norm))\n  prob_post_tbl |&gt; select(theta, prob_posterior)\n}\n\nEjercicio: corre las pruebas para esta versión de la función como hicimos arriba. Este es un cambio correcto, y desde el punto de vista de desarrollo, si nuestra batería de pruebas es apropiado podemos hacerlo con más confianza.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-5-analizar-los-datos-y-resumir-resultados.",
    "href": "02-flujo-basico.html#paso-5-analizar-los-datos-y-resumir-resultados.",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.5 Paso 5: Analizar los datos y resumir resultados.",
    "text": "2.5 Paso 5: Analizar los datos y resumir resultados.\nCon este trabajo hecho (ojo: para modelos grandes es un trabajo considerable, pero importante), podemos proceder a analizar los datos.\nSupongamos que se tomó una muestra de \\(N=20\\) personas, con 17 negativos y 3 positivos. Calculamos la posterior:\n\n# en nuestro modelo *no* importa el orden, verifica:\ndatos_tbl &lt;- tibble(Pos = c(rep(1, 3), rep(0, 17)))\nposterior &lt;- calcular_posterior(muestra = datos_tbl$Pos)\nggplot(posterior, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") \n\n\n\n\n\n\n\n\nY hay varias maneras de resumir esta posterior. Por ejemplo, podemos calcular (ojo: veremos más detalles de esto más adelante):\n\n# Media\nposterior |&gt; \n  mutate(theta = theta) |&gt; \n  summarise(media = sum(theta * prob_posterior))\n\n# A tibble: 1 × 1\n  media\n  &lt;dbl&gt;\n1 0.166\n\n# Intervalo de alta probabilidad 90%\nposterior |&gt; \n  mutate(theta = theta) |&gt; \n  arrange(desc(prob_posterior)) |&gt; \n  mutate(cumsum = cumsum(prob_posterior)) |&gt; \n  filter(cumsum &lt;= 0.9) |&gt; \n  pull(theta) |&gt; \n  range()\n\n[1] 0.1 0.2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-6-evaluar-el-modelo-y-cómputos",
    "href": "02-flujo-basico.html#paso-6-evaluar-el-modelo-y-cómputos",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.6 Paso 6: Evaluar el modelo y cómputos",
    "text": "2.6 Paso 6: Evaluar el modelo y cómputos\nEn este ejemplo, el modelo es muy simple, y los cómputos son sencillos. Para modelos más complejos es necesario checar que los cómputos sean correctos, y que el modelo ajusta razonablemente bien a los datos en los aspectos que nos interesan, de modo que dejaremos esta discusión cuando veamos el flujo bayesiano más avanzado.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#versión-continua",
    "href": "02-flujo-basico.html#versión-continua",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.7 Versión continua",
    "text": "2.7 Versión continua\nEn el ejemplo anterior utilizamos una variable aleatoria discreta para modelar la seroprevalencia, pero esto generalmente no es conveniente. Ahora repetimos el ejercicio considerando más naturalmente que \\(\\theta\\) puede tomar cualquier valor en \\([0,1]\\).\nPara el paso 1 y 2 (definir modelo generativo y cantidad a estimar), utilizamos el mismo diagrama de arriba y la misma función que simula datos. Igual que antes, para cualquier muestra \\(D\\) compuesta de 0 y 1’s (negativos y positivos), la probabilidad de observar la muestra \\(D\\) dada una conjetura \\(\\theta\\) es:\n\\[ p(D|\\theta) = \\theta^{N_+}(1-\\theta)^{N_-}\\] Y recordamos que desde el punto de vista bayesiano, queremos resumir nuestra información obtenida con la distribución posterior \\(p(\\theta|D)\\), e igual que antes tenemos que:\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta).\\] Por el momento pondremos la densidad continua uniforme \\(p(\\theta) = 1\\) para \\(\\theta\\in [0,1]\\) (densidad uniforme), entonces\n\\[p(\\theta|D) \\propto \\theta^{N_+}(1-\\theta)^{N_-}\\]\nEn este caso, para normalizar tenemos que hacer la integral de la expresión de la derecha, y dividir por el resultado. En general, escribiremos\n\\[B(a,b) = \\int_{0}^1 \\theta^{a-1}(1-\\theta)^{b-1} d\\theta\\] así que en nuestro caso, la posterior es:\n\\[p(\\theta|D) = \\frac{1}{B(N_{+} + 1,N_{-}+1)} \\theta^{N_+}(1-\\theta)^{N_-}\\] Es posible demostrar con cálculo que \\(B(a,b) = \\frac{(a-1)!(b-1)!}{(a+b-1)!}\\), pero eso no es importante ahora. Este tipo de densidades pertenecen a la familia beta con parámetros \\((a,b)\\), donde \\(a&gt;0, b&gt;0\\).\nPor ejemplo, si observamos 2 positivos y tres negativos, nuestra posterior es una beta con parámetros \\((3,4)\\), y se ve así:\n\nlibrary(tidyverse)\ntheta &lt;- seq(0,1, 0.01)\ntibble(theta = theta, densidad = dbeta(theta, 3, 4)) |&gt; \n  ggplot(aes(x = theta, y = densidad)) +\n  geom_line() +\n  labs(x = \"theta\", y = \"Densidad posterior\") \n\n\n\n\n\n\n\n\nNotamos adicionalmente que es posible seleccionar otra distribución inicial que no sea la uniforme. En este caso particular es conveniente (aunque no siempre tiene sentido) usar una distribución beta, de manera que es fácil ver que si ponemos por ejemplo\n\\[p(\\theta) \\propto \\theta^{a-1}(1-\\theta)^{b-1}\\]\nentonces la posterior, por la fórmula de Bayes, es:\n\\[p(\\theta|D) \\propto \\theta^{N_+ +a -1 }(1-\\theta)^{N_{-}+b-1}\\] que también es de la familia beta, pero con parámetros \\((N_{+} +a, N_{-} +b)\\).\n\n2.7.1 Ejercicio: actualizaciones de posterior\nPodemos examinar la posterior para dados distintos datos. Supondremos que la distribución a priori es uniforme.\n\nset.seed(92192)\ntheta_seq &lt;- seq(0,1, 0.001)\ndatos_sim &lt;- sim_pos_neg(theta = 0.25, N = 12) |&gt; \n  mutate(obs = ifelse(Pos==1, \"P\", \"N\")) |&gt; \n  mutate(n = 1:12)\n# graficar posteriores para cada n\ndatos_graf &lt;- datos_sim |&gt; \n  mutate(n_pos = cumsum(Pos), n_neg = cumsum(Neg)) |&gt; \n  mutate(muestra = accumulate(obs, ~ paste0(.x, .y))) |&gt; \n  group_by(n) |&gt;\n  mutate(dens_graf = \n    list(tibble(theta = theta_seq, \n      densidad = dbeta(theta_seq, n_pos + 1, n_neg + 1)))) |&gt; \n  unnest(dens_graf)\nggplot(datos_graf, aes(x=theta, y = densidad, group = n)) +\n  geom_line() + \n  facet_wrap(~ muestra) +\n  geom_abline(slope = 0, intercept = 1, color = \"gray\") \n\n\n\n\n\n\n\n\nAhora repetimos con una inicial beta \\((0,2)\\) (que equivale a observar dos negativos y ningún positivo en una muestra de 3 personas), de modo que \\(p(\\theta) = 2(1-\\theta)\\):\n\nset.seed(92192)\ntheta_seq &lt;- seq(0,1, 0.001)\ndatos_sim &lt;- sim_pos_neg(theta = 0.25, N = 12) |&gt; \n  mutate(obs = ifelse(Pos==1, \"P\", \"N\")) |&gt; \n  mutate(n = 1:12)\n# graficar posteriores para cada n\ndatos_graf &lt;- datos_sim |&gt; \n  mutate(n_pos = cumsum(Pos), n_neg = cumsum(Neg)) |&gt; \n  mutate(muestra = accumulate(obs, ~ paste0(.x, .y))) |&gt; \n  group_by(n) |&gt;\n  mutate(dens_graf = \n    list(tibble(theta = theta_seq, \n                densidad = dbeta(theta_seq, n_pos + 1, n_neg + 3)))) |&gt; \n  unnest(dens_graf)\nggplot(datos_graf, aes(x=theta, y = densidad, group = n)) +\n  geom_line() + \n  facet_wrap(~ muestra) +\n  geom_abline(slope = -2, intercept = 2, color = \"gray\") \n\n\n\n\n\n\n\n\n\nEn este punto, podríamos ir al siguiente paso, que es escribir una función para calcular la posterior. En realidad ya sabemos su función de densidad, pero cualquier resumen que hagamos de esta distribución requerirá de integrales (¿por qué? piensa en cómo calcular la probabilidad de ser menor que un valor, o cómo se calcula la media).\nAunque en este ejemplo simple la posterior tiene una forma conocida y hay manera de calcular (analíticamente o con rutinas numéricas ya implementadas) esos resúmenes de interés (media, cuantiles, etc.), en general calcular integrales no es una estrategia que podamos llevar muy lejos.\n\n\nMás de verificaciones apriori\nAntes de continuar, sin embargo, veremos cómo se veo el chequeo predictivo a priori que consideramos en la sección de arriba.\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # apriori seleccionada\n      theta_sim &lt;- rbeta(1, 1, 3)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\n\nPodemos ver por ejemplo dónde esperamos ver el número de positivos a lo largo de distintas muestras, cuando \\(N=30\\):\n\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos)) |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n`summarise()` has grouped output by 'rep'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\nEste resultado es consecuencia de nuestros supuestos, antes de ver los datos, y resume que esperamos con mayor probabilidad un número bajo de positivos (en una muestra de N=30), y que es muy poco probable que observemos prevalencias muy altas. Dependiendo de la situación, este puede ser un resultado aceptable.\nUn resultado no aceptable para una enfermedad que sabemos que es relativamente rara (aunque tenemos incertidumbre), por ejemplo, podría ser el siguiente:\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # apriori seleccionada\n      theta_sim &lt;- rbeta(1, 30, 3)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos)) |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n`summarise()` has grouped output by 'rep'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\nEste resultado no es aceptable cuando sabemos que es prácticamente imposible que la mayoría de la población está infectada. Debemos entonces regresar y ajustar nuestros supuestos: el problema en este caso es la elección de la distribución a priori para \\(\\theta\\).\nObservación: la crítica es sobre el conjunto completo de supuestos iniciales que hacemos acerca del problema. Cuando los diagnósticos no son aceptables desde el punto de vista teórico es necesario investigar dónde está el problema. Las distribuciones apriori que usamos, igual que cualquier supuesto, están sujetas a esta crítica. Nótese que esta crítica la estamos haciendo sin ver los datos que esperamos observar: es una crítica de supuestos.\n\n\n2.7.2 Métodos Monte Carlo\nUna vez que tenemos la densidad posterior podemos mostrarla o resumirla de varias maneras. Si tenemos una expresión analítica, esos resúmen típicamente consisten de integrales, por ejemplo:\n\nLa media o mediana posterior\nDeciles o u otro tipo de percentiles de la posterior\nIntervalos de probabilidad posterior\n\nEste proceso puede ser no trivial incluso para densidades posteriores conocidas. La alternativa a integrar es simular de la posterior y calcular las cantidades de interés a partir de las simulaciones. En general, esto es más fácil que integrar. En nuestro ejemplo, en lugar de usar una función de calcular_posterior, construimos una que es simular_posterior.\nEsta función será simple porque simular de una beta es un problema estándar, y existen muchas implementaciones. Podríamos escribir, por ejemplo:\n\nsimular_posterior &lt;- function(muestra, n){\n  tibble(theta = \n    rbeta(n, sum(muestra) + 1, length(muestra) - sum(muestra) + 1))\n}\n\n\nmuestra\n\n[1] 1 0 0 1 0\n\nsims_post &lt;- simular_posterior(muestra, 10000)\n\n\nsims_post |&gt; \n  ggplot(aes(x = theta)) +\n  geom_histogram(bins = 50)\n\n\n\n\n\n\n\n\nSi queremos calcular la media, por ejemplo, hacemos\n\n sims_post |&gt; pull(theta) |&gt;  mean()\n\n[1] 0.4280916\n\n\nSi queremos la probabilidad de que la prevalencia esté por debajo de 20% hacemos:\n\nsims_post |&gt; \n  summarise(prob = mean(theta &lt; 0.2))\n\n# A tibble: 1 × 1\n    prob\n   &lt;dbl&gt;\n1 0.0961\n\n\nMuchas veces se presentan intervalos de probabilidad posterior, por ejemplo, podríamos reportar que con 90% de probabilidad la prevalencia está en el siguiente intervalo:\n\nsims_post |&gt; \n  summarise(inf = quantile(theta, 0.05),\n            sup = quantile(theta, 0.95)) |&gt; \n  mutate(inf = round(inf, 2),\n         sup = round(sup, 2))\n\n# A tibble: 1 × 2\n    inf   sup\n  &lt;dbl&gt; &lt;dbl&gt;\n1  0.16  0.73\n\n\nObservación: No hay un intervalo mágico que debe reportarse (por ejemplo 95% de probabilidad es una costumbre o superstición). Hay varias maneras de construir intervalos de probabilidad. Dejaremos esta discusión para más adelante.\n\n\n\n\n\n\nMétodos Monte Carlo\n\n\n\nLos métodos Monte Carlo están basados en simulación de variables aleatorias. Las cantidades que nos interesan son integrales bajo una densidad de probabilidad. Si queremos calcular en general \\[I = \\int f(x)p(x)dx,\\] simulamos una gran cantidad de observaciones \\(x_1,\\ldots, x_M\\) bajo \\(p(x)\\), y entonces (Ley de los grandes números):\n\\[\\frac{1}{M} \\sum_{i=1}^{M} f(x_i) \\to I\\] cuando \\(M\\to \\infty\\). De este modo, podemos aproximar con la precisión que requiramos la integral \\(I\\).\n\n\nNota 1: Sin más información del proceso de simulación, no es posible demostrar que una aproximación es “suficientemente” buena, no importa que tan grande sea \\(M\\). Más adelante veremos una batería de diagnósticos para al menos excluir los casos comunes en los que la aproximación es mala.\nNota 2: En nuestro caso, las integrales de interés usualmente son de la forma \\[I = \\int f(\\theta)p(\\theta|D) d\\theta,\\] donde \\(D\\) es la información de la muestra, \\(\\theta\\) en general es un vector de parámetros del modelo, y \\(f(\\theta)\\) es una función de \\(\\theta\\) que nos interesa. Por ejemplo, para la media posterior de \\(\\theta\\), usaríamos \\(f(\\theta) = \\theta\\). Podemos aproximar cualquier integral si tenemos simulaciones de la posterior:\n\\[\\theta_i \\sim p(\\theta|D) \\implies \\frac{1}{M} \\sum_{i=1}^{M} f(\\theta_i) \\to I.\\]\n\nFinalmente, checamos todo nuestra construcción de estimación como hicimos arriba, la diferencia es que ahora usamos simulaciones para entender el comportamiento de la posterior. En este caso, el proceso es como sigue:\n\nGeneramos un valor de la apriori \\(\\theta_{sim} \\sim \\text{Beta}(1,3)\\)\nSimulamos datos de la muestra (\\(N=25\\)) con el valor simulado de \\(\\theta\\)\nSimulamos un número grande \\(M\\) de valores de la posterior (aquí usaremos \\(M=10000\\))\nRepetimos 1-3\n\n\nset.seed(812)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 25)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior(datos_sim$Pos, 10000)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\nsimular_posterior &lt;- function(muestra, n){\n  tibble(theta = \n    rbeta(n, sum(muestra) + 1, \n             length(muestra) - sum(muestra) + 3))\n}\n\nAhora usamos histogramas por ejemplo para mostrar cómo luce la posterior, y comparamos con los valores de la simulación:\n\nggplot(simulacion_rep, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#observaciones-1",
    "href": "02-flujo-basico.html#observaciones-1",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.8 Observaciones",
    "text": "2.8 Observaciones\nEl proceso de arriba lo refinaremos considerablemente en el resto del curso.\n\nEn primer lugar, los modelos generativos serán más complicados, y estarán basados en teoría más compleja (que expresamos con diagramas causales)\nUsaremos más herramientas y componentes para construir modelos estadísticos apropiados, ya sea que construyamos un modelo completo para todo el proceso de generación de datos, o que usemos modelos estándar como regresión para aproximar respuestas, cuando es apropiado\nRefinaremos el proceso de checar que el cómputo (checar Monte Carlo) y la inferencia (verificación apriori) es correcta bajo nuestros supuestos.\nFinalmente, veremos qué hacer después de hacer la estimación y que los puntos de arriba están resueltos, para tener confianza en nuestras conclusiones.\n\n\n2.8.1 Resumen\nAquí juntamos algunas observaciones que se derivan de lo que hemos visto (flujo de trabajo y estimación bayesiana):\n\nTodo nuestro trabajo está fundamentado en entender qué es lo que queremos estimar dentro de un modelo generativo. Los diagramas causales nos ayudan a conectar el problema de interés con nuestros modelos, a construir modelos generativos y hacer explícitos nuestros supuestos.\nEl proceso de estimación siempre es el mismo: nuestro estimador es la distribución posterior, que se construye a partir de la verosimilitud y la apriori (modelo generativo). Nuestro estimador es la posterior de las cantidades de interés, que pueden resumirse de distintas maneras. Cualquier cálculo derivado de otras cantidades de interés debe considerar toda la posterior (no solo la media o la moda, etc. posterior).\nNuestro proceso incluye los chequeos predictivos a priori (basados en simulación de datos). Esto son cruciales para detectar problemas en nuestros supuestos (vs teoría) y que nuestro proceso sea internamente consistente. Esto también es una verificación de la información a priori.\nGeneralmente es más conveniente y práctico hacer simulaciones que calcular analíticamente la posterior o sus integrales.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico-2.html",
    "href": "02-flujo-basico-2.html",
    "title": "3  Flujo de trabajo básico: refinando el modelo",
    "section": "",
    "text": "3.1 Prevalencia con error conocido\nNuestro ejemplo de la sección anterior es poco realista pues usualmente las pruebas que son utilizadas para medir la prevalencia no son perfectas. Bajo condiciones muy controladas, el perfil de desempeño de las pruebas se mide, obteniendo resultados son del siguiente tipo:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Flujo de trabajo básico: refinando el modelo</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico-2.html#prevalencia-con-error-conocido",
    "href": "02-flujo-basico-2.html#prevalencia-con-error-conocido",
    "title": "3  Flujo de trabajo básico: refinando el modelo",
    "section": "",
    "text": "En pruebas de gold standard, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas.\nSin considerar la incertidumbre, esto implica que la prueba tiene una sensibilidad de 84% y una especificidad de 99.5%.\n\n\n3.1.1 Paso 1: modelo generativo\nPrimero supondremos que estos porcentajes de error son fijos. Nuestro modelo que incluye el error de medición se como sigue:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    p\n    Npos\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    Nobs [label = &lt;N&lt;SUB&gt;obs&lt;/SUB&gt;&gt;]\n    #Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    p -&gt; Npos\n    #p -&gt; Nneg\n    N -&gt; Npos\n    Npos -&gt; Nobs\n    #N -&gt; Nneg\n    esp -&gt; Nobs\n    sens -&gt; Nobs\n    #esp -&gt; Nneg\n    #sens -&gt; Nneg\n{ rank = same; p; N }\n{ rank = same; Npos}\n{ rank = max; sens; esp}\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nDonde vemos ahora que el estado real de cada persona de la prueba es desconocido, aunque el resultado de la prueba depende de ese estado, y la cantidad de positivos que observamos es ahora \\(N_{obs}\\), que depende también de la sensibilidad y especificidad de la prueba.\nY para constuir el modelo generativo notamos que la probabilidad de que un individuo infectado salga positivo es \\(\\text{sens}\\), y la probabilidad de que un individuo no infectado salga positivo es \\((1-\\text{esp})\\). De este modo, el modelo generativo es:\n\nsim_pos_neg &lt;- function(theta = 0.01, N = 20, sens = 0.84, esp = 0.995) {\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, theta)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra: si es positivo, calculamos\n  # la probabilidad de que realmente sea positivo\n  sim_tbl &lt;- tibble(Pos_verdadero, Neg_verdadero) |&gt; \n    mutate(Pos = rbinom(N, 1, Pos_verdadero * sens + Neg_verdadero * (1-esp))) |&gt; \n    mutate(Neg = 1 - Pos)\n  # Observaciones\n  sim_tbl |&gt; select(Pos, Neg)\n}\n\nHacemos unas pruebas:\n\nset.seed(8212)\nsim_pos_neg(theta = 0.3, N = 1e7, sens = 0.7, esp = 1) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.2099\n\nsim_pos_neg(theta = 0.3, N = 1e7, sens = 1, esp = 1) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.3001\n\n\n\n\n3.1.2 Paso 2: cantidad a estimar\nEn este punto hay que tener cuidado, porque no queremos estimar la proporción de positivos potenciales en la población (pues la prueba es imperfecta), sino la proporción de verdaderos positivos en la población. Esta cantidad sigue siendo representada por \\(\\theta\\) en nuestro modelo generativo.\n\n\n3.1.3 Paso 3: modelo estadístico\nEl modelo estadístico es ahora diferente. Vamos a plantear primero \\(p(D|\\theta, sens, esp)\\), que es la probabilidad de observar los datos \\(D\\) dado que \\(\\theta\\) es el parámetro de interés, y \\(sens\\) y \\(esp\\) (que en este caso suponemos conocidos). Es fácil ver que la probabilidad de obtener un positivo ahora es:\n\\(\\theta_{obs} = P(Positivo | \\theta, sens, esp) = \\theta \\cdot sens + (1-\\theta) \\cdot (1-esp)\\)\nSi llamamos a esta cantidad \\(\\theta_{obs}\\), de forma que dada una muestra de 0’s y 1’s, tenemos que la verosimilitud de la muestra dada cada conjetura \\(\\theta\\), y con \\(sens\\) y \\(esp\\) fijas, es:\n\\[p(D|\\theta, sens, esp) = \\theta_{obs}^{N_{+}}(1-\\theta_{obs})^{N_{-}}\\] Suponiendo que la distribución apriori de \\(\\theta\\) es uniforme, tenemos entonces que la distribución posterior cumple:\n\\[p(\\theta|D, sens, esp) \\propto \\theta_{obs}^{N_{+}}(1-\\theta_{obs})^{N_{-}}\\] donde \\(\\theta_{obs}\\) está dada por la fórmula de arriba. Sustituyendo:\n\\[p(\\theta|D, sens, esp) \\propto (\\theta \\cdot sens + (1-\\theta) \\cdot (1-esp))^{N_{+}}(\\theta(1-sens) + (1-\\theta)esp)^{N_{-}}\\]\nEsta posterior tiene la estructura de una distribución beta, pero es un poco más complicada. En este punto, utilizaremos una técnica que funciona para problemas chicos (de unos cuantos parámetros), y que consiste en hacer una aproximación discreta de la distribución posterior:\n\n\n\n\n\n\nMétodo de aproximación de rejilla\n\n\n\n\nDividimos el intervalo \\([0,1]\\) en \\(m\\) partes iguales, y calculamos el valor de la expresión proporcional a la posterior en cada uno de estos intervalos (por ejemplo en los puntos medios).\nNormalizamos estos valores para que sumen 1, y obtenemos una distribución discreta que aproxima la posterior.\nMuestreamos de esta distribución discreta para obtener una muestra de la posterior.\n\nEste método sólo es factible en modelos simples cuando hay solamente unos cuantos parámetros por estimar, pues su complejidad crece exponencialmente con el número de parámetros. Rara vez se usa en la práctica por esta razón.\n\n\nAquí implementamos esta técnica de aproximación por rejilla. Incluimos también una Beta(1,3) como a priori:\n\nsimular_posterior_error &lt;- function(muestra, n, sens = 1, esp = 1){\n    theta &lt;- seq(1e-12, 1-1e-12, by = 0.0001)\n    p_obs &lt;- theta * sens + (1 - theta) * (1 - esp)\n    # verosimilitud (en logaritmo)\n    log_dens_sin_norm &lt;- log(p_obs) * sum(muestra) +  \n      log(1-p_obs) * (length(muestra) - sum(muestra))\n    # a priori\n    log_dens_sin_norm &lt;- log_dens_sin_norm + dbeta(theta, 1, 3, log = TRUE)\n    # normalizar\n    log_dens_norm &lt;- log_dens_sin_norm - log_sum_exp(log_dens_sin_norm)\n    densidad_post &lt;- exp(log_dens_norm)\n    tibble(theta = sample(theta, size = n, replace = TRUE, prob = densidad_post))\n}\n\nY ahora podemos ver cómo se ve la posterior:\n\nset.seed(328)\nuna_muestra &lt;- sim_pos_neg(theta = 0.2, N = 600, sens = 0.6, esp = 0.999)\nmean(una_muestra$Pos)\n\n[1] 0.1233333\n\nsims_post_error &lt;- \n  simular_posterior_error(una_muestra$Pos, 5000, sens = 0.6, esp = 0.999) \nsims_post_error |&gt;\n  ggplot(aes(x = theta)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nAhora seguimos el flujo. Agregaremos la verificación a priori para entender si nuestro modelo recupera los parámetros.\n\nset.seed(8112)\nsimulacion_rep_error &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 150, sens = 0.6, esp = 0.999)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior_error(datos_sim$Pos, 10000, sens = 0.6, esp = 0.999)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\n\nAhora usamos histogramas por ejemplo para mostrar cómo luce la posterior, y comparamos con los valores de la simulación:\n\nggplot(simulacion_rep_error, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\n\n\n\nFigura 3.1: Verificación a priori\n\n\n\n\n\nContrasta con lo que pasaría si usaramos el modelo sin considerar fuentes de error:\n\nset.seed(812)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 150, sens = 0.6, esp = 0.999)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior_error(datos_sim$Pos, 10000, 1, 1)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\n\n\nggplot(simulacion_rep, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\n\n\n\nFigura 3.2: Verificación a priori fallida (modelo incorrecto)\n\n\n\n\n\nEste resultado está lejos de ser aceptable.\nComparamos esta densidad con lo que obtendríamos sin considerar el error de medición, con los mismos datos:\n\nset.seed(8)\nsims_post &lt;- \n  simular_posterior_error(una_muestra$Pos, 5000, 1, 1)\nambas_sims_tbl &lt;- \n  sims_post_error |&gt;\n  mutate(tipo = \"Con error de medición\") |&gt;\n  bind_rows(sims_post |&gt;\n              mutate(tipo = \"Sin error de medición\"))\nambas_sims_tbl |&gt; ggplot(aes(x = theta, fill = tipo)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 50) +\n  scale_fill_manual(values = c(\"red\", \"blue\")) +\n  geom_vline(xintercept = 0.2, linetype = \"dashed\", color = \"black\")\n\n\n\n\n\n\n\n\nY vemos que la diferencia entre las distribuciones es considerable. En primer lugar, la distribución con error de medición es más ancha (hay más incertidumbre). En segundo lugar, como estimador de el parámetro de interés, nuestro modelo que no considera el error parece dar estimaciones sesgadas hacia abajo. Esto es porque la prevalencia no es tan baja, y la sensibilidad de la prueba no es muy buena, de manera que con el modelo con error inferimos correctamente que hay más prevalencia que lo que indicaría la proporción de positivos en las pruebas.\nAunque este ejemplo es claro, prevalencia, sensibilidad y especificidad interactúan de maneras a veces poco intuitivas.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Flujo de trabajo básico: refinando el modelo</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico-2.html#prevalencia-con-datos-de-referencia",
    "href": "02-flujo-basico-2.html#prevalencia-con-datos-de-referencia",
    "title": "3  Flujo de trabajo básico: refinando el modelo",
    "section": "3.2 Prevalencia con datos de referencia",
    "text": "3.2 Prevalencia con datos de referencia\nAhora haremos un paso adicional: los valores de sensibilidad y especificidad generalmente no son conocidos con certeza, sino que son estimados a partir de una muestra de “estándar de oro”. En esta prueba particular, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas. Consideraremos 122 y 401 como tamaños de muestra fijos y conocidos (las personas fueron extraídas de otra población).\nDenotamos como \\(Ref\\) a los datos de referencia de “estándar de oro”.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta\n    esp\n    sens\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n  node [shape=plaintext]\n    Nobs [label = &lt;N&lt;SUB&gt;obs&lt;/SUB&gt;&gt;]\n   # Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n  edge [minlen = 3]\n    theta -&gt; Npos\n    #p -&gt; Nneg\n    N -&gt; Npos\n    Npos -&gt; Nobs\n    #N -&gt; Nneg\n    esp -&gt; Nobs\n    sens -&gt; Nobs\n    #esp -&gt; Nneg\n    #sens -&gt; Nneg\n    esp -&gt; Ref\n    sens -&gt; Ref\n{ rank = same; theta; N }\n#{ rank = same; Npos; Nneg}\n{ rank = max; sens; esp}\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nUsando argumentos como los del modelo original, las distribuciones de esp y sens son beta y podemos incorporarlas en la simulación de la posterior. Nuestra nueva función para simular el proceso generativo es:\n\nsim_pos_neg &lt;- function(p = 0.01, N = 20, pos_gold = c(103,122), neg_gold = c(399,401)) {\n  # Simular especificidad y sensibilidad\n  sens &lt;- rbeta(1, pos_gold[1] + 1, pos_gold[2] - pos_gold[1] + 1)\n  esp &lt;- rbeta(1, neg_gold[1] + 1, neg_gold[2] - neg_gold[1] + 1)\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, p)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra: si es positivo, calculamos\n  # la probabilidad de que realmente sea positivo\n  sim_tbl &lt;- tibble(Pos_verdadero, Neg_verdadero) |&gt; \n    mutate(Pos = rbinom(N, 1, Pos_verdadero * sens + Neg_verdadero * (1-esp))) |&gt; \n    mutate(Neg = 1 - Pos)\n  # Observaciones\n  sim_tbl |&gt; select(Pos, Neg)\n}\n\nConsiderando que tenemos tres parámetros, en este punto decidimos no hacer la aproximación de rejilla. Es posible hacer otro tipo de aproximaciones (por ejemplo cuadráticas), pero en lugar de esto veremos cómo lo haríamos con Stan. Más adelante discutiremos los algoritmos que Stan utiliza para simular de la posterior de modelos muy generales. Por el momento, notamos que está basado en un algoritmo de simulación MCMC (Markov Chain Montecarlo), que es el estándar para modelos que no son muy simples. Este ejemplo es para ilustrar cómo resolveríamos el problema más general, no es necesario que en este punto entiendas cómo funciona o los detalles de la implementación.\n\nlibrary(cmdstanr)\nmod_sc &lt;- cmdstan_model(\"./src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; n;\n  int&lt;lower=0&gt; kit_pos;\n  int&lt;lower=0&gt; n_kit_pos;\n  int&lt;lower=0&gt; kit_neg;\n  int&lt;lower=0&gt; n_kit_neg;\n}\n\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; //seroprevalencia\n  real&lt;lower=0, upper=1&gt; sens; //sensibilidad\n  real&lt;lower=0, upper=1&gt; esp; //especificidad\n}\n\ntransformed parameters {\n  real&lt;lower=0, upper=1&gt; prob_pos;\n\n  prob_pos = theta * sens + (1 - theta) * (1 - esp);\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  // modelos para resultados del kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales para cantidades no medidas\n  theta ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\n\nn &lt;- 50\nN &lt;- 3300\ndatos_lista &lt;- list(N = 3300, n = 50,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste &lt;- mod_sc$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\nsims &lt;- ajuste$draws(c(\"theta\", \"sens\", \"esp\"), format = \"df\")\nresumen &lt;- ajuste$summary(c(\"theta\"))\n\n\nresumen |&gt; select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean      q5    q95\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 theta    0.0104 0.00243 0.0174\n\n\nY podemos graficar la posterior de la seroprevalencia:\n\nggplot(sims, aes(x = theta)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nY vemos que los datos son consistentes con el dato reportado por los autores (alrededor de 1.2%), pero que no podemos excluir valores de prevalencia muy bajos (por abajo de 0.3% por ejemplo). Por otro lado, también son consistentes valores muy altos de seroprevalencia, de manera que este estudio resultó ser poco informativo de la IFR del COVID.\nPodemos hacer diagnósticos adicionales acerca de la razón de esta variabilidad alta, si graficamos la relación entre especificidad de la prueba y estimación de prevalencia:\n\nggplot(sims, aes(x = esp, y = theta)) + geom_point() +\n  xlab(\"Especificidad del kit\") + ylab(\"Prevalencia\") + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nLa asociación entre estas dos cantidades es interesante porque conceptualmente (y desde punto de vista del modelo), no hay relación entre estas dos variables: su asociación aparece porque son causas que compiten para explicar una observación.\nNótese que dada la prevalencia baja, la especificidad del kit es un factor importante para explicar la prevalencia observada, pero si no pensamos con cuidado podríamos concluir que los falsos positivos no deberían ser problema por que la especificidad para ser muy buena.\nY notamos que aún con una muestra relativamente grande, el rango de \\(\\theta\\) es considerable: va desde valores cercanos a 0 hasta valores alrededor de 0.025-0.03.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Flujo de trabajo básico: refinando el modelo</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html",
    "href": "03-modelos-genericos.html",
    "title": "4  Componentes de modelación 1",
    "section": "",
    "text": "4.1 Predicciones sin explicación\nEs posible obtener buenas predicciones con modelos estadísticos genéricos sin tener una explicación de cómo funciona el fenómeno que estamos modelando. Estos modelos, aunque pueden resultar en predicciones muy buenas y ser útiles, pueden ser riesgosos si se interpretan fuera de un contexto teórico con supuestos claros.\nEl primer ejemplo es de nuestra referencia de McElreath (2020): los epicilos planetarios del modelo geocéntrico para explicar el movimiento retrógrado de planetas en el cielo. Este modelo fue exitoso y muy preciso para calcular las posiciones futuras de los planetas en el cielo, pero sus fundamentos eran incorrectos: no es posible interpretar este modelo por sí solo para entender cómo funciona el sistema solar.\nModelos genéricos como regresión lineal o logística, métodos basados en árboles, redes neuronales típicamente caen en esta categoría de modelos de tipo “geocéntrico”: aunque pueden ser efectivos para predecir, debemos ser cuidadosos en su interpretación en términos de causas, efectos, y mecanismos del fenómeno que nos interesa.\nPodemos aplicar con éxito estas componentes de modelación si entendemos su papel: estos modelos genéricos no contienen o nos dan causas o mecanismos por sí solos, pero pueden ayudarnos extraer información causal bajo los supuestos apropiados.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#ejemplo-regresión-lineal",
    "href": "03-modelos-genericos.html#ejemplo-regresión-lineal",
    "title": "4  Componentes de modelación 1",
    "section": "4.2 Ejemplo: regresión lineal",
    "text": "4.2 Ejemplo: regresión lineal\nEn este ejemplo, introducimos notación para representar modelos, usaremos posteriores con varios parámetros, y veremos cómo construir y aplicar modelos lineales, todo desde el punto de vista de nuestro flujo de trabajo.\nEn este ejemplo de McElreath (2020) queremos describir la relación entre peso y estatura de adultos de una población relativamente homogénea. Nuestro modelo causal es como sigue:\n\nEn primer lugar, la estatura (\\(H\\)) de las personas adultas influye en su peso (\\(W\\)). El peso, está influenciado también por otras variables no observadas:\n\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    U\n  node [shape=plaintext]\n    H\n    W\n  edge [minlen = 3]\n    H -&gt; W\n    U -&gt; W\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nNótese que no consideramos \\(W\\to H\\), porque podemos pensar en varias intervenciones que podrían cambiar el peso por no cambian la estatura. Por otro lado, es difícil pensar en alguna intervención que cambie la estatura pero no cambie el peso de una persona. Adicionalmente, hay otros factores desconocidos no observados \\(U\\) que afectan el peso de cada persona adicionalmente a su estatura.\nAhora pasamos la modelo generativo. Supondremos que el peso de una persona adulta depende de su estatura de manera lineal, de forma que podemos escribir:\n\\[W = \\alpha + \\beta H + U\\] Como \\(U\\) no es observada, tenemos que definir cómo generar esta variable. Una distribución natural para esta variable es una distribución normal con media 0 y desviación estándar \\(\\sigma\\) no conocida, que escribimos como \\(U\\sim N(0,\\sigma)\\). Tenemos entonces que dados los valores \\(\\alpha\\) y \\(\\beta\\),\n\\[E[W|H] = \\alpha + \\beta H,\\] así que el valor esperado del peso de una persona, dada su estatura, es una función lineal de la estatura. La variable \\(U\\) representa la variabilidad en peso alrededor de este valor esperado. Usamos la distribución normal considerando que es una agregación de varias perturbaciones pequeñas, no relacionadas con estatura, que afectan el peso de una persona (aunque este supuesto también tiene que validarse).\nAdicionalmente, tenemos que hacer supuestos acerca del proceso generador para la estatura \\(H\\). Por el momento, y para ejemplificar, supondremos que la estatura es una variable normal con media en 160 cm y desviación estándar de 10cm.\nEmpezamos a escribir nuestro modelo generativo:\n\nsim_peso &lt;- function(n= 10, alpha, beta, sigma){\n  # simular estatura\n  H &lt;- rnorm(n, 160, 10)\n  # simular perturbación de peso\n  U &lt;- rnorm(n, 0, sigma)\n  # regresión lineal de peso dado estatura\n  W &lt;- alpha + beta * H + U\n  tibble(H, W)\n}\n\nPodemos checar nuestro modelo generativo con simulaciones predictivas a priori: generamos una muestra y checamos con el conocimiento del área:\n\nset.seed(9)\nsim_peso(100, alpha = 0, beta = 0.5, sigma = 5) |&gt; \n  ggplot(aes(x = H, y = W)) +\n  geom_point() +\n  labs(x = \"Estatura (cm)\", y = \"Peso (kg)\")\n\n\n\n\n\n\n\n\nPodemos escribir este generativo siguiendo el código de la función de arriba. Si cada persona la denotamos por un índice \\(i\\) entonces:\n\\[\n\\begin{align}\nW_i &= \\alpha + \\beta H_i + U_i \\\\\nU_i &\\sim N(0,\\sigma) \\\\\nH_i &\\sim N(160, 10)\n\\end{align}\n\\] De lado izquierdo están las variables, del lado derecho las definiciones, igualdad significa una relación determinística y \\(\\sim\\) significa “se distribuye como”.\nAhora podemos plantear nuestra pregunta inicial en términos de este modelo: nos interesa describir cómo cambia el peso esperado de una persona dependiendo de su estatura, es decir, describir la recta\n\\[ \\alpha + \\beta H\\] Con esto hemos terminado los primeros paso de nuestro flujo (modelo causal, modelo generativo, cantidad a estimar).\nNuestro método de estimación es bayesiano, así que podemos ser más específicos y decir que nos interesa la distribución posterior de \\(\\alpha,\\beta\\) dado datos observados. Otra manera de decir esto es que nos interesa describir la posterior de la recta \\(\\alpha + \\beta H\\).\nNótese en particular que en este ejemplo no nos interesa el proceso generador de \\(H\\), y dado nuestro diagrama causa, podemos considerar el análisis condicional a los valores que observamos de estatura.\nAhora podemos plantear nuestra estrategia de modelación estadística. Tenemos tres parámetros desconocidos \\(\\alpha,\\beta,\\sigma\\), y tenemos por la regla de bayes la posterior está dada por:\n\\[p(\\alpha,\\beta,\\sigma|W_i,H_i)\\propto p(W_i|H_i, \\alpha,\\beta,\\sigma)p(\\alpha,\\beta,\\sigma)\\] De modo que sólo nos interesa entender como es el peso condicional a la estatura, y por eso nuestra verosimilitud sólo considera \\(W_i\\) condicional a \\(H_i\\) (desde el punto de vista del diagrama, nos interesa modelar el nodo \\(W\\). En otros casos, quizá buscaríamos modelar la distribución conjunta de \\(W_i,H_i\\).\nAhora tenemos que poner distribuciones a priori \\(p(\\alpha, \\beta,\\sigma)\\) para los parámetros desconocidos, y continuar con nuestro flujo de modelación haciendo verificaciones a priori.\n\n\n\n\n\n\nDistribuciones a priori\n\n\n\nLa propuesta de distribuciones a priori depende de manera cercana de nuestras verificaciones a prior, como veremos más adelante. En general no existen distribuciones a priori “correctas”, sino justificables desde el punto de vista del conocimiento del área.\nLos chequeos a priori nos permite entender las consecuencias de nuestras decisiones acerca de las iniciales. Nótese que todo este trabajo se hace antes de ver los datos, lo que implica que no estamos buscando “sacar el resultado que queremos” de los datos.\n\n\n\n4.2.1 Distribuciones a priori\nEn primer lugar, haremos este trabajo más fácil si parametrizamos la recta de regresión de la siguiente manera, donde restamos a la estatura un valor típico de la distribución de estaturas (también puede usarse la media los datos, más comunmente, pero en este ejemplo tomamos un valor fijo para simplificar la explicación):\n\\[E[W|H] =  \\alpha + \\beta (H - 160)\\]\nLas apriori o iniciales expresan conocimiento del área (incluyendo las unidades que se están utilizando), y actúan como restricciones suaves. Supondremos que peso está en kilogramos y estatura en centímetros.\n\nCuando \\(H=160\\) esperamos que \\(W\\) esté alrededor de 50-70 kg, así que podemos centrar \\(\\alpha\\) en 60. Las unidades de \\(\\alpha\\) son kg. Una inicial (verificaremos dentro de un momento esa decisión) puede ser \\(\\alpha\\sim N(60, 10)\\). Recordemos que esto implica que \\(\\alpha\\) están dentre 60 - 2(10) = 40 y 60 + 10(2) = 80 con probabilidad 0.95, lo cual es considerable pero no excesivamente amplio para una persona de estatura 160cm.\nSi \\(\\alpha\\) es está alrededor de 60, la constante de proporcionalidad \\(\\beta\\) debe ser positiva, y no muy lejana de un valor entre 0 y 2. La razón es que no tiene sentido esperar que un aumento de 10 cm tenga un aumento esperado de peso de 20 kilos, por ejemplo. Podríamos poner una inicial como \\(\\beta\\sim N^+(0, 1)\\) (normal truncada en 0) por ejemplo. Esta distribución tiene los siguientes percentiles:\n\n\nquantile(rnorm(10000, 0, 1) |&gt; abs(), probs = seq(0, 1, 0.1)) |&gt; \n  round(3)\n\n   0%   10%   20%   30%   40%   50%   60%   70%   80%   90%  100% \n0.000 0.124 0.251 0.383 0.518 0.673 0.839 1.032 1.269 1.618 3.818 \n\n\nFinalmente, tenemos que poner una inicial para \\(\\sigma\\). Debe ser positiva, y representa la variabilidad que hay en el peso que no se debe a la estatura. Una inicial razonable es \\(\\sigma\\sim N^+(0, 20)\\), por ejemplo.\nQuedamos entonces con:\n\\[\n\\begin{align}\nW_i &= \\alpha + \\beta (H_i - 160) + U_i \\\\\nU_i &\\sim N(0,\\sigma) \\\\\n\\alpha &\\sim N(60, 10) \\\\\n\\beta &\\sim N^+(0, 1) \\\\\n\\sigma &\\sim N^+(0, 20) \\\\\n\\end{align}\n\\]\n\n\nChequeo predictivo a priori\nAhora podemos simular de la a priori cuáles son las posibilidades que estamos considerando. Utilizaremos valores razonables simulados de \\(H\\) para hacer el análisis.\n\nsim_peso_mod &lt;- function(n= 10){\n  alpha &lt;- rnorm(1, 60, 10)\n  beta &lt;- rnorm(1, 0, 1) |&gt; abs()\n  sigma &lt;- rnorm(1, 0, 20) |&gt; abs()\n  \n  # simular estaturas y pesos\n  H &lt;- rnorm(n, 160, 10)\n  mu_W = alpha + beta * (H - 160)\n  # simular perturbación de peso\n  U &lt;- rnorm(n, 0, sigma)\n  # regresión lineal de peso dado estatura\n  W &lt;- mu_W + U\n  tibble(alpha, beta, sigma, H, W)\n}\n\nY hacemos varias replicaciones:\n\nsims_tbl &lt;- map_df(1:20, function(rep) {\n  sim_peso_mod(100) |&gt; mutate(rep = rep)\n})\n\nNuestros supuestos actuales se ven como sigue:\n\nsims_tbl |&gt; \n  ggplot(aes(x = H, y = W)) +\n  geom_point() +\n  geom_abline(aes(intercept = alpha - 160 * beta, slope = beta), data = sims_tbl, color = \"red\") +\n  labs(x = \"Estatura (cm)\", y = \"Peso (kg)\") +\n  facet_wrap(~rep)\n\n\n\n\nSimulaciones predictivas a priori\n\n\n\n\n**Observación*: Esto parece ser razonable, aunque algunas replicaciones son algo extremas (muy poca variabilidad de peso, una relación muy débil o. muy fuerte entre estatura y peso). Comenzaremos con este modelo y seguiremos explorando sus consecuencias.\nNótese que en esta situación, un punto de vista que aparentemente es “conservador” en efecto pone peso en resultados que son infactibles del todo. Por ejemplo, si pusiéramos \\(\\beta\\sim N^+(0,100)\\) y \\(\\sigma\\sim N^+(0, 1000)\\), bajo el argumento de que no tenemos información acerca de \\(\\beta\\) o \\(\\sigma\\), obtendríamos:\n\n\nCódigo\nsim_peso_mod_mal &lt;- function(n= 10){\n  alpha &lt;- rnorm(1, 60, 10)\n  beta &lt;- rnorm(1, 0, 100) |&gt; abs()\n  sigma &lt;- rnorm(1, 0, 1000) |&gt; abs()\n  \n  # simular estaturas y pesos\n  H &lt;- rnorm(n, 160, 10)\n  mu_W = alpha + beta * (H - 160)\n  # simular perturbación de peso\n  U &lt;- rnorm(n, 0, sigma)\n  # regresión lineal de peso dado estatura\n  W &lt;- mu_W + U\n  tibble(alpha, beta, sigma, H, W)\n}\nsims_mal_tbl &lt;- map_df(1:20, function(rep) {\n  sim_peso_mod_mal(100) |&gt; mutate(rep = rep)\n})\nsims_mal_tbl |&gt; \n  ggplot(aes(x = H, y = W)) +\n  geom_point() +\n  geom_abline(aes(intercept = alpha - 160 * beta, slope = beta), data = sims_mal_tbl, color = \"red\") +\n  labs(x = \"Estatura (cm)\", y = \"Peso (kg)\") +\n  facet_wrap(~rep)\n\n\n\n\n\nModelo no realista\n\n\n\n\nEsta es una prueba inicial fallida. Regresaremos a este ejemplo más adelante. En este ejemplo particular que es muy simple y como veremos no es grave permitir algunos resultados algo extremos.\n\n\n\n\n\n\nTip\n\n\n\nEs riesgoso permitir valores de las apriori que no son consistentes con el conocimiento del área. Cuando tenemos muchos datos y relativamente pocos parámetros no es muy importante, pero conforme vayamos avanzando veremos que utilizar supuestos no realistas (como distribuiciones no informativas para los parámetros) tiene consecuencias considerables.\n\n\n\n\nModelo en Stan\nAunque en este punto es posible todavía hacer una aproximación por rejilla (sólo tenemos tres parámetros), escribiremos el modelo en Stan y simularemos de la posterior con MCMC (recuerda que más tarde explicaremos este proceso).\n\nNuestro objetivo ahora es calcular la posterior bajo los supuestos de arriba para datos generados de nuestro modelo, y ver si los cálculos funcionan apropiadamente.\n\nEl modelo en Stan se puede escribir como sigue:\n\nlibrary(cmdstanr)\nmod_peso &lt;- cmdstan_model(\"./src/peso-estatura-1.stan\")\nprint(mod_peso)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  h;\n  vector[N]  w;\n}\n\nparameters {\n  real alpha;\n  real &lt;lower=0&gt; beta;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  vector[N] w_media;\n  // determinístico dado parámetros\n  w_media = alpha + beta * (h - 160);\n}\n\nmodel {\n  // partes no determinísticas\n  w ~ normal(w_media, sigma);\n  alpha ~ normal(60, 10);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 20);\n}\n\n\nUna vez que escribimos nuestro modelo, hacemos nuestra siguiente verificación a priori: dados los supuestos del modelo generativo, ¿nuestro estimador funciona apropiadamente para responder la pregunta de interés?\nUtilizaremos una muestra de 350 personas simulada de nuestro proceso generador de datos. En cada caso, buscamos correr nuestro modelo y checar que nuestra estimación de la recta de regresión es consistente con los valores que utilizamos para generar los datos.\n\nset.seed(881)\nsims_inicial_check_tbl &lt;- map_df(1:10, function(rep) {\n  sim_peso_mod(352) |&gt; mutate(rep = rep)\n}) |&gt; nest(datos_sim = c(H, W))\nsims_tbl\n\n# A tibble: 2,000 × 6\n   alpha  beta sigma     H     W   rep\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n 1  61.0 0.203  22.9  165.  37.1     1\n 2  61.0 0.203  22.9  176.  52.4     1\n 3  61.0 0.203  22.9  154.  37.2     1\n 4  61.0 0.203  22.9  162.  70.2     1\n 5  61.0 0.203  22.9  156.  22.5     1\n 6  61.0 0.203  22.9  158.  54.8     1\n 7  61.0 0.203  22.9  173.  77.1     1\n 8  61.0 0.203  22.9  174.  56.9     1\n 9  61.0 0.203  22.9  150.  41.4     1\n10  61.0 0.203  22.9  150.  41.6     1\n# ℹ 1,990 more rows\n\n\nEn la siguiente gráfica vemos un comportamiento razonable de nuestro proceso de estimación. Recuerda que cada punto negro representa una simulación de la posterior, y el punto rojo es el valor que usamos para hacer la simulación de cada recuadro:\nOjo: los ejes de los recuadros varían con la simulación\n\n# fig-cap: Posterior para datos simulados\ndatos_check_tbl &lt;- sims_inicial_check_tbl |&gt; \n  select(rep, post_tbl) |&gt; \n  unnest(post_tbl)\nggplot(datos_check_tbl, aes(x = alpha, y = beta)) +\n  geom_point(alpha = 0.2) +\n  labs(x = \"alpha\", y = \"beta\") +\n  geom_point(data = sims_inicial_check_tbl, color = \"red\", size = 3) +\n  facet_wrap(~ rep, scales = \"free\") \n\n\n\n\n\n\n\n\nEsta gráfica también podemos hacerla como sigue, usando rectas:\n\n# nota: el intercept en geom_abline es la ordenada al origen\n# mientras que la alpha es valor de la recta para h = 160\ndatos_check_tbl |&gt; \n  ggplot() +\n  geom_abline(aes(intercept = alpha - beta * 160, slope = beta),\n              alpha = 0.5, colour = \"gray\") +\n  facet_wrap(~ rep, scales = \"free\") +\n  scale_x_continuous(limits = c(130, 200)) + \n  scale_y_continuous(limits = c(0, 200)) +\n  geom_abline(data = sims_inicial_check_tbl, \n    aes(intercept = alpha - beta * 160, \n      slope = beta), color = \"red\", linewidth = 1.05)\n\n\n\n\n\n\n\n\nEsta prueba computacional tiene buenos resultados: en general, la posterior se concentra alrededor del valor verdadero de cada simulación. Ahora podemos proceder a cargar los datos reales y hacer una simulación de la posterior.\n\n\n4.2.2 Ajustando el modelo a los datos reales\nCargamos los datos y producimos simulaciones de la posterior.\n\nset.seed(81)\ndatos_tbl &lt;- read_delim(\"../datos/Howell1.csv\", delim = \";\") |&gt; \n  filter(age &gt;= 18)\n\nRows: 544 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (4): height, weight, age, male\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndata_list &lt;- list(\n  N = nrow(datos_tbl),\n  h = datos_tbl$height,\n  w = datos_tbl$weight\n)\n# correr modelo en Stan\nmod_peso_ajuste &lt;- mod_peso$sample(\n  data = data_list,\n  iter_sampling = 2000,\n  refresh = 0)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.4 seconds.\nChain 3 finished in 0.4 seconds.\nChain 4 finished in 0.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 1.7 seconds.\n\n\nLa posterior de los parámetros de la recta se ve como siguen:\n\nsims_peso_post_tbl &lt;- mod_peso_ajuste |&gt; \n  as_draws_df() |&gt; \n  select(.draw, alpha, beta, sigma) \n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n\nggplot(sims_peso_post_tbl)+\n  geom_point(aes(x = alpha, y = beta)) \n\n\n\n\n\n\n\n\nY un resumen simple está dado por:\n\nmod_peso_ajuste$summary(c(\"alpha\", \"beta\", \"sigma\")) |&gt; \n  mutate(across(where(is.numeric),  ~ round(.x, 2)))\n\n# A tibble: 3 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 alpha    48.4   48.4   0.28  0.28 47.9  48.8      1    4900.    5333.\n2 beta      0.63   0.63  0.03  0.03  0.58  0.68     1    4700.    5066.\n3 sigma     4.26   4.25  0.16  0.16  4     4.53     1    5690.    5133.\n\n\n\n\n\n\n\n\nSimulaciones conjuntas\n\n\n\nObserva que los resúmenes marginales (variable por variable) no cuentan la historia completa de la posterior. En nuestro ejemplo, \\(\\alpha\\) y \\(\\beta\\) están correlacionadas en la posterior como muestra la gráfica anterior. Por eso cuando queremos calcular resúmenes de cantidades en las que influyen varios parámetros, es importante trabajar con las simulaciones conjuntas de los parámetros.\n\n\nPuedes ver que en realidad no es posible calcular la distribución de cantidades como \\(\\alpha + 10\\beta\\), por ejemplo, a partir de la información de la tabla de arriba: por ejemplo, la varianza de esta suma no es simplemente la suma de las varianzas",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#distribución-predictiva-posterior",
    "href": "03-modelos-genericos.html#distribución-predictiva-posterior",
    "title": "4  Componentes de modelación 1",
    "section": "4.3 Distribución predictiva posterior",
    "text": "4.3 Distribución predictiva posterior\nDado nuestro modelo, ahora podemos generar cómo se verían observaciones nuevas: en este caso, si tuviéramos una estatura, ¿cómo sería el peso de esa persona? Para esto tenemos que tener en cuenta tanto la posterior de los parámetros como el modelo de los datos.\nEn primer lugar, la posterior de la relación lineal es (cada línea de esta gráfica es una simulación de la posterior):\n\nggplot(sims_peso_post_tbl) +\n  geom_abline(aes(intercept = alpha - beta * 160, slope = beta),\n              colour = \"gray\", alpha = 0.1) +\n  scale_x_continuous(limits = c(130, 180)) +\n  scale_y_continuous(limits = c(20, 70)) \n\n\n\n\n\n\n\n\nEsto nos indican los valores esperados para estatura. Para la predictiva posterior, también tenemos que considerar dónde pueden aparecer individuos. Para simular a una estatura fija, por ejemplo, hacemos lo sugiente:\n\nsim_pred_post &lt;- function(n, sims_peso_post_tbl, h) {\n  # extraer parámetros de la posterior\n  pars &lt;- slice_sample(sims_peso_post_tbl, n = n, replace = TRUE) \n  # simular pesos\n  sims_tbl &lt;- map_df(h, function(h){\n    w_media &lt;- pars$alpha + pars$beta * (h - 160)\n    w &lt;- rnorm(n, w_media, pars$sigma)\n    tibble(rep = 1:n, h = h, w_media = w_media, w = w)\n  })\n  sims_tbl\n}\n\nLas predictivas posteriores para las estaturas \\(h = 160\\) y \\(h=150\\) son:\n\ncomp_ppost_tbl &lt;- sim_pred_post(5000, sims_peso_post_tbl, c(150, 160))\nggplot(comp_ppost_tbl, aes(x =  w, fill = factor(h))) +\n  geom_histogram(bins = 50, alpha = 0.5, position = \"identity\") \n\n\n\n\n\n\n\n\nque como vemos presentan variabilidad considerable más allá de la diferencia de valores esperados. Podemos calcular por ejemplo cuál es la probabilidad de que una persona de 150 cm sea más alta que una de 170 cm:\n\ncomp_ppost_tbl |&gt; \n  select(-w_media) |&gt; \n  pivot_wider(names_from = h, values_from = w) |&gt; \n  summarise(prop = mean(`150` &gt; `160`))\n\n# A tibble: 1 × 1\n   prop\n  &lt;dbl&gt;\n1 0.143\n\n\nY también es más útil calcular la distribución de la diferencia de pesos entre personas de 150 y 160 cm:\n\ncomp_ppost_tbl |&gt; \n  select(-w_media) |&gt; \n  pivot_wider(names_from = h, values_from = w) |&gt; \n  mutate(diferencia = `160` - `150`) |&gt; \nggplot(aes(x = diferencia)) +\n  geom_histogram(bins = 50, alpha = 0.5, position = \"identity\") +\n  labs(x = \"Diferencia de pesos 160 - 150cm\")\n\n\n\n\n\n\n\n\nEn contraste, si comparamos las estaturas medias de cada grupo, que no incluyen variabilidad individual más allá de la producida por la estatura:\n\nggplot(comp_ppost_tbl, aes(x =  w_media, fill = factor(h))) +\n  geom_histogram(bins = 100, alpha = 0.5, position = \"identity\") +\n  labs(x = \"Media de pesos\")\n\n\n\n\n\n\n\n\nPrácticamente tenemos seguridad que la media de pesos de los individuos de 150 cm es menor que la de los de 160 cm.\n\n\n\n\n\n\nTip\n\n\n\nEs importante no confundir el contraste a nivel individuo que hicimos arriba, y el que hicimos a nivel de medias de grupos. Los grupos tienen claramente medias diferentes, pero las distribuciones de individuos tienen traslape considerable.\n\n\nPodemos también resumir la distribución predictiva para distintas estaturas:\n\nresumen_ppost_tbl &lt;- sim_pred_post(20000, sims_peso_post_tbl, \n                                   h = seq(130, 180, 2.5)) |&gt; \n  group_by(h) |&gt; \n  summarise(q5 = quantile(w, 0.05), \n            q95 = quantile(w, 0.95),\n            q_media_5 = quantile(w_media, 0.05),\n            q_media_95 = quantile(w_media, 0.95)) \n\nEn nuestra gráfica anterior tendríamos entonces nuestra recta junto con rangos de 90% para la estatura de los individuos:\n\nggplot(sims_peso_post_tbl) +\n  geom_abline(aes(intercept = alpha - beta * 160, slope = beta),\n              colour = \"gray\", alpha = 0.01) +\n  scale_x_continuous(limits = c(130, 180)) +\n  scale_y_continuous(limits = c(10, 80)) + \n  geom_ribbon(data = resumen_ppost_tbl,\n    aes(x = h, ymin = q_media_5, ymax = q_media_95),\n      fill = NA, colour = \"gray\") + \n  geom_ribbon(data = resumen_ppost_tbl,\n    aes(x = h, ymin = q5, ymax = q95), fill = NA, colour = \"red\")\n\n\n\n\n\n\n\n\n\n4.3.1 Verificaciones de predictiva posterior\nAdemás de ser útil para calcular cantidades de interés de manera natural, la predictiva posterior también está sujeta a crítica y validación. Veremos más de este punto, pero la idea básica es la siguiente:\n\n\n\n\n\n\nVerificaciones de predictiva posterior\n\n\n\nUna vez que tenemos la posterior dados los datos:\n\nTomamos una simulación de todos los parámetros del modelo.\nSimulamos nuevas observaciones (una muestra del mismo tamaño) a partir de los parámetros simulados.\nComparamos los datos simulados con los datos observados (gráficas u otros resúmenes apropiados).\nRepetimos para varias simulaciones.\n\nDiferencias sistemáticas entre datos observados y datos simulados de la predictiva posterior indican fallas del modelo o áreas donde puede mejorar.\n\n\nHay muchas variaciones de este tipo de verificaciones. En nuestro caso podemos hacer manualmente este proceso una vez que tenemos simulaciones de la posterior, tomando las mismas estaturas de los datos y simulando datos del modelo para el peso.\n\nsims_check_post &lt;- sim_pred_post(10, sims_peso_post_tbl, \n                                 h = datos_tbl$height) |&gt; \n  select(-w_media)\nsims_check_post &lt;- bind_rows(sims_check_post, \n   datos_tbl |&gt; mutate(rep = 11) |&gt; select(rep, h = height, w = weight)) |&gt; \n  mutate(rep = digest::digest2int(as.character(rep), seed = 992)) \nggplot(sims_check_post) +\n  geom_point(aes(x = h, y = w), alpha = 0.2) + facet_wrap(~ rep)\n\n\n\n\n\n\n\n\n¿Puedes reconocer dónde están los datos? Si hay desajustes graves y sistemáticas, deberías poder detectarlos en una gráfica de este tipo. Veremos más de este tipo de verificaciones en el curso.\n\n# Respuesta\ndigest::digest2int(\"11\", seed = 992)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#ampliando-el-modelo",
    "href": "03-modelos-genericos.html#ampliando-el-modelo",
    "title": "4  Componentes de modelación 1",
    "section": "4.4 Ampliando el modelo",
    "text": "4.4 Ampliando el modelo\nEntre los adultos humanos, hombres y mujeres tienen distintas distribuciones de peso y estatura. La variable \\(S\\) (sexo) influye tanto en estatura como en peso. La relación la consideramos causalmente partiendo en \\(S\\):\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    U\n    V\n    Z\n  node [shape=plaintext]\n    H\n    W\n    S\n  edge [minlen = 3]\n    H -&gt; W\n    U -&gt; W\n    S -&gt; H\n    S -&gt; W\n    V -&gt; H\n    Z -&gt; S\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nOmitiendo del diagrama las variables no observadas que también son causas únicamente de \\(S\\) y \\(W, H\\):\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n  \n  node [shape=plaintext]\n    H\n    W\n    S\n  edge [minlen = 3]\n    H -&gt; W\n    S -&gt; H\n    S -&gt; W\n\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nSi queremos saber cómo influye el sexo en el peso, este diagrama indica que hay dos tipos de preguntas que podemos hacer:\n\n¿Cuál es el efecto causal de \\(S\\) sobre \\(W\\) (efecto total) ?\n¿Cuál es el efecto causal directo de \\(S\\) sobre \\(W\\)? Es decir, que no actúa a través de \\(H\\).\n\nAunque tenemos un solo modelo causal, pueden construirse distintos modelos estadísticos para contestar cada pregunta. El modelo causal nos dice que si no tenemos causas comunes de \\(S\\) y \\(H\\) y \\(W\\), entonces podemos estimar el efecto total de \\(S\\) sobre \\(W\\) (esto lo formalizaremos más adelante).\nEmpezamos con el efecto total. Para esto, podemos usar el modelo lineal e ignorar la estatura, donde \\(S_i=2\\) si el individuo \\(i\\) es hombre y \\(S_i=1\\) si el individuo \\(i\\) es mujer.\n\\[\n\\begin{align}\nW_i &\\sim N(\\alpha_{S_i}, \\sigma)\\\\\n\\alpha_1,\\alpha_2 &\\sim N(60, 10) \\\\\n\\sigma &\\sim N^+(0, 20) \\\\\n\\end{align}\n\\] Nótese que tenemos dos posibles medias para el peso, una para hombres y otra para mujeres. La estatura no nos importa porque la pregunta es acerca del efecto total de sexo sobre estatura. Para las iniciales podemos seguir un argumento similar al de arriba.\nNota: esta parametrización es más conveniente que utilizar un indicador (o dummy) de sexo en términos de interpetación y en términos de poner iniciales acordes con el conocimiento del área, aunque estadísticamente son equivalentes.\nEl modelo generador simplificado para este caso puede ser:\n\nsim_peso_mod_s &lt;- function(S, alpha, sigma){\n  n &lt;- length(S)\n  W &lt;- rnorm(n, alpha[S], sigma)\n  tibble(alpha_1 = alpha[1], alpha_2 = alpha[2], \n         sigma, S = S, W = W)\n}\n\nDado este modelo generador, ¿cuál es el efecto causal de sexo? Tenemos que definir esta cantidad en términos del modelo. En nuestro caso, definiremos el efecto causal promedio sobre la población, que definimos como la diferencia promedio de estaturas de dos poblaciones: una compuesta enteramente por hombres y otra por mujeres.\n\nset.seed(2021)\n# Fjamos mismos valores de los parámetros para simular dos\n# poblaciones\nsim_hombres &lt;-  sim_peso_mod_s(rep(2, 1000), c(55, 70), 10)\nsim_mujeres &lt;-  sim_peso_mod_s(rep(1, 1000), c(55, 70), 10)\nmean(sim_hombres$W - sim_mujeres$W)\n\n[1] 14.75203\n\n\n\nVerificación a priori\nAhora generamos una población con estos parámetros y vemos si podemos recuperar el efecto causal promedio sobre la población. Nuestro modelo es como definimos arriba:\n\nlibrary(cmdstanr)\nmod_peso &lt;- cmdstan_model(\"./src/peso-estatura-2.stan\")\nprint(mod_peso)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  w;\n  array[N] int s;\n}\n\nparameters {\n  array[2] real alpha;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n\n}\n\nmodel {\n  // modelo para peso\n  w ~ normal(alpha[s], sigma);\n  // también se puede escribir como\n  // for (i in 1:N) {\n  //   w[i] ~ normal(alpha[s[i]], sigma);\n  // }\n  // iniciales\n  alpha ~ normal(60, 10);\n  sigma ~ normal(0, 20);\n}\n\n\nSimulamos datos y ajustamos el modelo, usando los mismos parámetros fijos:\n\nS_sim &lt;- sample(c(1,2), 1000, replace = TRUE)\ndatos_sim_tbl &lt;- sim_peso_mod_s(S_sim, c(55, 70), 10)\n\n\nmod_2_fit &lt;- mod_peso$sample(\n  data = list(N = nrow(datos_sim_tbl), \n              s = datos_sim_tbl$S, \n              w = datos_sim_tbl$W),\n  refresh = 0, seed = 221\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.7 seconds.\n\n\n\nmod_2_fit$summary(c(\"alpha\", \"sigma\"))\n\n# A tibble: 3 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 alpha[1] 55.0   55.0  0.435 0.429 54.2   55.7  1.00    4611.    2866.\n2 alpha[2] 70.9   70.9  0.435 0.444 70.2   71.6  1.00    4350.    2891.\n3 sigma     9.77   9.76 0.223 0.227  9.41  10.1  1.00    4210.    3013.\n\n\nNótese que la diferencia de medias poblacionales es de alrededor de 15 cm, que es lo que esperábamos según el cálculo de arriba. Podemos replicar el cálculo que hicimos arriba directamente usando simulación:\n\nPara cada simulación de la posterior calculamos una población hipotética de hombres y otras de mujeres (mismos parámetros)\nCalculamos la diferencia de medias poblacionales\nResumimos con la posterior.\n\nEsto es fácil hacerlo directamente en Stan, pero en este ejemplo lo calcularemos manualmente:\n\nsims_post_tbl &lt;- mod_2_fit$draws() |&gt; as_draws_df() |&gt; \n  as_tibble()\nsimular_diferencia_post &lt;- function(sims_post_tbl){\n  # Simulamos parámetros de la posterior\n  pars &lt;- sample_n(sims_post_tbl, 1) |&gt; \n    select(starts_with(\"alpha\"), sigma)\n  # Simulamos datos\n  sims_hombres &lt;- sim_peso_mod_s(rep(2, 1000), \n      alpha = c(pars$`alpha[1]`, pars$`alpha[2]`), pars$sigma)\n  sims_mujeres &lt;- sim_peso_mod_s(rep(1, 1000), \n      c(pars$`alpha[1]`, pars$`alpha[2]`), pars$sigma)\n  diferencia &lt;- mean(sims_hombres$W - sims_mujeres$W)\n  # Calculamos la diferencia de medias\n  tibble(diferencia = diferencia) |&gt; bind_cols(pars)\n}\n\n\nsimular_diferencia_post(sims_post_tbl)\n\n# A tibble: 1 × 4\n  diferencia `alpha[1]` `alpha[2]` sigma\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1       15.3       55.5       70.4  9.60\n\n\nY ahora calculamos el resumen de interés, que es la posterior del contraste o diferencia entre las dos poblaciones simuladas. Comparamos con la línea en rojo que es la cantidad que establecimos a estimar:\n\nmap_df(1:4000, ~ simular_diferencia_post(sims_post_tbl) |&gt; \n         mutate(rep = .x)) |&gt;  \nggplot(aes(x = diferencia)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"Efecto de sexo en estatura hombres vs mujeres (cm)\") +\n  geom_vline(xintercept = mean(sim_hombres$W - sim_mujeres$W), \n             color = \"red\", linewidth = 1.5)\n\n\n\n\n\n\n\n\nPuedes repetir este ejercicio para distintos valores de los parámetros, como hicimos en los ejemplos de arriba.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#ajustar-a-los-datos-observados-y-resumir",
    "href": "03-modelos-genericos.html#ajustar-a-los-datos-observados-y-resumir",
    "title": "4  Componentes de modelación 1",
    "section": "4.5 Ajustar a los datos observados y resumir",
    "text": "4.5 Ajustar a los datos observados y resumir\nAhora usamos los datos reales y calculamos el estimador que probamos arriba.\n\nmod_2_fit &lt;- mod_peso$sample(\n  data = list(N = nrow(datos_tbl), \n              s = datos_tbl$male + 1, \n              w = datos_tbl$weight),\n  refresh = 0, seed = 221\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.5 seconds.\n\n\nY repetimos exactamente el proceso que probamos arriba:\n\nsims_post_tbl &lt;- mod_2_fit$draws() |&gt; as_draws_df() |&gt; \n  as_tibble()\ndif_tbl &lt;- map_df(1:4000, ~ simular_diferencia_post(sims_post_tbl) |&gt; \n         mutate(rep = .x)) \ndif_tbl |&gt; \nggplot(aes(x = diferencia)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"Efecto de sexo en peso hombres vs mujeres (kg)\") \n\n\n\n\n\n\n\n\nConcluimos que el efecto total de sexo sobre peso está entre unos 5.5 y 8 kg de diferencia de hombres vs mujeres.\nEjercicio: explica porqué mostrar por separado las distribuciones de poblaciones de hombres vs la de poblaciones de mujeres no da la respuesta que buscamos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#efecto-directo-de-sexo",
    "href": "03-modelos-genericos.html#efecto-directo-de-sexo",
    "title": "4  Componentes de modelación 1",
    "section": "4.6 Efecto directo de sexo",
    "text": "4.6 Efecto directo de sexo\nAhora pensemos cómo podemos calcular el efecto directo de sexo sobre peso, sin tomar en cuente su influencia en la estatura. En nuestro diagrama, nos interesa sólo considerar la influencia que va directamente de sexo a peso, y no la que pasa por el camino que va a través de la estatura. Este tipo de análisis se llama a veces análisis de mediación.\nLa idea es bloquear el camino que va de sexo a estatura, y esto podemos hacer condicionando o estratificando por los valores de \\(H\\). Es decir, para cada valor de \\(H\\), queremos calcular cuál es la diferencia entre una población de hombres y de mujeres (con la misma estatura \\(H\\)). Las diferencias que encontremos no puede deberse a estatura, pues esta valor es fijo. Al estratificar por \\(H\\), decimos que el camino \\(S\\to H\\to W\\) está bloqueado, y refinaremos esta idea más adelante.\nEn términos de cantidad a estimar, quisiéramos, para cada estatura \\(H\\), calcular la diferencia de una población de hombres vs una de mujeres. La diferencia es el efecto directo a la estatura \\(H\\).\nEl modelo estadístico que proponemos para estimar el efecto directo es entonces:\n\\[\n\\begin{align}\nW_i &\\sim N(\\mu_i, \\sigma)\\\\\n\\mu_i &= \\alpha_{S_i} + \\beta_{S_i} (H_i - \\bar{H})\\\\\n\\alpha_1,\\alpha_2 &\\sim N(60, 10) \\\\\n\\beta_1,\\beta_2 &\\sim N^+(0, 1) \\\\\n\\sigma &\\sim N^+(0, 20) \\\\\n\\end{align}\n\\]\nEl contraste que queremos calcular lo podemos identificar con parámetros en el modelo. Por ejemplo, si \\(\\beta_1 = \\beta_2\\), el efecto directo, para cualquier estatura, debería ser \\(\\alpha_2 - \\alpha_1\\). Sin embargo, seguimos con nuestro camino de hacer simulación para mantener más flexibilidad y simplicidad.\nEjercicio: Haz verificaciones a priori: genera datos sintéticos, examínalos, y verifica que el modelo es capaz de recuperar el contraste de interés.\n\n4.6.1 Ajuste a datos reales y resumen\n\nmod_peso_2 &lt;- cmdstan_model(\"./src/peso-estatura-3.stan\")\nprint(mod_peso_2)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  w;\n  vector[N]  h;\n  array[N] int s;\n}\n\ntransformed data {\n  real h_media;\n  h_media = mean(h);\n}\n\nparameters {\n  array[2] real alpha;\n  array[2] real&lt;lower=0&gt; beta;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  array[N] real mu;\n  for (i in 1:N) {\n    mu[i] = alpha[s[i]] + beta[s[i]] * (h[i] - h_media);\n  }\n}\n\nmodel {\n  // modelo para peso\n  w ~ normal(mu, sigma);\n  // también se puede escribir:\n  //for (i in 1:N) {\n  //  w[i] ~ normal(mu[i], sigma);\n  //}\n  alpha ~ normal(60, 10);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 20);\n}\n\ngenerated quantities {\n\n}\n\n\n\nmod_3_fit &lt;- mod_peso_2$sample(\n  data = list(N = nrow(datos_tbl), \n              s = datos_tbl$male + 1, \n              h = datos_tbl$height,\n              w = datos_tbl$weight),\n  init = 0.01, step_size = 0.01, refresh = 0, seed = 221\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.3 seconds.\nChain 2 finished in 0.3 seconds.\nChain 3 finished in 0.3 seconds.\nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 1.3 seconds.\n\n\n\nmod_3_fit$summary(c(\"alpha\", \"beta\", \"sigma\")) |&gt; \n  knitr::kable(digits = 2)\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nalpha[1]\n45.17\n45.17\n0.45\n0.45\n44.45\n45.91\n1\n2270.19\n2455.26\n\n\nalpha[2]\n45.09\n45.10\n0.47\n0.45\n44.31\n45.83\n1\n2822.98\n2524.93\n\n\nbeta[1]\n0.66\n0.66\n0.06\n0.06\n0.55\n0.76\n1\n2109.75\n2083.05\n\n\nbeta[2]\n0.61\n0.61\n0.06\n0.06\n0.52\n0.70\n1\n2737.57\n2646.95\n\n\nsigma\n4.27\n4.26\n0.16\n0.16\n4.02\n4.55\n1\n4090.86\n2699.93\n\n\n\n\n\n\n\n\nLa diferencia entre las dos rectas parece ser chica. Eso implicaría que el efecto directo de sexo en peso es débil. Sin embargo, es mejor calcular y resumir el contraste como hemos hecho en otros ejemplos.\nRepetimos exactamente el proceso que probamos arriba. Haremos los cálculos manualmente otra vez (aunque conviene más hacerlos dentro de stan):\n\nsims_post_tbl &lt;- mod_3_fit$draws() |&gt; as_draws_df() |&gt; \n  as_tibble()\nh_media &lt;- mean(datos_tbl$height)\n# función para simular pesos\nsim_peso_mod_sh &lt;- function(S, H, alpha, beta, sigma, h_media){\n  n &lt;- length(S)\n  W &lt;- rnorm(n, alpha[S] + beta[S] * (H - h_media), sigma)\n  tibble(W = W)\n}\nsimular_diferencia_post_2 &lt;- function(sims_post_tbl, h){\n  pars &lt;- sample_n(sims_post_tbl, 1) |&gt; \n    select(starts_with(c(\"alpha\", \"beta\")), sigma)\n  alpha &lt;- c(pars$`alpha[1]`, pars$`alpha[2]`)\n  beta &lt;- c(pars$`beta[1]`, pars$`beta[2]`)\n  diferencia &lt;- numeric(length(h))\n  # para cada nivel de estatura especificado\n  for(i in seq_along(h)){\n    # Simulamos poblaciones\n    sims_hombres &lt;- sim_peso_mod_sh(rep(2, 1000), h[i],\n      alpha = alpha, beta = beta, pars$sigma, h_media = h_media)\n    sims_mujeres &lt;- sim_peso_mod_sh(rep(1, 1000), h[i],\n      alpha = alpha, beta = beta, pars$sigma, h_media = h_media)\n    diferencia[i] &lt;- mean(sims_hombres$W - sims_mujeres$W)\n  }\n  tibble(diferencia = diferencia, h = h) |&gt; bind_cols(pars)\n}\n\nPor ejemplo:\n\nsimular_diferencia_post_2(sims_post_tbl, h = c(150, 170))\n\n# A tibble: 2 × 7\n  diferencia     h `alpha[1]` `alpha[2]` `beta[1]` `beta[2]` sigma\n       &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1      1.38    150       45.2       45.9     0.610     0.502  4.25\n2     -0.836   170       45.2       45.9     0.610     0.502  4.25\n\n\n\nh &lt;- seq(130, 190, by = 5)\ndif_tbl &lt;- map_df(1:1000, \n    ~ simular_diferencia_post_2(sims_post_tbl, h) |&gt; \n         mutate(rep = .x))\n\n\ndif_tbl |&gt; \nggplot(aes(x = h, y = diferencia, group = rep)) +\n  geom_line(alpha = 0.1) +\n  labs(x = \"Contraste de peso hombres vs mujeres (kg)\") +\n  geom_hline(yintercept = 0, colour = \"red\") \n\n\n\n\n\n\n\n\nEsto muestra que el efecto directo de sexo en peso es relativamente chico: la mayor parte del efecto es a través de la estatura. Existe una ligera tendencia a que los hombre de menos estatura sean más pesados, y las mujeres de más estatura sean relativamente menos pesadas, pero realmente no podemos afirmar con confianza ningún efecto claro.\n\n\n\n\n\n\nTip\n\n\n\nCuando agregamos una variable como estatura en el modelo de regresión, decimos que estamos estratificando por estatura. En este caso, bloqueamos el efecto causal que tiene sexo en peso a través de la estatura. El efecto causal entre los la variable sexo, que se hace dentro de cada estrato, y se expresa en los coeficientes de sexo, tiene una interpretación totalmente diferente en comparación al modelo que no incluye estatura.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#regresión-logística-tiros-de-golf",
    "href": "03-modelos-genericos.html#regresión-logística-tiros-de-golf",
    "title": "4  Componentes de modelación 1",
    "section": "4.7 Regresión logística: tiros de golf",
    "text": "4.7 Regresión logística: tiros de golf\nEste caso está basado en el paper Gelman y Nolan (2002) y el caso de estudio de Gelman.\nQueremos entender la probabilidad de éxito de putts de Golf (putts: tiros relativamente cerca del hoyo que buscan que la pelota ruede al hoyo o muy cerca de él), y cómo depende el éxito de la distancia del tiro. ¿Qué tan precisos son los profesionales a diferentes distancias? Los datos que tenemos son varios putts de Golf de profesionales a varias distancias, y para cada distancia el porcentaje de éxitos de esos putts.\nComenzaremos con el siguiente diagrama causal:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    V\n    Ang [label = &lt;&theta;&gt;]\n    U\n  node [shape=plaintext]\n    D\n    Y\n  edge [minlen = 3]\n    D -&gt; V\n    D -&gt; Y\n    V -&gt; Y\n    Ang -&gt; Y\n    U -&gt; Y\n{rank = same; D; V}\n{rank = same; Ang; Y}\n{rank = max; U}\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nEn este caso, el modelo causal es como sigue: conocemos la distancia \\(D\\) al hoyo en cada tiro. El éxito (\\(Y=1\\)) o fracaso (\\(Y=0\\)) depende de la distancia, junto con la velocidad a la que sale la pelota (muy alto o muy bajo puede dar un tiro fallido), y el ángulo \\(\\theta\\) de salida. Adicionalmente, hay otros factors \\(U\\) que pueden afectar la probabilidad de éxito. Nótese que no escribiríamos, por ejemplo \\(Y \\leftarrow D\\), porque la distancia no cambia causalmente con el resultado del tiro, aunque es cierto que si intervenimos en la distancia, esperaríamos obtener tasas de éxito diferentes. Igualmente, es necesario poner una flecha de \\(V\\) a \\(D\\) y \\(V\\) a \\(Y\\).\nTodas estas variables antecedentes de \\(Y\\) interactúan para determinar el éxito de un tiro.\nCantidad a estimar: queremos conocer el efecto total de \\(D\\) sobre \\(Y\\). Esto es, queremos conocer la curva \\(p(Y=1|D=d)\\), que es una función de \\(d\\), y también hacer contrastes del tipo \\(p(Y=1|D=d + 10) - p(Y = 1|D=d),\\) por ejemplo.\nModelo estadístico: Nuestro diagrama causal justifica que no es necesario considerar \\(V\\) o \\(\\theta\\) en el modelo, pues nos interesa el efecto total de la distancia sobre \\(Y\\). Esto justifica el uso de un modelo genérico usamos \\(Y\\) como respuesta y \\(D\\) como variable independiente. Intentaremos con un modelo genérico como regresión logística.\nPlanteamos entonces un modelo logístico:\n\\(p(Y = 1| D = d) = \\frac{1}{1 + \\exp(-\\alpha - \\beta d)} = h(\\alpha +\\beta d)\\)\nY nuestro modelo es:\n\\[\n\\begin{align}\nY_i &\\sim Bern(p_i(D_i)) \\\\\np_i &= \\frac{1}{1+\\exp(-\\alpha - \\beta D_i)} \\\\\n\\end{align}\n\\]\nEn términos de este modelo, queremos estimar la curva \\(h(\\alpha +\\beta d)\\), o los parámetros \\(\\alpha\\) y \\(\\beta\\).\nAhora construimos un modelo generativo, donde \\(D\\) está dada en centímetros:\n\nsimular_putts &lt;- function(distancias, alpha, beta) {\n  p &lt;- 1 / (1 + exp(-alpha - beta * distancias))\n  tibble(y = rbinom(length(distancias), 1, p), d = distancias) |&gt; \n    select(d, y)\n}\n\nFijamos parámetros y simulamos datos:\n\nset.seed(22)\ndistancias &lt;- seq(0, 1000, 5) |&gt; rep(each = 5)\nsimular_putts(distancias, 3, -0.005) |&gt; \n  ggplot(aes(x = d, y = y)) +\n  geom_jitter(height = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Éxito\") +\n  geom_smooth(span = 0.5)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nNótese que para este ejemplo utilizamos valores de \\(\\alpha\\) y \\(\\beta\\) fijos. Valores imposibles para golfistas profesionales, por ejemplo, podrían ser los siguientes:\n\nset.seed(22)\ndistancias &lt;- seq(0, 1000, 5) |&gt; rep(each = 5)\nsimular_putts(distancias, 10, -1) |&gt; \n  ggplot(aes(x = d, y = y)) +\n  geom_jitter(height = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Éxito\") +\n  geom_smooth(span = 0.5)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nEsta configuración de parámetros no es razonable, pues implicaría que sólo pueden completar los tiros a unos cuantos centímetros del hoyo. Sabemos que esto no es cierto.\nPara completar nuestro modelo generativo, es necesario especificar los valores que pueden tomar estas variables. Pondremos distribuciones iniciales o a priori apropiadas para los parámetros. En este punto no hemos visto ningún dato, así que podemos experimentar para hacer una selección apropiada desde el punto de vista del conocimiento del área que tenemos actualmente.\nPodemos poner por ejemplo \\[\\alpha \\sim \\text{Normal}(6, 2),\\] pues sabemos a que distancias de casi cero, es muy seguro lograr el tiro (no lejos de 100% de éxito). Para la \\(\\beta\\), consideramos que a unos 100 cm es muy probable hacer el tiro, pero a 1000 cm (10 m) la probabilidad baja considerablemente. Experimentaremos poniendo (debe ser negativa)\n\\[\\beta \\sim \\text{Normal}^-(0, 0.025).\\]\ny ahora reescribimos nuestra función de simulación:\n\nsimular_putts &lt;- function(distancias) {\n  alpha &lt;- rnorm(1, 6, 2)\n  beta &lt;-  - abs(rnorm(1, 0, 0.025))\n  p &lt;- 1 / (1 + exp(-alpha - beta * distancias))\n  tibble(y = rbinom(length(distancias), 1, p), p = p, d = distancias) |&gt; \n    select(d, p, y) |&gt; \n    mutate(alpha = alpha, beta = beta)\n}\n\nY podemos ver cómo se ven diversas curvas que incluye nuestro modelo:\n\ndistancias &lt;- seq(0, 1000, 1) \nmap_df(1:100,  \\(x) simular_putts(distancias) |&gt; mutate(id = x)) |&gt; \n  ggplot(aes(x = d, y = p, group = id)) +\n  geom_line(alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\")\n\n\n\n\n\n\n\n\nLos casos extremos son poco creíbles (0 probabilidad a 2 metros o 100% de probabilidad a 6 metros), pero tenemos un rango razonable para las curvas. Podemos ver la curva promedio:\n\nreps_sim &lt;- map_df(1:1000,  \\(x) simular_putts(distancias) |&gt; mutate(id = x)) \nresumen &lt;- reps_sim |&gt; group_by(d) |&gt; summarise(p_5 = quantile(p, 0.10),\n                                                p95 = quantile(p, 0.90),\n                                                p = mean(p))\nreps_sim |&gt; \n  ggplot(aes(x = d, y = p)) +\n  #geom_line(aes(group = id), alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  geom_ribbon(data = resumen, aes(ymin = p_5, ymax = p95), alpha = 0.2) +\n  geom_line(data = resumen, color = \"red\", linewidth = 2) \n\n\n\n\n\n\n\n\nUna vez que estamos satisfechos con nuestro modelo (nótese que hay lugar para varias críticas), podemos proceder a calcular la distribución posterior, primero con datos simulados.\nLa posterior en este caso es más complicada y no tenemos una manera simple de simularla. Explicaremos más adelante cómo hacer esto (usando MCMC). Por ahora, escribiremos un programa de Stan que nos da simulaciones de la posterior. Tomaremos por el momento Stan como una caja negra, y después justificaremos este procedimiento.\n\n#! message: false\nlibrary(cmdstanr)\nmod_logistica &lt;- cmdstan_model(\"./src/golf-logistico.stan\")\nprint(mod_logistica)\n\ndata {\n  int&lt;lower=0&gt; N;\n  array[N] int n;\n  vector[N] d;\n  array[N] int y;\n}\nparameters {\n  real alpha;\n  real&lt;upper = 0&gt; beta;\n}\nmodel {\n  y ~ binomial_logit(n, alpha + beta * d);\n  alpha ~ normal(6, 2);\n  beta ~ normal(0, 0.025);\n}\n\n\n\nset.seed(425)\ndistancias &lt;- rnorm(100, 0, 2000) |&gt; abs() \ndatos &lt;- simular_putts(distancias)\ndatos_mod &lt;- datos |&gt; group_by(d) |&gt; \n  summarise(n = n(), y = sum(y)) |&gt; \n  ungroup()\najuste &lt;- mod_logistica$sample(\n  data = list(N = nrow(datos_mod), \n              d = datos_mod$d, y = datos_mod$y, n = datos_mod$n), \n                        refresh = 1000, init = 10, step_size = 0.01)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.5 seconds.\n\nsims &lt;- ajuste$draws(c(\"alpha\", \"beta\"), format = \"df\")\nresumen &lt;- ajuste$summary()\n\n\nresumen\n\n# A tibble: 3 × 10\n  variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__     -11.3    -11.0    1.01   0.772  -13.3    -10.3     1.00    1197.\n2 alpha      3.85     3.77   1.29   1.33     1.86     6.08    1.00    1051.\n3 beta      -0.0364  -0.0356 0.0114 0.0116  -0.0560  -0.0191  1.00    1072.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n\ndatos$alpha[1]\n\n[1] 2.691742\n\ndatos$beta[1]\n\n[1] -0.02548956\n\n\n\nggplot(sims, aes(alpha, beta)) + geom_point() +\n  geom_point(data = datos |&gt; first(), aes(alpha, beta), color = \"red\", size = 3)\n\n\n\n\n\n\n\n\nY podemos graficar la posterior de interés, que se construye con todas las curvas simuladas:\n\ngrafs_tbl &lt;- sims |&gt;\n  rowwise() |&gt;\n  mutate(graf = list(tibble(d = seq(0, 600, 10)) |&gt; \n           mutate(p = 1 / (1 + exp(-alpha - beta * d)))\n  )) |&gt; \n  ungroup() |&gt; \n  slice_sample(n = 1000) |&gt; \n  select(.draw, graf) |&gt; \n  unnest(graf) \n\nY graficamos:\n\ngrafs_tbl |&gt; \n  ggplot(aes(x = d, y = p, group = .draw)) +\n  geom_line(alpha = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\")\n\n\n\n\n\n\n\n\nPor el momento, podríamos hacer unas cuantas simulaciones distintas, y ver que las curvas obtenidas son las que esperaríamos (más tarde formalizaremos este proceso). También podríamos hacer simulaciones con distintos tamaños de muestra, y entender cuánta incertidumbre en la estimación de las curvas podríamos tener.\nAhora llegamos al siguiente paso, que tomar los datos y estimar nuestra curva de desempeño según la distancia. Será necesario convertir de pies a centímetros en la variable de distancia:\n\n# nota: x está en pies (ft)\ndatos_golf &lt;- read_delim(\"../datos/golf.csv\", delim = \" \")\n\nRows: 19 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\ndbl (3): x, n, y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(datos_golf)\n\n# A tibble: 6 × 3\n      x     n     y\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     2  1443  1346\n2     3   694   577\n3     4   455   337\n4     5   353   208\n5     6   272   149\n6     7   256   136\n\n\n\nset.seed(1225)\najuste &lt;- mod_logistica$sample(\n  data = list(N = nrow(datos_golf), \n              d = 30.48 * datos_golf$x, y = datos_golf$y, n = datos_golf$n), \n                        refresh = 1000, init = 10, step_size = 0.01)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims &lt;- ajuste$draws(c(\"alpha\", \"beta\"), format = \"df\")\nresumen &lt;- ajuste$summary()\n\n\nresumen\n\n# A tibble: 3 × 10\n  variable        mean   median      sd     mad       q5      q95  rhat ess_bulk\n  &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__     -3028.      -3.03e+3 9.67e-1 6.82e-1 -3.03e+3 -3.03e+3  1.00    1487.\n2 alpha        2.23     2.23e+0 5.77e-2 5.73e-2  2.14e+0  2.32e+0  1.01    1128.\n3 beta        -0.00839 -8.39e-3 2.18e-4 2.21e-4 -8.75e-3 -8.04e-3  1.01    1148.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nAhora simulamos la posterior y la contrastamos con los datos:\n\ngrafs_tbl &lt;- sims |&gt;\n  rowwise() |&gt;\n  mutate(graf = list(tibble(d = 30.48 * seq(0, 20, 0.5)) |&gt; \n           mutate(p = 1 / (1 + exp(-alpha - beta * d)))\n  )) |&gt; \n  ungroup() |&gt; \n  slice_sample(n = 100) |&gt; \n  select(.draw, graf) |&gt; \n  unnest(graf) \n\n\nresumen_golf &lt;- datos_golf |&gt;\n  mutate(d = 30.48 * x, p = y / n)\n\n\ngrafs_tbl |&gt; \n  ggplot(aes(x = d, y = p)) +\n  geom_line(aes(group = .draw), alpha = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  geom_point(data = resumen_golf, color = \"red\") +\n  geom_linerange(data = resumen_golf, \n    aes(ymin = p - 2 * sqrt(p * (1 - p) / n),  \n        ymax = p + 2 * sqrt(p * (1 - p) / n)),\n    color = \"red\")\n\n\n\n\nChequeo predictivo posterior (deficiente)\n\n\n\n\nVemos que la curva estimada desajusta. Este tipo de análisis se llama chequeo a posteriori, y mas frecuentemente se hace un chequeo predictivo posterior, que veremos más adelante. Por el momento, nos quedamos con la conclusión de que el modelo no es apropiado para estos datos: no hemos capturado apropiadamente la relación que hay entre éxito y distancia.\nEn este punto veremos dos caminos:\n\nEl primero es continuar con modelos genéricos que no toman en cuenta mecanismos específicos de los datos. Por ejemplo, podríamos poner más terminos derivados de la distancia (polinomios o splines).\nEl segundo camino, es utilizar más información acerca del fenómeno de interés. Sabemos como funciona básicamente el golf, y también sabemos geometría y física que determina el proceso generador de datos. Podemos utilizar esta información para construir un modelo más apropiado.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#usando-teoría-para-construir-modelos",
    "href": "03-modelos-genericos.html#usando-teoría-para-construir-modelos",
    "title": "4  Componentes de modelación 1",
    "section": "4.8 Usando teoría para construir modelos",
    "text": "4.8 Usando teoría para construir modelos\nEn la gráfica causal que vimos arriba, hay mucha información adicional que no hemos utilizado acerca de la naturaleza de la dependencia de las variables involucradas. En esta parte, en lugar de usar un modelo genérico, utilizaremos geometría y algo de física para construir un modelo más apropiado.\nEl problema es considerablemente complicado conceptualmente (Holmes (1991), Penner (2002)) si consideramos todas las fuentes de variación: ángulo de tiro, potencia de tiro, declive en greens y así sucesivamente.\nSeguiremos haciendo la simplificación de superficie plana, pero consideramos dos parámetros para el tiro con distintas condiciones de éxito:\n\nEl ángulo del tiro\nLa velocidad con la que la pelota llega (o no llega) al hoyo\n\nEl diámetro de una pelota de golf y el hoyo (en centrímetros) es de\n\ndiam_pelota &lt;- (1.68 * 2.54) |&gt;  round(1)\ndiam_hoyo &lt;- (4.25 * 2.54) |&gt;  round(1)\nc(diam_pelota, diam_hoyo)\n\n[1]  4.3 10.8\n\n\nSupondremos por el momento que los greens de golf (áreas cerca del hoyo) son perfectamente planos, de modo que el éxito depende de\n\nTirar la pelota con un ángulo suficientemente cercano a cero con respecto a la línea que va del centro de la pelota al centro del hoyo.\nTirar la pelota con una velocidad suficiente para llegue al hoyo pero no tan alta que vuele por encima del hoyo.\n\nMejores datos de los tipos de fallo sería útil, pero por el momento no consideramos que estén disponibles.\nEmpezamos construyendo nuestro modelo considerando sólamente el ángulo de tiro.\n\n4.8.0.1 Ángulo de tiro\nSupongamos que la distancia del centro de la pelota al centro del hoyo es \\(d\\), y que \\(\\theta\\) es el ángulo del tiro con respecto a la recta que va del centro de la pelota al centro del hoyo. El tiro es exitoso cuando (si \\(\\theta\\) está en radianes):\n\\[\\tan(\\theta) &lt; \\frac{R - r}{2d}\\]\n Tenemos que\n\n(diam_hoyo - diam_pelota)/2\n\n[1] 3.25\n\n\nAsí que para nuestro problema simplificado, la condición de éxito es (d está dado en centímetros y \\(\\theta\\) en radianes):\n\\[\\tan(\\theta) &lt; \\frac{3.25}{d}\\]\nMejores golfistas tendrán mejor control sobre \\(\\theta\\), y conforme \\(d\\) es más grande, la probabilidad de tener éxito baja:\n\ntibble(d = seq(10, 600, 1)) |&gt;  \n  mutate(theta_grados = (180 / pi) * atan(3.25 / d)) |&gt;  \nggplot(aes(d, theta_grados)) + geom_point() +\n  xlab(\"Distancia (cm)\") +\n  ylab(expression(paste(\"Desviación máxima en grados\"))) +\n  labs(subtitle = \"Desviación máxima permitida para tener éxito a distintas distancias\") +\n  scale_y_log10()\n\n\n\n\n\n\n\n\nPor el momento, sólo consideraremos el ángulo y la distancia. Supongamos que un tirador profesional tira con un ángulo \\(\\theta\\) que se distribuye como\n\\[\\theta\\sim N(0,\\sigma),\\] donde \\(\\theta=0\\) indica que el tiro es directo al hoyo. La probabilidad de tener éxito es entonces\n\\[P(Y=1|\\theta) = P(|\\theta| &lt; \\arctan(3.25/d)) = 2\\Phi \\left (\\frac{\\arctan(3.25/d)}{\\sigma}  \\right )-1\\] Así que nuestro modelo completo es\n\\[\n\\begin{align}\nY_i &\\sim Bern(p_i(D_i)) \\\\\np_i &= 2\\Phi(\\arctan(3.25/D_i)/\\sigma)-1 \\\\\n\\end{align}\n\\] Nótese que sólo tenemos un parámetro \\(\\sigma\\) en este modelo en lugar de dos como en la regresión logística. La diferencia grande también es la forma funcional de la probabilidad de éxito.\nAntes de escribir nuestra función, necesitamos poner una inicial sobre \\(\\sigma\\). Probaremos considerando que un jugador profesional puede tener una desviación de 0 a 10 grados, por ejemplo. Convirtiendo a radianes podríamos poner:\n\\[\n\\begin{align}\nY_i &\\sim Bern(p_i(D_i)) \\\\\np_i &= 2\\Phi(\\arctan(3.25/D_i)/\\sigma)-1 \\\\\n\\sigma &\\sim N^+(0, 5\\pi/180))\n\\end{align}\n\\]\n\nsimular_putts_angulo &lt;- function(distancias) {\n  sigma &lt;- rnorm(1, 0, 5 * pi / 180) |&gt; abs()\n  p &lt;- 2 * pnorm(atan(3.25 / distancias)/sigma) - 1\n  tibble(y = rbinom(length(distancias), 1, p), p = p, d = distancias) |&gt; \n    select(d, p, y) |&gt; \n    mutate(sigma = sigma)\n}\n\nY podemos ver cómo se ven diversas curvas que incluye nuestro modelo:\n\ndistancias &lt;- seq(0, 600, 1) \nmap_df(1:100,  \\(x) simular_putts_angulo(distancias) |&gt; mutate(id = x)) |&gt; \n  ggplot(aes(x = d, y = p, group = id)) +\n  geom_line(alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\")\n\n\n\n\n\n\n\n\nEsta inicial espera que en general los tiros a menos de menos de 50cm se consigan con mucha frecuencia o casi seguro, 2 metros se consigan con cierta frecuencia, y 6 metros se consigan con relativamente menos frecuencia. Tiene el defecto de que pone mucho peso en desviaciones muy chicas, lo cual es poco creíble (las rectas que se pegan mucho probabilidad uno para todas las distancias).\nUn cambio razonable que podemos hacer, por ejemplo, es poner:\n\\[\\theta_{grados} \\sim Gamma(a, b)\\]\nCuya media queremos poner por ejemplo en 2 grados \\(a/b = 2\\), y suponemos una desviación estándar de unos \\(a/b^2 = 0.5\\) grados. En este caso,\n\nmu &lt;- 2\nbeta  &lt;- 2\nqplot(rgamma(1e5, mu * beta, beta))\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nsimular_putts_angulo &lt;- function(distancias) {\n  sigma &lt;- (pi/180) * rgamma(1, mu * beta, beta) \n  p &lt;- 2 * pnorm(atan(3.25 / distancias)/sigma) - 1\n  tibble(y = rbinom(length(distancias), 1, p), p = p, d = distancias) |&gt; \n    select(d, p, y) |&gt; \n    mutate(sigma = sigma)\n}\n\nY podemos ver cómo se ven diversas curvas que incluye nuestro modelo:\n\ndistancias &lt;- seq(0, 600, 1) \nmap_df(1:200,  \\(x) simular_putts_angulo(distancias) |&gt; mutate(id = x)) |&gt; \n  ggplot(aes(x = d, y = p, group = id)) +\n  geom_line(alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  ylim(c(0,1))\n\n\n\n\n\n\n\n\nNota: Checando con esta gráfica podemos modificar los parámetros de la Gamma para poner una inicial apropiada.\nDejaremos como ejercicio hacer las pruebas predictivas a priori, y continuaremos con el ajuste a los datos para checar el ajuste de este modelo:\n\n#! message: false\nlibrary(cmdstanr)\nmod_golf &lt;- cmdstan_model(\"./src/golf-principios-1.stan\")\nprint(mod_golf)\n\ndata {\n  int&lt;lower=0&gt; N;\n  array[N] int n;\n  vector[N] d;\n  array[N] int y;\n}\ntransformed data {\n  vector[N] angulo_maximo = atan(3.25 ./ d);\n}\nparameters {\n  real&lt;lower=0&gt; sigma_ang;\n  }\ntransformed parameters {\n  real sigma = sigma_ang * pi() / 180;\n  vector[N] p = 2 * Phi(angulo_maximo / sigma) - 1;\n}\nmodel {\n  y ~ binomial_logit(n, p);\n  sigma_ang ~ gamma(4, 2);\n}\n\n\n\nset.seed(225)\najuste_2 &lt;- mod_golf$sample(\n  data = list(N = nrow(datos_golf),\n              d =  30.48 * datos_golf$x, y = datos_golf$y, n = datos_golf$n),\n  refresh = 1000, init = 0.01, step_size = 0.01)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims_2 &lt;- ajuste_2$draws(c(\"sigma\", \"sigma_ang\"), format = \"df\")\nresumen_2 &lt;- ajuste_2$summary(c(\"sigma\", \"sigma_ang\"))\n\n\nresumen_2\n\n# A tibble: 2 × 10\n  variable    mean median      sd     mad     q5    q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 sigma     0.0308 0.0307 0.00136 0.00139 0.0286 0.0331  1.00    1271.    1797.\n2 sigma_ang 1.76   1.76   0.0782  0.0795  1.64   1.90    1.00    1271.    1797.\n\n\nAhora simulamos la posterior y la contrastamos con los datos:\n\ngrafs_2_tbl &lt;- sims_2 |&gt;\n  rowwise() |&gt;\n  mutate(graf = list(tibble(d = 30.48 * seq(0, 20, 0.5)) |&gt;\n                       mutate(p = 2 * pnorm(atan(3.25 / d)/sigma) - 1))) |&gt;\n  ungroup() |&gt;\n  slice_sample(n = 100) |&gt;\n  select(.draw, graf) |&gt;\n  unnest(graf)\n\nEl resultado es considerablemente mejor que el de la regresión logística, aunque tiene algunos fallos en rangos medios:\n\ngrafs_2_tbl |&gt;\n  ggplot(aes(x = d, y = p)) +\n  geom_line(aes(group = .draw), alpha = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  geom_point(data = resumen_golf, color = \"red\") +\n  geom_linerange(data = resumen_golf,\n                 aes(ymin = p - 2 * sqrt(p * (1 - p) / n),\n                     ymax = p + 2 * sqrt(p * (1 - p) / n)),\n                 color = \"red\") +\n  ylim(c(0,1))\n\n\n\n\nChequeo predictivo posterior\n\n\n\n\nEste es un modelo relativamente simple que sólo toma en cuenta ángulos y distancia. Para más refinaciones que toman en cuenta la velocidad, puedes revisar también este análisis de M. Broadie, en donde se extiende este modelo bajo principios geométricos y físicos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#modelos-genéricos-para-ajustar-curvas",
    "href": "03-modelos-genericos.html#modelos-genéricos-para-ajustar-curvas",
    "title": "4  Componentes de modelación 1",
    "section": "4.9 Modelos genéricos para ajustar curvas",
    "text": "4.9 Modelos genéricos para ajustar curvas\nOtra posibilidad es utilizar un modelo más flexible creando variables derivadas de la distancia. En este caso, quizá podemos ajustar una curva que sea aceptable desde el punto de vista predictivo, pero no podremos aprender mucho acerca de cómo funciona la probabilidad de éxitos de los tiros de putts\n\n\n\n\n\n\nSplines y ajuste de curvas\n\n\n\nLos splines nos dan una manera estándar de ajustar curvas más flexibles, de tipo polinomial por tramos. Usualmente son numéricamente más conveniente que polinomios.\n\n\nAunque hay muchos tipos de splines (los más comunes son B-splines), para este problema consideraremos una base de splines cuadráticos que resultan en curvas monótonas (I-splines). Puedes ver más detalles de splines en McElreath (2020)\nEn este caso, haremos expansión de entradas de las siguiente manera. Supongamos que tenemos la variable de distancia \\(d\\) que va de 0 a 750 cm, por ejemplo. Construimos entradas derivadas de la siguiente manera:\n\nlibrary(splines2)\nnudos &lt;- c(25, 50, 100, 200, 400)\ndistancias &lt;- seq(0, 750, 1)\nsplines_tbl &lt;- iSpline(distancias, knots = nudos, \n  Boundary.knots = c(0, 750), degree = 2, intercept = FALSE) |&gt; \n  as_tibble() |&gt; \n  mutate(d = distancias) |&gt; \n  pivot_longer(-d, names_to = \"spline\", values_to = \"valor\")\nggplot(splines_tbl) +\n  geom_line(aes(x = d, y = valor, color = spline)) +\n  geom_vline(xintercept = nudos, color = \"red\", linetype = 2) \n\n\n\n\n\n\n\n\nEsta gráfica muestra cómo para cada distancia \\(x\\) generamos valores \\(x_1,\\ldots, x_p\\) que son variables derivadas de \\(x\\). Podemos entonces obtener más flexibilidad hacer regresión en estas nuevas \\(p\\) variables en lugar de usar solamente \\(x\\). Por la elección de la base, obsérvese que siempre que \\(\\beta_1, \\ldots, \\beta_p\\) sean no negativos, entonces la función \\[\\alpha + \\beta_1 x_1 + \\cdots + \\beta_p x_p\\] será monótona no decreciente, que es lo que necesitamos para este problema.\nNuestra función generadora para este modelo puede ser:\n\nsimular_putts &lt;- function(distancias, nudos) {\n  # Simular intercepto\n  alpha &lt;- rnorm(1, 4, 2)\n  # Simular coeficientes de splines\n  beta &lt;-  - abs(rnorm(7, 0, 1.5))\n  # Calcular splines para distancias dadas\n  mat_splines &lt;- splines2::iSpline(distancias, \n    Boundary.knots = c(0, 750), knots = nudos, degree = 2, intercept = FALSE) \n  # Calcular probabilidad de éxito con regresión logística\n  p &lt;- 1 / (1 + exp(- alpha - mat_splines %*% beta))\n  tibble(y = rbinom(length(distancias), 1, p), p = p, d = distancias) |&gt; \n    select(d, p, y) |&gt; \n    mutate(alpha = alpha, beta = list(beta))\n}\n\n\nset.seed(8123)\ndistancias &lt;- seq(1, 600, 5) |&gt; rep(each = 5)\nsimular_putts(distancias, nudos) |&gt; \n  ggplot(aes(x = d, y = y)) +\n  geom_jitter(height = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Éxito\") +\n  geom_smooth(span = 1, se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nY podemos hacer simulaciones a priori para entender nuestros supuestos:\n\nmap_df(1:100,  \\(x) simular_putts(distancias, nudos) |&gt; mutate(id = x)) |&gt; \n  ggplot(aes(x = d, y = p, group = id)) +\n  geom_line(alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\")\n\n\n\n\n\n\n\n\nAhora construimos nuestro nuevo modelo en Stan, donde \\(x\\) será la matriz de splines (entradas derivadas como se explicó arriba):\n\n#! message: false\nlibrary(cmdstanr)\nmod_logistica_splines &lt;- cmdstan_model(\"./src/golf-logistico-splines.stan\")\nprint(mod_logistica_splines)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; p;\n  array[N] int n;\n  vector[N] d;\n  matrix[N, p] x;\n  array[N] int y;\n}\nparameters {\n  real alpha;\n  array[p] real&lt;upper=0&gt; beta;\n}\nmodel {\n  for(i in 1:N){\n    y[i] ~ binomial_logit(n[i], alpha + dot_product(x[i,], to_vector(beta)));\n  }\n  alpha ~ normal(4, 2);\n  beta ~ normal(0, 1.5);\n}\n\n\n\nset.seed(1225)\nmat_splines &lt;- splines2::iSpline(30.48 * datos_golf$x, \n      Boundary.knots = c(0, 750), knots = nudos, degree = 2, intercept = FALSE) \najuste &lt;- mod_logistica_splines$sample(\n  data = list(N = nrow(datos_golf), p = ncol(mat_splines),\n              d = 30.48 * datos_golf$x, \n              x = mat_splines,\n              y = datos_golf$y, n = datos_golf$n), \n  refresh = 1000, init = 0.1, \n  step_size = 0.1, adapt_delta = 0.99)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 2.9 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 3.2 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 3.2 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 4.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 3.4 seconds.\nTotal execution time: 13.7 seconds.\n\n\nWarning: 236 of 4000 (6.0%) transitions hit the maximum treedepth limit of 10.\nSee https://mc-stan.org/misc/warnings for details.\n\nsims &lt;- ajuste$draws(c(\"alpha\", \"beta\"), format = \"df\")\n\nresumen &lt;- ajuste$summary()\n\n\nresumen\n\n# A tibble: 9 × 10\n  variable      mean    median    sd   mad        q5        q95  rhat ess_bulk\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__     -2911.    -2911.    2.22  2.13  -2916.    -2908.      1.00    1193.\n2 alpha        4.88      4.80  0.939 0.934     3.49      6.57    1.00    1575.\n3 beta[1]     -0.974    -0.803 0.748 0.743    -2.39     -0.0803  1.00    1876.\n4 beta[2]     -1.24     -1.12  0.796 0.839    -2.70     -0.156   1.00    1665.\n5 beta[3]     -1.91     -1.92  0.269 0.268    -2.35     -1.46    1.00    1548.\n6 beta[4]     -1.03     -1.03  0.226 0.229    -1.40     -0.669   1.00    1501.\n7 beta[5]     -1.23     -1.24  0.265 0.264    -1.63     -0.758   1.00    1650.\n8 beta[6]     -0.403    -0.350 0.289 0.292    -0.949    -0.0319  1.00    1718.\n9 beta[7]     -0.645    -0.529 0.521 0.485    -1.69     -0.0490  1.00    2091.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nAhora simulamos la posterior y la contrastamos con los datos:\n\nd &lt;- 30.48 * seq(0, 20, 0.5)\nmat_splines_pred &lt;- splines2::iSpline(30.48 * seq(0, 20, 0.5), \n       Boundary.knots = c(0, 750), knots = nudos, degree = 2,\n                                 intercept = FALSE) \nsims_2 &lt;- sims  |&gt; group_by(.draw, .chain, .iteration) |&gt; nest() \ngrafs &lt;- purrr::map(sims_2$data, function(pars){\n  pars &lt;- as.numeric(pars)\n  alpha &lt;- pars[1]\n  beta &lt;- pars[2:8]\n  p &lt;- 1/(1 + exp(- alpha - mat_splines_pred %*% beta))\n  tibble(p = as.numeric(p), d = d)\n})\nsims_graf_tbl &lt;- sims_2 |&gt; add_column(graf = grafs) |&gt; select(-data) |&gt; \n  ungroup() |&gt; \n  slice_sample(n = 100) |&gt; \n  select(.draw, graf) |&gt; \n  unnest(graf) \n\n\nsims_graf_tbl |&gt; \n  ggplot(aes(x = d, y = p)) +\n  geom_line(aes(group = .draw), alpha = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  geom_point(data = resumen_golf, color = \"red\") +\n  geom_linerange(data = resumen_golf, \n    aes(ymin = p - 2 * sqrt(p * (1 - p) / n),  \n        ymax = p + 2 * sqrt(p * (1 - p) / n)),\n    color = \"red\")\n\n\n\n\n\n\n\n\nEste modelo ajusta mejor, y puede ser usado para hacer comparaciones de probabilidad de éxito a diferentes distancias. Su defecto es que no es interpetable como nuestro modelo anterior (aprendemos poco sobre cómo funcionan los putts), y es considerablemente más difícil de ajustar.\nPuedes ver más de splines en McElreath (2020), y en Hastie, Tibshirani, y Friedman (2017). Puedes revisar también este caso de Stan que explica cómo utilizar splines de forma más general en Stan.\n\n\n\n\nGelman, Andrew, y Deborah Nolan. 2002. «A Probability Model for Golf Putting». Teaching Statistics 24 (septiembre): 93-95. https://doi.org/10.1111/1467-9639.00097.\n\n\nHastie, Trevor, Robert Tibshirani, y Jerome Friedman. 2017. The Elements of Statistical Learning. Springer Series en Statistics. Springer New York Inc. http://web.stanford.edu/~hastie/ElemStatLearn/.\n\n\nHolmes, Brian W. 1991. «Putting: How a golf ball and hole interact». American Journal of Physics 59 (2): 129-36. https://doi.org/10.1119/1.16592.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.\n\n\nPenner, Albert. 2002. «The physics of putting». Canadian Journal of Physics 80 (febrero): 83-96. https://doi.org/10.1139/p01-137.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "05-dags.html",
    "href": "05-dags.html",
    "title": "5  Modelos gráficos y causalidad",
    "section": "",
    "text": "5.1 Modelos gráficos\nEn primer lugar, podemos pensar cómo se asignan los valores de las variables en nuestro proceso generador de datos. Pensamos entonces de qué depende directamente cada variable para determinar su valor, de manera que cada nodo \\(X\\) de la variable se puede escribir por ejemplo como \\(Y = f(X, W)\\) y \\(Z = g(X)\\). Esto es desde el punto de vista téorico y de conocimiento de área que tenemos (además de supuestos que provienen del diseño del estudio, si los datos son generados bajo un diseño elegido por nosotros), y representan supuestos causales. En este ejemplo particular, tenemos un modelo gráfico asociado, que escribimos como:\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n    W\n  edge [minlen = 3]\n   X -&gt; Y\n   Z -&gt; X\n   W -&gt; Y\n}\n\", width = 150, height = 40)\nNótese que no describimos exactamente cómo son las funciones que relacionan las variables, sino más bien qué variables son causas directas de qué otras. Por ejemplo, aunque en nuestro ejemplo de arriba \\(Y\\) puede estar correlacionado con \\(Z\\), no hay una causa directa a \\(Y\\), porque cambios en \\(Z\\) afectan a \\(X\\), y es el cambio en \\(X\\) que es causa directa de \\(Y\\).\nNota: hay varias maneras de construir modelos causales además de DAGs. Una de ellas es sistemas de ecuaciones diferenciales (en el tiempo), que a veces son necesarias para modelos de biología, clima o epidemiología por ejemplo. También pueden utilizarse modelos de agentes (modelamos partes más pequeñas o simples del sistemas y sus interacciones). Quizá los DAGs son los modelos con más populares y tienen amplia aplicabilidad.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#modelos-gráficos",
    "href": "05-dags.html#modelos-gráficos",
    "title": "5  Modelos gráficos y causalidad",
    "section": "",
    "text": "Modelos gráficos Y DAGs\n\n\n\nEn un modelo gráfico, dibujamos una arista de un nodo \\(X\\) a un nodo \\(Y\\) si el valor de la variable \\(Y\\) depende directamente del valor de la variable \\(X\\), es decir si \\(X\\) es una causa directa de \\(Y\\). En estos modelos no especificamos la fórmula o naturaleza de cada relación directa, sino simplemente que ésta existe.\nTrabajamos principalmente con modelos causales que pueden representarse como DAGs (gráficas dirigidas acícilcas), donde no existen ciclos de causas entre las variables.\nExisten dos tipos de nodos en estas gráficas: variables exógenas que no dependen de otros nodos para tomar su valor, y variables endógenas que son descendientes de al menos otro nodo. Cuando conocemos las variables exógenas, en teoría podemos simular todo el sistema si especificamos el modelo de cada nodo endógeno.\n\n\n\n\n5.1.1 Ejemplo simple\nPara entender los conceptos empezamos con una historia de datos sencilla. En un juego de azar, supongamos que escogemos al azar un número \\(X\\) entre 0 y 1, y luego tiramos dos veces cinco volados con probabilidad de sol \\(X\\). Medimos el número de soles en cada prueba como \\(S_1\\) y \\(S_2\\). Finalmente, la ganancia \\(G\\) obtenida es la suma de \\(S_1+S_2\\) si el día es lluvioso o solamente \\(S_1\\) si el día es soleado.\nNótese que tanto como \\(S_1\\) y \\(S_2\\) dependen de su valor de \\(X\\), además de que dependen de otras variables \\(U_1\\) y \\(U_2\\), muy complicadas, que determinan cómo caen los volados. \\(G\\) depende de su valor de \\(S_1\\) y \\(S_2\\), además de depender de una variable \\(D\\) que describe si el día actual es lluvioso o soleado. El diagrama causal resultante es el que sigue, donde consideramos que observaremos \\(U1\\), \\(U2\\) y \\(U3\\).\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=circle]\n    U1\n    U2\n    U3\n    U4\n  node [shape=plaintext]\n    S1\n    S2\n    X\n  edge [minlen = 3]\n   X -&gt; S1\n   X -&gt; S2\n   U1 -&gt; S1\n   U2 -&gt; S2\n   S1 -&gt; G\n   S2 -&gt; G\n   D -&gt; G\n   U3 -&gt; D\n   U4 -&gt; X\n{\n  rank = same; S1; S2;U1;U2\n}\n\n}\n\")\n\n\n\n\n\n\nEn este ejemplos no podemos saber \\(U1\\) y \\(U2\\), y no nos interesa modelar la física de monedas, manera de lanzarlas, etc. En este ejemplo también no consideraremos qué hace que un día sea soleado o lluvioso (no nos interesa modelar el clima). En este momento, en teoría tenemos ecuaciones determinísticas para todas las variables, y si conocemos todas las variables exógenas \\(U1,U2,U3,U4\\) podríamos determinar exactamente lo que va a suceder con la ganancia, por ejemplo, o cualquier otra variable del sistema.\nSin embargo, muchas veces excluímos variables exógenas que sólo afectan a una variable endógena, y consideramos que las relaciones de dependiencia de la gráfica son probabilísticas:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=circle]\n   \n  node [shape=plaintext]\n    S1\n    S2\n    X\n  edge [minlen = 3]\n   X -&gt; S1\n   X -&gt; S2\n   S1 -&gt; G\n   S2 -&gt; G\n   D -&gt; G\n{\n  rank = same; S1; S2\n}\n\n}\n\")\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nUsualmente, consideramos que las flechas en un DAG indican que un cambio en el nodo padre causa un cambio en la distribución de probabilidades de los hijos (no necesariamente lo determina).\nUsamos estas distribuciones para abstraer otros efectos exógenos que determinan los hijos cuyo mecanismo no nos interesa modelar causalmente.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#modelos-gráficos-y-regla-del-producto",
    "href": "05-dags.html#modelos-gráficos-y-regla-del-producto",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.2 Modelos gráficos y regla del producto",
    "text": "5.2 Modelos gráficos y regla del producto\nLos modelos gráficos también nos muestran cómo hacer factorizaciones útiles de los datos.\nSi tenemos cualquier conjunto de variables aleatorias \\(X_1,\\ldots,X_p\\), la distibución conjunta de estas variables \\(p(x_1,x_2,\\ldots, x_p)\\) nos sirve para calcular cualquier cantidad de interés que involucra estas variables.\nRecordamos ahora la regla del producto: para cualquier conjunto de variables aleatorias \\(X_1,\\ldots,X_p\\), la conjunta se puede factorizar siempre como:\n\\[p(x_1,x_2,\\ldots, x_p) = p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)\\ldots p(x_p|x_1,x_2,\\ldots,x_{p-1})\\] Hay muchas manera de escribir esta factorización, dependiendo de cómo ordenamos las variables. El modelo gráfico nos da un ordenamiento natural (primero van padres y luego hijos) de las variables que nos permite aplicar la regla del producto, según la dirección de las flechas del diagrama:\n\nEjemplo\nEn el ejemplo de arriba, un ordenamiento es \\(X,D,S1,S2,G\\). Entonces, podemos escribir la regla del producto:\n\\[p(x,s_1,s_2,d,g) = p(x)p(d|x)p(s_1|x,d)p(s_2|x,d,s_1)p(g|x,d,s1,s2)\\] Que podemos simplificar porque por ejemplo, \\(p(s_2|x, d,s_1) = p(s_2|x)\\), ya que \\(s_1\\) no influye directamente en \\(s_2\\). Por la misma lógica, \\(p(d|x) = p(d)\\) y \\(p(g|x,s_1,s_2,d) = p(g|s_1,s_2,d)\\), etc. Entonces:\n\\[p(x,s_1,s_2,d,g) = p(x)p(d)p(s_1|x)p(s_2|x)p(g|s_1,s_2,d)\\] Al incluir sólo las causas directas obtenemos una manera más parsimoniosa de modelar las relaciones entre estas variables, lo cual nos servirá más tarde cuando apliquemos modelos estadísticos para aprender de estas relaciones. Bajo nuestros supuestos no es necesario modelar toda la cadena de dependencias, pues algunas flechas no están presentes.\nEn nuestro caso, suponemos de acuerdo con lo que sabemos:\n\n\\(p(x)\\) es uniforme en \\([0,1]\\),\nSupondremos por ejemplo que \\(p(d=lluvioso) =0.3\\) (tomando un día del año al azar),\n\\(S_1|X\\) y \\(S_2|X\\) son binomiales con 5 pruebas y probabilidad \\(X\\), y\n\\(G|S_1,S_2,D\\) es determinística: \\(G\\) toma el valor \\(S_1+ S_2\\) si \\(D\\) es lluvioso, y \\(S_1\\) en otro caso. Con esto, tenemos un modelo conjunto completo del sistema de interés.\n\n\n\nEjemplo\nPara entender mejor la parsimonia que podemos alcanzar usando supuestos causales, considera la cadena \\(X\\to Y\\to Z\\to W\\to A\\). Imagina que cada una de estas variables puede tomar 2 valores. La conjunta de cinco variables binarias \\((X,Y,Z,W,A)\\), en general, requiere de \\(2^5-1=31\\) parámetros. Sin embargo, si se satisface \\(X\\to Y\\to Z\\to W\\to A\\) sólo requirimos 1 parámetro para \\(p(x)\\), 2 para \\(p(y|x)\\), 2 para \\(p(z|y)\\), etc. En total, sólo necesitamos 9 parámetros.\n\n\n\n\n\n\nRegla del producto para DAGs\n\n\n\nSupongamos que tenemos un DAG con variables \\(X_i\\). Si denotamos por \\(pa_i\\) a los padres de \\(X_i\\), entonces siempre podemos factorizar la conjunta como\n\\[p(x_1,\\ldots, x_p) = \\prod_{i=1}^p p(x_i|pa_i)\\] Las posibles conjuntas que satisfacen esta ecuación decimos que son consistentes con el DAG.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#regla-del-producto-y-simulación",
    "href": "05-dags.html#regla-del-producto-y-simulación",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.3 Regla del producto y simulación",
    "text": "5.3 Regla del producto y simulación\nEl orden del modelo gráfico también nos indica cómo simular las variables de la gráfica. Como cada modelo gráfico nos da una factorización de la conjunta, podemos utlizar esta para simular datos una vez que conocemos o estimamos las relaciones de dependencia directa. Empezamos con las variables exógenas (que no tienen padres) y vamos simulando hacia adelante.\n\nEjemplo\nEn nuestro ejemplo simulamos primero \\(X\\) y \\(D\\). A partir de \\(X\\) podemos simular \\(X_1\\) y \\(S_2\\), y a partir de \\(D\\), junto con \\(S_1\\) y \\(S_2\\), podemos simular \\(G\\). En nuestro ejemplo tendríamos\n\nsimular_juego &lt;- function(N){\n  x &lt;- runif(N)\n  d &lt;- sample(c(\"lluvioso\",\"soleado\"), N, replace = TRUE, prob = c(0.3,0.7))\n  s1 &lt;- rbinom(N, 5, x)\n  s2 &lt;- rbinom(N, 5, x)\n  g &lt;- ifelse(d==\"lluvioso\", s1+s2, s1)\n  tibble(x, d, s1, s2, g)\n}\nsimular_juego(5)\n\n# A tibble: 5 × 5\n       x d           s1    s2     g\n   &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 1.00   soleado      5     5     5\n2 0.0271 soleado      0     0     0\n3 0.571  lluvioso     2     4     6\n4 0.197  soleado      1     1     1\n5 0.206  lluvioso     1     2     3",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#estructuras-básicas-de-dags",
    "href": "05-dags.html#estructuras-básicas-de-dags",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.4 Estructuras básicas de DAGs",
    "text": "5.4 Estructuras básicas de DAGs\nVeremos que para razonar acerca de las asociaciones e independencias (condicionales o no) que pueden aparecer o no en una conjunta, podemos examinar la gráfica que la represente, o dicho de otra manera, entender bajo qué condiciones puede propagarse información de un nodo a otro.\nRecuerda qué es la independencia condicional. Decimos por ejemplo que \\(X\\) y \\(Y\\) son condicionalmente independientes dada \\(Z\\) cuando se cumplen las siguientes ecuaciones equivalentes:\n\n\\(p(x|y,z) = p(x |z)\\)\n\\(p(y|x,z) = p(y|z)\\)\n\\(p(x,y|z) = p(x|z)p(y|z)\\)\n\nEs decir, en estos casos si conocemos \\(Y\\), por ejemplo, información acerca de \\(Z\\) no cambia la condicional \\(p(y|x,z)=p(y|z)\\). También vemos que la conjunta de \\(X\\) y \\(Y\\) condicionada a \\(Z\\) se factoriza como el producto de las condicionales de \\(X\\) y \\(Y\\) dada \\(Z\\).\nEste es un concepto fundamental en estadística, y también en inferencia causal. Como vimos arriba, nos permite construir modelos para sistemas considerablemente grandes, pues muchas veces las relaciones causales directas importantes son ralas (es decir, no todo está conectado con todo).\n\n\n\n\n\n\nIndependencia condicional\n\n\n\nLas independencias condicionales que forzosamente se cumplen para cualquier relación funcional entre variables del sistema (o dicho de otra manera, cualquier conjunta consistente con el DAG), pueden leerse directamente de la estructura del modelo gráfico (DAG) correspondiente (ver definición de \\(d\\)-separación más adelante).\n\nEsto nos permite hacer razonamiento lógico de qué puede estar asociado o no según nuestros supuestos causales.\nNota: Pueden existir otras independiencias condicionales adicionales para algunas conjuntas que también pueden representarse con el DAG.\n\n\n\nPara entender modelos gráficos en general, y que independencias condicionales implican o no, basta endender cuatro estructuras básicas que pueden aparecer. ßConsideremos tres variables \\(X\\), \\(Y\\) y \\(Z\\). Las cuatro estructuras que tenemos que entender en primer lugar pueden verse también como métodos de razonamiento lógico derivados de las leyes de probabilidad:\n\nCausa común o bifurcaciones \\(X\\leftarrow Z \\rightarrow Y\\).\nCadenas o mediación \\(X\\rightarrow Z \\rightarrow Y\\).\nColisionadores \\(X\\rightarrow Z \\leftarrow Y\\).\nDescendientes, como en \\(X\\rightarrow Z \\rightarrow Y, Z\\to A\\).\n\nTodas estas estructuras pueden ser fuente de confusión, en el sentido de que producen patrones de correlación que pueden ser malinterpretados causalmente si no utilizamos supuestos causales.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#bifurcaciones-o-causa-común",
    "href": "05-dags.html#bifurcaciones-o-causa-común",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.5 Bifurcaciones o causa común",
    "text": "5.5 Bifurcaciones o causa común\nEn el siguiente ejemplo, llamamos a \\(Z\\) una causa que es común a \\(X\\) y \\(Y\\).\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   Z -&gt; X\n   Z -&gt; Y\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso,\n\n\\(X\\) y \\(Y\\) tienen asociación\nSi condicionamos (o estratificamos) con \\(Z\\), entonces \\(X\\) y \\(Y\\) son condicionalmente independientes.\n\nEste tipo de estructura también se llama bifurcación, o decimos más tradicionalmente que \\(Z\\) es un confusor en esta gráfica. Variación en \\(Z\\) produce variación conjunta de \\(X\\) y \\(Y\\).\nPor ejemplo, podríamos encontrar que el uso de aspirina \\(X\\) está asociado a una mortalidad más alta \\(Y\\). Una causa común es enfermedad grave que produce dolor (\\(Z\\)). Sin embargo, si condicionamos a personas sanas, veríamos que no hay relación entre uso de aspirina y mortalidad, igualmente veríamos que entre las personas enfermas el uso de aspirina no les ayuda a vivir más tiempo.\nEn este caso, tenemos:\n\\[p(x, y, z) =  p(z)p(x|z)p(y|z)\\] Y como el lado izquierdo es igual (en general) a \\(p(x,y|z)p(z)\\), obtenemos la independiencia condicional de \\(X\\) y \\(Y\\) dado \\(Z\\).\n\nEjemplo (simulación)\n\nrbern &lt;- function(n, prob){\n  rbinom(n, 1, prob = prob)\n} \nsimular_confusor &lt;- function(n = 10){\n  z &lt;- rbern(n, p = 0.5) |&gt; as.numeric()\n  x &lt;- rbern(n, p = z * 0.3 + (1 - z) * 0.8)\n  y &lt;- rbinom(n, 4, z * 0.9 + (1 - z) * 0.3)\n  tibble(x, z, y)\n}\nsims_confusor &lt;- simular_confusor(50000)\n\n\\(X\\) y \\(Y\\) están asociadas\n\nsims_confusor |&gt; select(x, y) |&gt; \n  count(x, y) |&gt; \n  group_by(x) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\n\n\n\n\nLo cual lo vemos también si calculamos la correlación:\n\ncor(sims_confusor |&gt; select(x,y)) |&gt; round(3)\n\n       x      y\nx  1.000 -0.423\ny -0.423  1.000\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1, vemos que \\(X\\) y \\(Y\\) son independientes, o dicho de otra manera, la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) sólo depende de \\(Z\\):\n\nsims_confusor |&gt; \n  count(x, y, z) |&gt; \n  group_by(x, z) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, z, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\n\n\n\n\nUna consecuencia es por ejemplo que la correlación debe ser cero:\n\ncor(sims_confusor |&gt; filter(z == 1) |&gt; select(x,y)) |&gt; round(3)\n\n      x     y\nx 1.000 0.001\ny 0.001 1.000\n\ncor(sims_confusor |&gt; filter(z == 0) |&gt; select(x,y)) |&gt; round(3)\n\n      x     y\nx 1.000 0.002\ny 0.002 1.000\n\n\nUn ejemplo con variables continuas podría ser como sigue:\n\nsimular_bifurcacion &lt;- function(n = 10){\n  z &lt;- rbern(n, p = 0.5)\n  x &lt;- rnorm(n, 100 + 20 * z, 15)\n  y &lt;- rnorm(n, 100 + 30 * z, 20)\n  tibble(x, z, y)\n}\nsims_bifurcacion &lt;- simular_bifurcacion(5000)\n\n\\(X\\) y \\(Y\\) son dependientes (por ejemplo si vemos la media condicional de \\(Y\\) dado \\(X\\):\n\nggplot(sims_bifurcacion, aes(x = x, y = y, colour = z)) + \n  geom_point(alpha = 0.2) +\n  geom_smooth(span = 1, se = FALSE)\n\n\n\n\n\n\n\n\nSi condicionamos a \\(Z\\), no hay dependencia entre \\(X\\) y \\(Y\\)\n\nggplot(sims_bifurcacion, aes(x = x, y = y, colour = z, group = z)) + \n  geom_point(alpha = 0.2) +\n  geom_smooth(span = 2)\n\n\n\n\n\n\n\n\n\n\nEjemplo: matrimonio y divorcio\nEn este ejemplo de McElreath (2020), se muestra que regiones de Estados Unidos con tasas más altas de matrimonio también tienen tasas más altas de divorcio.\n\ndata(WaffleDivorce)\nWaffleDivorce |&gt; \n  ggplot(aes(x = Marriage, y = Divorce)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAunque esta es una correlación clara, lo que nos interesa en este caso el efecto causal \\(M\\to D\\). Es importante notar que hay considerable variabilidad de la edad promedio al casarse a lo largo de los estados:\n\nWaffleDivorce |&gt; \n  ggplot(aes(sample = MedianAgeMarriage)) +\n  geom_qq() +\n  geom_qq_line()\n\n\n\n\n\n\n\n\nPara el modelo causal, tenemos que considerar las siguientes afirmaciones que no son muy difíciles de justificar:\n\nLa edad promedio al casarse de cada estado es un factor que influye en la tasa de divorcio (menor edad a casarse implica mayores tasas de divorcio, pues las parejas tienen más tiempo para divorciarse, porque la gente cambia más cuando es joven).\nAdicionalmente, si la gente tiende a casarse más joven, en cualquier momento hay más gente con probabilidad de casarse, por lo que esperaríamos que la edad al casarse también influye en la tasa de matrimonio.\n\nEsto implica que tenemos que considerar una causa común de la edad al casarse en nuestro diagrama causal:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    M\n    D\n    Edad\n  edge [minlen = 3]\n   Edad -&gt; M\n   Edad -&gt; D\n   M -&gt; D\n{rank=same; M; D;}\n\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nPor la discusión de arriba, es claro que es necesario considerar la edad al casarse si queremos estimar el efecto de tasa de matrimonio en la tasa de divorcio. Es posible que la correlación entre estas dos tasas puede ser explicada solamente por la edad al casarse, y que en realidad al flecha \\(M\\to D\\) sea muy débil o inexistente.\nYa que tenemos este modelo causal básico, tendríamos que proponer un proceso generador, proponer un modelo estadístico, y probar nuestra estimación. Este paso nos lo saltaremos (ver sección anterior), aunque sigue siendo necesario.\nPor el momento recordemos que si condicionamos (se dice también estratificar) por edad al casarse, y no vemos relación condicional entre las dos tasas, la relación que vimos en los datos es factible que haya aparecido por la causa común que induce correlación. Una manera en que estratificamos o condicionamos a una variable continua en un modelo lineal, como sigue:\n\\[D_i\\sim N(\\mu_i, \\sigma)\\] donde \\[\\mu_i = \\alpha + \\beta_M M_i + \\beta_E Edad_i\\] ¿De qué manera estamos estratificando por edad en este ejemplo? Obsérvese que para cada Edad que fijemos, la relación entre \\(M\\) y \\(D\\) es:\n\\[\\mu_i = (\\alpha + \\beta_E Edad) + \\beta_M M_i  \\] Cada valor de \\(E\\) produce una relación diferente entre \\(M\\) y \\(D\\) (en este caso particular, una recta diferente con distinta altura).\nAhora tenemos que poner iniciales para terminar nuestro modelo estadístico. En este punto poner iniciales informadas para estos coeficientes puede ser complicado (depende de cuánta demografía sabemos). Podemos usar un enfoque más simple, considerando las variables estandarizadas. De esta forma podemos poner iniciales más estándar. Utilizaremos\n\nescalar &lt;- function(x){\n  (x - mean(x))/sd(x)\n}\nWaffleDivorce &lt;- WaffleDivorce |&gt; \n  mutate(Marriage_est = escalar(Marriage), \n         Divorce_est = escalar(Divorce), \n         MedianAgeMarriage_est = escalar(MedianAgeMarriage))\ndatos_lista &lt;- list(\n  N = nrow(WaffleDivorce),\n  d_est = WaffleDivorce$Divorce_est, \n  m_est = WaffleDivorce$Marriage_est, \n  edad_est = WaffleDivorce$MedianAgeMarriage_est)\n\n\nmod_mat_div &lt;- cmdstan_model(\"./src/matrimonio-divorcio-1.stan\")\nprint(mod_mat_div)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  d_est;\n  vector[N]  m_est;\n  vector[N]  edad_est;\n}\n\nparameters {\n  real alpha;\n  real  beta_M;\n  real  beta_E;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  vector[N] w_media;\n  // determinístico dado parámetros\n  w_media = alpha + beta_M * m_est + beta_E * edad_est;\n}\n\nmodel {\n  // partes no determinísticas\n  d_est ~ normal(w_media, sigma);\n  alpha ~ normal(0, 1);\n  beta_M ~ normal(0, 0.5);\n  beta_E ~ normal(0, 0.5);\n  sigma ~ normal(0, 1);\n}\n\ngenerated quantities {\n  real dif;\n  {\n    //simulamos 50 estados\n    int M = 50;\n    array[M] real dif_sim;\n    for(i in 1:M){\n      real edad_sim_est = normal_rng(0, 1);\n      // fijamos el valor de M en 0 y 1 para el modelo con do(M)\n      real M_sim_0 = normal_rng(alpha * beta_M * 0 + beta_E * edad_sim_est, sigma);\n      real M_sim_1 = normal_rng(alpha * beta_M * 1 + beta_E * edad_sim_est, sigma);\n      dif_sim[i] = M_sim_1 - M_sim_0;\n    }\n    dif = mean(dif_sim);\n  }\n\n}\n\n\n\nsims_mod &lt;- mod_mat_div$sample(data = datos_lista, \n                   chains = 4, \n                   init = 0.1, step_size = 0.1,\n                   iter_warmup = 1000, \n                   iter_sampling = 1000,\n                   refresh = 0)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\nresumen &lt;- sims_mod$summary(c(\"alpha\", \"beta_M\", \"beta_E\", \"sigma\"))\n\n\nresumen |&gt; \n  ggplot(aes(x = variable, y = mean, ymin = q5, ymax = q95)) +\n  geom_hline(yintercept = 0, color = \"red\") +\n  geom_point() +\n  geom_linerange() +\n  coord_flip()\n\n\n\n\n\n\n\n\nY el resultado que obtenemos es que no observamos un efecto considerable de las tasas de matrimonio en las tasas de divorcio, una vez que estratificamos por la causa común de edad de matrimonio. Este ejemplo es simple y podemos ver el efecto causal directo en un sólo coeficiente \\(\\beta_M\\), pero de todas formas haremos contrastes como hicimos en la parte anterior.\n\n\n5.5.1 Simulando intervenciones\nLa manera más directa de definir efecto causal, bajo nuestros supuestos causales, es a través de intervenciones (imaginarias o reales).\n\n\n\n\n\n\nNota\n\n\n\nEntendemos saber una causa como poder predecir correctamente las consecuencias de una intervención en el sistema generador de datos.\n\n\nEn nuestro caso, el diagrama de arriba muestra nuestro modelo causal. Si nosotros alteramos este proceso causal, interviniendo en la tasa de matrimonio, la distribución de matrimonio ya no depende de la Edad (pues está bajo nuestro control). Esto quiere decir que ahora consideramos el siguiente diagrama, en donde la nueva dependendencia del divorcio del matrimonio la escribiremos como \\(p(D|do(M))\\):\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    M\n    D\n    Edad\n  edge [minlen = 3]\n   Edad -&gt; D\n   M -&gt; D\n{rank=same; M; D;}\n\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEs decir, borramos todas las flechas que caen en \\(M\\) (pues la estamos interveniendo al valor que queramos), y luego simulando \\(D\\).\nEn nuestro ejemplo (ve el código de Stan de arriba, la parte de generated quantities) simularemos los 50 estados bajo dos intervenciones: todos tienen la tasa promedio de matrimonio vs. los 50 estados con tasa de matrimonio un error estándar por encima de la tasa promedio. Repetimos esta comparación sobre todas las simulaciones de la posterior:\n\nsims_tbl &lt;- sims_mod$draws(format = \"df\") |&gt; \n  select(dif) \nsims_tbl |&gt; summarize(\n  q5 = quantile(dif, 0.05),\n  q95 = quantile(dif, 0.95)\n)\n\n# A tibble: 1 × 2\n      q5   q95\n   &lt;dbl&gt; &lt;dbl&gt;\n1 -0.276 0.272\n\n\n\nggplot(sims_tbl, aes(x = dif)) +\n  geom_histogram(bins = 50) +\n  geom_vline(xintercept = 0, color = \"red\")\n\n\n\n\n\n\n\n\nEn este caso, vemos que el resultado de la intervención no tienen una tendencia clara hacia incrementar o disminuir la tasa de divorcio, aunque existe variabilidad por la incertidumbre que tenemos acerca de las relaciones modeladas.\n\n\n\n\n\n\nTip\n\n\n\nLa relación que vimos entre matrimonio y divorcio en nuestro ejemplo es probablemente producida por la causa común Edad, y no necesariamente es causal.\n\n\nFinalmente, antes de terminar sería apropiado hacer chequeos predictivos posteriores, pero por el momento los omitiremos para avanzar en los otros tipos de estructuras básicas en los DAGs.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#cadenas-o-mediación",
    "href": "05-dags.html#cadenas-o-mediación",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.6 Cadenas o mediación",
    "text": "5.6 Cadenas o mediación\nEn este caso tenemos:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   X -&gt; Z\n   Z -&gt; Y\n}\n\", width = 150, height = 20)\n\n\n\n\n\n\nEn este caso,\n\nExiste asociación entre \\(X\\) y \\(Y\\), pero no existe relación directa entre ellas. Decimos que \\(Z\\) es un mediador del efecto de \\(X\\) sobre \\(Y\\).\nSi condicionamos a un valor de \\(Z\\), \\(X\\) y \\(Y\\) son condicionalmente independientes.\n\nPodemos pensar en \\(Z\\) como un mediador del efecto de \\(X\\) sobre \\(Y\\). Si no permitimos que \\(Z\\) varíe, entonces la información de \\(X\\) no fluye a \\(Y\\).\nPor ejemplo, si \\(X\\) tomar o no una medicina para el dolor de cabeza, \\(Z\\) es dolor de cabeza y \\(Y\\) es bienestar general, \\(X\\) y \\(Y\\) están relacionadas. Sin embargo, si condicionamos a un valor fijo de dolor de cabeza, no hay relación entre tomar la medicina y bienestar general.\nEn términos de factorización, podemos checar la independencia condicional: como \\(p(x,y,z) = p(x)p(z|x)p(y|z)\\), entonces\n\\[p(x, y | z) = p(x,y,z) / p(z) = (p(x)(z|x)) (p(y|z) / p(z))\\] y vemos que el lado izquierdo se factoriza en una parte que sólo involucra a \\(x\\) y \\(z\\) y otro factor que sólo tiene a \\(y\\) y \\(z\\): no hay términos que incluyan conjuntamente a \\(x\\), \\(y\\) y \\(z\\). Podemos de cualquier forma continuar notando\n\\[p(x)p(z|x)/p(z) = p(x,z)/p(z) = p(x | z)\\] de modo que\n\\[p(x, y | z) = p(x|z) p(y|z) \\]\nY mostramos un ejemplo simulado:\n\nrbern &lt;- function(n, prob){\n  rbinom(n, 1, prob = prob)\n} \nsimular_mediador &lt;- function(n = 10){\n  x &lt;- rbern(n, p = 0.5) |&gt; as.numeric()\n  z &lt;- rbern(n, p = x * 0.8 + (1 - x) * 0.3)\n  y &lt;- rbinom(n, 2, z * 0.7 + (1 - z) * 0.5)\n  tibble(x, z, y)\n}\nsims_mediador &lt;- simular_mediador(50000)\n\n\\(X\\) y \\(Y\\) son dependientes:\n\nsims_mediador |&gt; select(x, y) |&gt; \n  count(x, y) |&gt; \n  group_by(x) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\n\n\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1:\n\nsims_mediador |&gt; \n  count(x, y, z) |&gt; \n  group_by(x, z) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, z, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\n\n\n\n\nY vemos que la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) sólo depende de \\(Z\\). Una consecuencia es por ejemplo que la correlación debe ser cero:\n\ncor(sims_mediador |&gt; filter(z == 1) |&gt; select(x,y)) |&gt; round(3)\n\n      x     y\nx 1.000 0.001\ny 0.001 1.000\n\ncor(sims_mediador |&gt; filter(z == 0) |&gt; select(x,y)) |&gt; round(3)\n\n      x     y\nx 1.000 0.008\ny 0.008 1.000\n\n\nPodemos también hacer un ejemplo continuo:\n\nsimular_mediador &lt;- function(n = 10){\n  x &lt;- rnorm(n, 100, 10)\n  prob &lt;- 1 / (1 + exp(-(x - 100)/5))\n  z &lt;- rbern(n, p = prob)\n  y &lt;- rnorm(n, 100 + 30 * z, 15)\n  tibble(x, z, y)\n}\nsims_mediador &lt;- simular_mediador(2000)\n\n\\(X\\) y \\(Y\\) son dependientes (por ejemplo si vemos la media condicional de \\(Y\\) dado \\(X\\):\n\nggplot(sims_mediador, aes(x = x, y = y, colour = z)) + geom_point() +\n  geom_smooth(span = 1, se = FALSE)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\nSi condicionamos a \\(Z\\), no hay dependencia entre \\(X\\) y \\(Y\\)\n\nggplot(sims_mediador, aes(x = x, y = y, colour = z, group = z)) + \n  geom_point() +\n  geom_smooth(span = 2)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nNótese que en este ejemplo sí hay un efecto causal de \\(X\\) sobre \\(Y\\), pero está mediado por otra variable \\(Z\\). Si condicionamos a \\(Z\\), no hay relación entre \\(X\\) y \\(Y\\). El análisis condicionado podría llevarnos a una conclusión errónea de que \\(X\\) no influye sobre \\(Y\\).\n\n\n\n\n\n\nTip\n\n\n\nNota que no existe una diferencia estadística entre una bifurcación y una cadena: en ambos casos, las variables \\(X\\) y \\(Y\\) están correlacionadas, y son independientes una vez que condicionamos o estratificamos por \\(Z\\). Sin embargo, su tratamiento en inferencia causal es muy diferente.\n\n\n\nSesgo post-tratamiento\nEn McElreath (2020) se discute que en algunos estudios experimentales, se estratifica por variables que son consecuencia del tratamiento. Esto induce sesgo post-tratamiento, lo cual puede llevar a equivocaciones en donde parece que el tratamiento no tiene efecto cuando sí lo tiene. Incluso bajo condiciones de experimento (donde el tratamiento es asignado al azar) estratificar por mediadores es una mala idea. Ver más en McElreath (2020), donde por ejemplo cita una fuente que en estudios experimentales de Ciencia Política, casi la mitad de ellos sufre de este tipo de sesgo por estratificación por mediadores.\n\n\nEjemplo: Burks\nEste ejemplo es de Pearl y Mackenzie (2018). En 1926 Burks recolectó datos sobre qué tanto podría esperarse que la inteligencia de padres se hereda a los hijos (medido según una prueba de IQ). Construyó un diagrama parecido al de abajo:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape = circle]\n    U\n  node [shape=plaintext]\n  edge [minlen = 3]\n    IntPadres -&gt; NSE\n    NSE -&gt; IntHijos\n    U -&gt; NSE\n    U -&gt; IntHijos\n    IntPadres -&gt; IntHijos\n{rank = same; U}\n}\n\")\n\n\n\n\n\n\nComo el NSE es del hogar (una medida general de estatus social), se consideró en principio como una variable pre-tratamiento a la inteligencia de los niños por la que tradicionalmente se controlaba. Burks notó que hacer esto tenía no era apropiado, pues tiene como consecuencia cortar parte del efecto total de la inteligencia sobre el la inteligencia de los hijos. En otras palabras: la inteligencia de los padres hace más probable mejor NSE, y mejor NSE presenta mejores condiciones de desarrollo para sus hijos. Estatificar por esta variable bloquea este efecto.\nAdicionalmente, como veremos, condicionar a NSE abre un camino no causal entre Inteligencia de Padres e Hijos.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#colisionador-o-causas-alternativas",
    "href": "05-dags.html#colisionador-o-causas-alternativas",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.7 Colisionador o causas alternativas",
    "text": "5.7 Colisionador o causas alternativas\nEn este caso, a \\(Z\\) también le llamamos un colisionador. Este es el caso que puede ser más difícil de entender en un principio. Consiste de la siguiente estructura:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   X -&gt; Z\n   Y -&gt; Z\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\n\nEn este caso \\(X\\) y \\(Y\\) son independientes. Tanto \\(X\\) como \\(Y\\) influyen en \\(Z\\).\nSin embargo, si condicionamos a \\(Z\\) entonces \\(X\\) y \\(Y\\) están asociados.\n\nPor ejemplo, si observamos que el pasto está mojado, entonces saber que no llovió implica que probablemente se encendieron los aspersores.\nComo la conjunta se factoriza como:\n\\[p(x,y,z) = p(x)p(y)p(z|x,y)\\] Entonces integrando sobre \\(Z\\):\n\\[p(x,y) = \\int p(x,y,z)dz = p(x)p(y)\\int p(z|x,y)\\, dz\\] pero \\(p(z|x,y)\\) integra uno porque es una densidad, de forma que \\(x\\) y \\(y\\) son independientes.\nMostramos un ejemplo simulado:\n\nsimular_colisionador &lt;- function(n = 10){\n  x &lt;- rbern(n, 0.5) \n  y &lt;- rbinom(n, 2, 0.7)\n  z &lt;- rbern(n, p = 0.1 + 0.7 * x * (y &gt; 1)) \n  tibble(x, z, y)\n}\nsims_colisionador &lt;- simular_colisionador(50000)\n\n\\(X\\) y \\(Y\\) son independientes:\n\nsims_colisionador|&gt; select(x, y) |&gt; \n  count(x, y) |&gt; \n  group_by(x) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\n\n\n\ncor(sims_colisionador |&gt; select(x,y))\n\n             x            y\nx  1.000000000 -0.002419657\ny -0.002419657  1.000000000\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1:\n\nsims_colisionador |&gt; \n  count(x, y, z) |&gt; \n  group_by(x, z) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, z, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\n\n\n\n\nY vemos que la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) depende de \\(X\\) y de \\(Z\\).\nLas correlaciones condicionales, por ejemplo, no son cero:\n\nprint(\"Dado Z = 0\")\n\n[1] \"Dado Z = 0\"\n\ncor(sims_colisionador |&gt; filter(z == 0) |&gt; select(x,y)) |&gt; round(3)\n\n       x      y\nx  1.000 -0.278\ny -0.278  1.000\n\nprint(\"Dado Z = 1\")\n\n[1] \"Dado Z = 1\"\n\ncor(sims_colisionador |&gt; filter(z == 1) |&gt; select(x,y)) |&gt; round(3)\n\n      x     y\nx 1.000 0.374\ny 0.374 1.000\n\n\nOtro ejemplo con variables continuas:\n\nsimular_colisionador_2 &lt;- function(n = 10){\n  x &lt;- rnorm(n, 100, 20) \n  y &lt;- rnorm(n, 100, 20)\n  z &lt;- rbern(n, p = 0.92 * ((x + y) &gt; 220) + 0.05) \n  tibble(x, z, y)\n}\nsims_colisionador &lt;- simular_colisionador_2(1000)\n\n\\(X\\) y \\(Y\\) son independientes:\n\nggplot(sims_colisionador, aes(x = x, y = y)) + geom_point()\n\n\n\n\n\n\n\n\nSin embargo, si condicionamos a un valor de \\(Z\\), \\(X\\) y \\(Y\\) ya no son independientes:\n\nggplot(sims_colisionador, aes(x = x, y = y, group = z, colour = factor(z))) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE) \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nY vemos que condicional a \\(Z\\), \\(X\\) y \\(Y\\) están correlacionadas, aunque no hay relación causal entre \\(X\\) y \\(Y\\).\n\n5.7.1 Ejemplos de colisionadores\nExisten muchos ejemplos de colisionadores en análisis de datos. Algunos ejemplos se deben a sesgo de selección (puedes dibujar diagramas para cada uno de estos):\n\nPodemos observar correlaciones entre habilidades que en realidad son independientes si observamos muestras de estudiantes seleccionados por un examen de admisión (por ejemplo, para entrar es necesario tener alta habilidad atlética y/o alta habilidad académica).\nEntre los artículos científicos publicados (ver McElreath (2020)), aquellos que son más tomados por las noticias son los menos confiables. Esta correlación puede aparecer aunque no exista relación en proyectos científicos entre confiabilidad e interés de los medios, pues lo que se fondea o publica puede tener dos razones: ser trabajo muy confiable, o ser trabajo que “está de moda” o atrae la atención de los medios.\n\nPero también puede ser consecuencia de condicionar a variables endógenos (que resultan ser colisionadores), y ocurren como parte del procesamiento o construcción de modelos. Un ejemplo interesante de McElreath (2020) es el siguiente:\n\nNos interesa saber si la edad influye en la felicidad o bienestar de las personas.\nAlgún investigador puede pensar que es necesario controlar por sí las personas están casadas o no, por ejemplo, para “quitar” ese efecto o algo así.\nEsto puede ser mala idea si consideramos que un diagrama apropiado puede ser \\(F \\rightarrow Matrim \\leftarrow Edad\\), que se basa en las observaciones de que personas más felices generalmente tienen mayor posibilidad de casarse, y también conforme pasa el tiempo, hay más oportunidades para casarse.\nEsto induce una correlación no causal entre edad y felicidad dentro de los grupos de casados y no casados, y puede llevar a conclusiones incorrectas.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#razonamiento-de-descendientes",
    "href": "05-dags.html#razonamiento-de-descendientes",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.8 Razonamiento de descendientes",
    "text": "5.8 Razonamiento de descendientes\nCondicionar a un descendiente puede entenderse como “condicionar parcialmente” o “débilmente” a los padres de ese descendiente.\nPor ejemplo, condicionar a un colisionador también produce dependencias condicionales:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n    A\n  edge [minlen = 3]\n   X -&gt; Z\n   Y -&gt; Z\n   Z -&gt; A\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso,\n\n\\(X\\) y \\(Y\\) son independientes\n\\(X\\) y \\(Y\\) son dependientes si condicionamos a \\(A\\).\n\nDependiendo de la naturaleza de la asociación entre el colisionador \\(Z\\) y su descendiente \\(A\\), esta dependencia puede ser más fuerte o más débil.\nPor ejemplo, en nuestro ejemplo donde el pasto mojado es un colisionador entre cuánta agua dieron los aspersores y cuánta lluvia cayó, un descendiente del pasto mojado es el estado de las plantas del jardín. Aunque los aspersores trabajan independientemente de la lluvia, si observamos que las plantas se secaron entonces lluvia y aspersores están correlacionados: por ejemplo, si noto que los aspersores están descompuestos, entonces concluimos que no hubo lluvia.\n\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X [label = lluvia]\n    Y [label = aspersores]\n    Z [label = humedad]\n    A [label = plantas]\n  edge [minlen = 3]\n   X -&gt; Z\n   Y -&gt; Z\n   Z -&gt; A\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEjemplo\n\nsimular_desc &lt;- function(n = 10){\n  x &lt;- rbern(n, 0.5) \n  y &lt;- rbinom(n, 2, 0.7)\n  z &lt;- rbern(n, p = 0.1 + 0.7 * x * (y &gt; 1)) \n  a &lt;- rbern(n, p = 0.5 + 0.5 * z)\n  tibble(x, z, y, a)\n}\nsims_colisionador &lt;- simular_desc(50000)\n# No hay correlación\ncor(sims_colisionador$x, sims_colisionador$y)\n\n[1] -0.002188914\n\n\nSin embargo,\n\ncor(sims_colisionador |&gt; filter(a ==0) |&gt; select(x,y))\n\n           x          y\nx  1.0000000 -0.2831817\ny -0.2831817  1.0000000\n\n\n\ncor(sims_colisionador |&gt; filter(a ==1) |&gt; select(x,y))\n\n          x         y\nx 1.0000000 0.1076867\ny 0.1076867 1.0000000\n\n\n\n\n5.8.1 Ejemplo: dependencias de colisionador\nVerificamos que en nuestro modelo de Santa Clara, efectivamente nuestro modelo no implica ninguna dependencia no condicional entre sensibilidad de la prueba y prevalencia. Eso debería ser claro de la simulación, pero de todas formas lo checamos\n\nlibrary(cmdstanr)\nmod_sc &lt;- cmdstan_model(\"./src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; n;\n  int&lt;lower=0&gt; kit_pos;\n  int&lt;lower=0&gt; n_kit_pos;\n  int&lt;lower=0&gt; kit_neg;\n  int&lt;lower=0&gt; n_kit_neg;\n}\n\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; //seroprevalencia\n  real&lt;lower=0, upper=1&gt; sens; //sensibilidad\n  real&lt;lower=0, upper=1&gt; esp; //especificidad\n}\n\ntransformed parameters {\n  real&lt;lower=0, upper=1&gt; prob_pos;\n\n  prob_pos = theta * sens + (1 - theta) * (1 - esp);\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  // modelos para resultados del kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales para cantidades no medidas\n  theta ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\nEn este caso, no pondremos información acerca de positivos en la prueba:\n\ndatos_lista &lt;- list(N = 0, n = 0,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste &lt;- mod_sc$sample(data = datos_lista, refresh = 1000, iter_sampling = 400)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 1 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 1 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 2 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 2 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 3 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 3 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 4 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 4 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims &lt;- ajuste$draws(c(\"theta\", \"sens\", \"esp\"), format = \"df\")\nresumen &lt;- ajuste$summary(c(\"theta\"))\n\n\nggplot(sims, aes(x = theta, y = sens)) + geom_point() +\n  scale_x_sqrt()\n\n\n\n\n\n\n\n\nNo vemos ninguna asocación entre estas dos variables.\nSin embargo, al condicionar al valor de Positivos, creamos una relación que no podemos interpretar como casual. En este caso particular supondremos prácticamente fija la sensibilidad para ver solamente lo que sucede en el colisionador de especificidad y número de positivos (la especificidad en este ejemplo es más crítica):\n\ndatos_lista &lt;- list(N = 3300, n = 50,\n kit_pos = 1030000, n_kit_pos = 1220000, # números grandes para que esté practicamente\n# fija la sensibilidad\n kit_neg = 399, n_kit_neg = 401)\najuste &lt;- mod_sc$sample(data = datos_lista, refresh = 1000, iter_sampling = 400)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 1 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 1 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 2 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 2 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 3 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 3 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 4 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 4 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims &lt;- ajuste$draws(c(\"theta\", \"sens\", \"esp\"), format = \"df\")\nresumen &lt;- ajuste$summary(c(\"theta\"))\n\n\nggplot(sims, aes(x = theta, y = esp)) + geom_point() \n\n\n\n\n\n\n\n\nY vemos que condiconando al colisionador, obtenemos una relación fuerte entre prevalencia y especificidad de la prueba: necesitaríamos más datos de especificidad para obtener una estimación útil.\n\nLa razón de que la especificidad es más importante en este ejemplo es que la prevalencia es muy baja al momento del estudio, y los falsos positivos pueden introducir más error en la estimación\nTambién repetimos nótese que el análisis correcto de estos datos no se puede hacer con intervalos separados para cada cantidad, sino que debe examinarse la conjunta de estos parámetros.\n\n\nCon estas tres estructuras elementales podemos entender de manera abstracta la existencia o no de asociaciones entre nodos de cualquier gráfica dirigida.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#d-separación",
    "href": "05-dags.html#d-separación",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.9 d-separación",
    "text": "5.9 d-separación\nAhora buscaremos describir todas las posibles independendencias condicionales y no condicionales que pueden aparecer en una gráfica, para entender cómo aparecen asociaciones entre variables de nuestro modelo, dependiendo del tipo de condicionamiento que hacemos.\nVeremos que el criterio es algorítmico. Más adelante discutiremos cuáles de estas asociaciones se deben a efectos causales y cuáles no, y esto nos permitirá establecer estrategias de condicionamiento (qué variables controlar o no), recolección de datos y diseño de experimentos para construir los estimadores correctos de los efectos causales de interés.\n\n\n\n\n\n\nd-separación: Caminos activos y bloqueados\n\n\n\n\nUn camino \\(p\\) entre \\(X\\) y \\(Y\\) es una sucesión de aristas que conecta a \\(X\\) con \\(Y\\) (sin importar) la dirección de las aristas.\n\nAhora supongamos que \\(Z = \\{Z_1,Z_2,\\ldots, Z_q\\}\\) son una colección de nodos. Decimos que un camino \\(p\\) entre \\(X\\) y \\(Y\\) está activo condicional a los nodos en \\(Z\\) cuando:\n\nSiempre que hay un colisionador \\(X_i\\to U\\gets X_j\\) en el camino \\(p\\), entonces \\(U\\) o alguno de sus descendientes está en \\(Z\\)\nNingún otro nodo a lo largo de \\(p\\) está en \\(Z\\).\n\nEn caso contrario, decimos que el camino \\(p\\) está bloqueado.\nSi \\(Z\\) bloquea todos los caminos posibles entre \\(X\\) y \\(Y\\), decimos que \\(X\\) y \\(Y\\) están \\(d\\)-separados condicionalmente a \\(Z\\), o \\(d\\)-separados por \\(Z\\).\n\n\nSegún la discusión que tuvimos arriba de los modos de razonamiento en gráficas de modelos probabilísticos, el siguiente teorema no es sorpresa:\n\n\n\n\n\n\nCriterio de d-separación\n\n\n\nEn una DAG \\(G\\):\n\nSi dos variables están d-separadas por las variables \\(Z\\), entonces \\(X\\) y \\(Y\\) son condicionalmente independientes dadas las variables en \\(Z\\) para cualquier conjunta representada por \\(G\\).\nSi dos variables no están d-separadas por \\(Z\\), entonces existen conjuntas representadas por \\(G\\) tales que \\(X\\) y \\(Y\\) no tienen dependencia condicional dado \\(Z\\).\n\n\n\nNota 1: nótese que este teorema nos da una manera abstracta de razonar acerca de la asociación en un modelo gráfico: no es necesario saber la forma particular de las condicionales para utilizarlo.\nNota 2: Vale la pena mencionar que el segundo inciso en general es una implicación más fuerte: cuando no hay \\(d\\)-separación, existe algún tipo de dependencia casi seguro (en el sentido probabilístico de posible conjuntas).\nNota 3: Las independencias condicionales también pueden ser útiles para checar los supuestos de nuestro modelo: si encontramos asociaciones fuertes (condicionales o no) entre variables que nuestra estructura implica independencia condicional, entonces puede ser que nuestra estructura causal requiera revisión. Qué tanto podemos probar esto depende del tamaño de los datos que tengamos y de el tipo de condicionamiento que estamos haciendo.\nFinalmente (ver por ejemplo Koller y Friedman (2009), p 75), existe un algoritmo eficiente para encontrar todas las posibles independencias condicionales implicadas por una gráfica:\n\n\n\n\n\n\nCálculo de d-separación\n\n\n\nExiste un algoritmo de complejidad lineal en el tamaño de la gráfica para encontrar todos los nodos con caminos activos a un nodo \\(X\\) condicional a las variables \\(A\\).\n\n\nVer por ejemplo el sitio dagitty.net, donde podemos poner nuestra gráfica y enlistar todas los supuestos de independencia condicional implicados por un modelo.\n\nEjemplo\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Z \n    W \n    X\n    Y \n    U\n  edge [minlen = 3]\n    Z -&gt; W\n    X -&gt; W\n    X -&gt; Y\n    W -&gt; U\n    S -&gt; Y\n    UZ -&gt; Z\n    V -&gt; Z\n    V -&gt; S\n}\n\")\n\n\n\n\n\n\nConsideremos la relación entre Z y Y. Primero vemos que hay dos caminos entre \\(Z\\) y \\(Y\\), que son \\(p_1:X\\gets V \\to S\\) y \\(p_2: Z\\to W \\gets X \\to Y\\)\n\nEn primer lugar, ¿son independientes si no condicionamos a ninguna variable? No, pues el camino \\(p_1\\) es activo, e induce correlación.\n¿Son condicionalmente independientes si condicionamos a \\(V\\)? En este caso, condicionar a \\(V\\) bloquea el camino \\(p_1\\). El camino \\(p_2\\) está bloqueado por el colisionador \\(W\\), así que todos los caminos están bloqueados si condicionamos a \\(V\\). Por lo tanto \\(Z\\) y \\(Y\\) son condicionalmente independientes dado \\(V\\), o \\(Z\\perp\\!\\!\\!\\perp Y|V\\).\nSi condicionamos a \\(W y V\\), ¿son independientes \\(Z\\) y \\(Y\\)? No. El camino \\(p_1\\) está bloqueado, así que ese no induce asociación. Sin embargo, al condicionar al colisionador \\(W\\) activamos el camino \\(p_2\\).\nAhora supongamos que tenemos datos condicionales a algún valor de \\(W\\) solamente. Condicionando a \\(V\\) bloqueamos el camino \\(p_1\\), pero el camino \\(p_2\\) está activo. ¿Qué pasaría si condicionamos adicionalmente a \\(X\\)? En este caso, el conjunto de condicionamiento es \\(\\{V, W, X\\}\\). El camino \\(p_2\\) está bloqueado. Y aunque condicionamos al colisionador, \\(X\\) bloque el camino. Por lo tanto \\(Z\\) y \\(Y\\) son condicionalmente independientes dado \\(\\{V, W, X\\}\\).\n\n\n\nEjercicio\nRepite el ejemplo anterior para la siguiente gráfica. Analiza que pasa si condicionamos o no a valores de \\(T\\), y qué pasa si adicionalmente condicionamos a \\(W\\), y luego repite los pasos del ejemplo anterior.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Z \n    W \n    X\n    Y \n    U\n    T\n  edge [minlen = 3]\n    T -&gt; Z\n    T -&gt; Y\n    Z -&gt; W\n    X -&gt; W\n    X -&gt; Y\n    W -&gt; U\n    S -&gt; Y\n    UZ -&gt; Z\n}\n\")\n\n\n\n\n\n\n\n\nEjemplo (análisis de factores)\nEn análisis de factores intentamos expresar variables observadas \\(X_i\\) en función de relativamente pocas variables latentes \\(F_j\\). El diagrama que representa sus supuestos básicos es uno como el siguiente:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    F1 [label = &lt;F&lt;sub&gt;1&lt;/sub&gt; &gt; ]\n    F2 [label = &lt;F&lt;sub&gt;2&lt;/sub&gt; &gt; ]\n  node [shape=plaintext]\n    X1 [label = &lt;X&lt;sub&gt;1&lt;/sub&gt; &gt; ]\n    X2 [label = &lt;X&lt;sub&gt;2&lt;/sub&gt; &gt; ]\n    X3 [label = &lt;X&lt;sub&gt;3&lt;/sub&gt; &gt; ]\n    X4 [label = &lt;X&lt;sub&gt;4&lt;/sub&gt; &gt; ]\n    X5 [label = &lt;X&lt;sub&gt;5&lt;/sub&gt; &gt; ]\n  edge [minlen = 3]\n    F1 -&gt; X1\n    F1 -&gt; X2\n    F1 -&gt; X3\n    F1 -&gt; X4\n    F1 -&gt; X5\n    F2 -&gt; X1\n    F2 -&gt; X2\n    F2 -&gt; X3\n    F2 -&gt; X4\n    F2 -&gt; X5\n}\n\")\n\n\n\n\n\n\n\n\\(F_1\\) y \\(F_2\\) son independientes\n\\(X_i\\) y \\(X_j\\) son condicionalmente independientes dadas \\(F_1\\) y \\(F_2\\)\n\nUsualmente hacemos supuestos adicionales como linealidad \\[E[X_i|F_1, F_2] = \\lambda_{i,1}F_1+  \\lambda_{i,1}F_1\\] y por ejemplo normalidad de \\(X_i\\) condicional a los factores.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#caminos-causales",
    "href": "05-dags.html#caminos-causales",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.10 Caminos causales",
    "text": "5.10 Caminos causales\nSi el DAG que consideramos representa relaciones causales (mecanísticas) entre las variables, es decir, qué variable “escucha” a qué otras para decidir su valor, entonces podemos hacer la siguiente definición:\n\n\n\n\n\n\nCaminos causales\n\n\n\nEn un DAG, los caminos causales entre \\(X\\) y \\(Y\\) son de la forma \\(X\\to U_1\\to U_2 \\to \\cdots U_j \\to Y\\). Puede haber varios de ellos en un diagrama dado, y cada uno representa un mecanismo en que cambios en \\(X\\) producen cambios en \\(Y\\)\nSi nos interesa el efecto total de \\(X\\) sobre \\(Y\\),\n\nQueremos que todos los caminos causales de \\(X\\) a \\(Y\\) estén activos,\nQueremos condicionar para que todos los caminos no causales estén bloqueados, en particular, no queremos condicionar a colisionadores o sus descendientes que introduzcan relaciones no causales, y queremos bloquear caminos no casuales creados por bifurcaciones.\n\nSi nos interesa el efecto directo de \\(X\\) sobre \\(Y\\),\n\nAdicionalmente a los puntos del efecto directo, queremos condicionar para bloquear también todos los caminos causales que no sean directos.\n\n\n\n\n5.10.1 Ejemplo\nEn la tarea vimos un diagrama como sigue para el problema de los zorros:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=plaintext]\n    A\n    F\n    G\n    W\n  edge [minlen = 3]\n    A -&gt; F\n    F -&gt; G\n    F -&gt; W\n    G -&gt; W\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nVimos que para calcular el efecto directo de \\(F\\) sobre \\(W\\), por ejemplo, es necesario bloquear el camino que pasa por \\(G\\) (estratificar por este nodo). Para el efecto total no es necesario condicionar a ningún otro nodo.\nAhora supongamos que creemos que \\(G\\) y \\(W\\) tienen una causa común \\(U\\) no observada.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape = circle]\n  U\n  node [shape=plaintext]\n    A\n    F\n    G\n    W\n  edge [minlen = 3]\n    A -&gt; F\n    F -&gt; G\n    F -&gt; W\n    G -&gt; W\n    U -&gt; G\n    U -&gt; W\n{rank=same U;G}\n\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nEn este caso:\n\nPodemos estimar el efecto total de \\(F\\) sobre \\(W\\) sin condicionar a nada. La adición de \\(U\\) no crea ningún nuevo camino no causal activo entre \\(F\\) y \\(W\\).\nSin embargo, no es posible estimar el efecto directo de \\(F\\) sobre \\(W\\): la razón es que si condicionamos a \\(G\\), entonces el camino no causal \\(F\\rightarrow G \\leftarrow U \\rightarrow W\\) se activa. Si conociéramos \\(U\\) podríamos bloquearlo.\n\n\n\n\n\nKoller, D., y N. Friedman. 2009. Probabilistic Graphical Models: Principles and Techniques. MIT Press.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.\n\n\nPearl, Judea, y Dana Mackenzie. 2018. The Book of Why: The New Science of Cause and Effect. New York: Basic Books.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html",
    "href": "06-calculo-do.html",
    "title": "6  Identificación y cálculo-do",
    "section": "",
    "text": "6.1 Cambiando el proceso generador de datos\nComenzamos con el ejemplo más simple de una variable confusora:\ngrViz(\"\n  digraph {\n    node [shape = plaintext];\n    X [label = 'X'];\n    Y [label = 'Y'];\n    U [label = 'U'];\n    X -&gt; Y;\n    U-&gt; X ;\n    U -&gt; Y;\n  {rank = same; X; Y;}\n  }\n  \", width = 200, height = 50)\nNos interesa estimar el efecto causal de \\(X\\) sobre \\(Y\\). Sucede que en muchas ocasiones existen variables como \\(U\\) que son causas comunes de \\(X\\) y \\(Y\\). Como vimos, esto implica que no podemos simplemente ver la correlación entre \\(X\\) y \\(Y\\) para entender el efecto de \\(X\\) sobre \\(Y\\), pues una causa común de variación conjunta entre estas dos variables. Esta variable \\(U\\) puede ser observada o no.\nEste tipo de confusores ocurren muchas veces en datos observacionales (es decir, de un proceso o sistema que funcione sin intervención de los investigadores). Por ejemplo, si un estudio observa que aquellos que se aplicaron (voluntariamente) un tratamiento \\(X\\), tienen menor riesgo de hospitalización \\(Y\\) por cierta enfermadad. Sin embargo, se observa también que aquellos que se aplicaron el tratamiento tienen menos riesgo de tener accidentes viales. Esto indica que la observación de la reducción de riesgo de hospitalización entre los que escogieron el tratamiento probablemente se debe al menos en parte a una variable confusora (por ejemplo, qué tipo de actividades hacen, qué tan cautelosos son, etc.)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#cambiando-el-proceso-generador-de-datos",
    "href": "06-calculo-do.html#cambiando-el-proceso-generador-de-datos",
    "title": "6  Identificación y cálculo-do",
    "section": "",
    "text": "6.1.1 Experimentación\nCuando es posible, podemos proponer generar nuevos datos donde alteramos el proceso generador. Una forma muy efectiva y útil, que es muy conveniente cuando es posible, es controlar la asignación del tratamiento. Si en el diagrama anterior, diseñamos un estudio donde observamos a un grupo de personas para las cuales el tratamiento se asignó de acuerdo a un proceso aleatorio, entonces el nuevo diagrama para este nuevo proceso generador es:\n\ngrViz(\"\n  digraph {\n    node [shape = plaintext];\n    X [label = 'X'];\n    Y [label = 'Y'];\n    R\n    U [label = 'U'];\n    R -&gt; X\n    X -&gt; Y;\n    U -&gt; Y;\n  {rank = same; R;X; Y;}\n  }\n  \")\n\n\n\n\n\nNótese que:\n\nLa variable \\(R\\) no puede ser endógena (es decir, ninguna flecha del sistema puede incidir en ella), pues se utiliza un dado o algo totalmente no relacionado para asignar el tratamiento. Por ejemplo, también podríamos asignar el tratamiento otra manera determinística como si el día de nacimiento de la persona es par o impar.\nEn este nuevo diseño, no puede existir una flecha de \\(U\\) a \\(X\\), pues nada en \\(X\\) responde a cambios en \\(X\\), qué solo depende del proceso de aleatorización \\(R\\).\n\nEn este caso, no es necesario estratificar por ninguna variable y podemos proponer directamente un modelo estadístico para \\(Y\\) en función de \\(X\\) que nos permita estimar el efecto causal de \\(X\\) sobre \\(Y\\).\n\n\n\n\n\n\nExperimentos\n\n\n\nEsto describe la idea básica de un experimento simple: es una herramienta para modificar el proceso generador de datos que nos permite identificar efectos causales de manera relativamente simple.\nCuando es posible hacer experimentos de calidad, esta puede ser la mejor forma de estimar efectos causales.\n\n\nEn muchos casos, sin embargo, no es posible hacer experimentos de calidad. Hay varias diversas razones, por ejemplo cuando se trata de experimentos que involucran personas:\n\nNo es ético aleatorizar: es totalmente inaceptable asignar aleatoriamente a personas a un tratamientos como fumar 20 cigarros al día, o aleatorizar a niños a recibir educación o no.\nAleatorización imposible o imperfecta: no es posible lograr un control total sobre la asignación del tratamiento, y la adherencia al tratamiento asignado de las personas puede variar (por ejemplo, uso de tapabocas en escuelas). A lo más podemos considerar los efectos de una política que intenta tratar a una selección aleatoria de individuos (IIT, o intent-to-treat).\n\nAsí que muchas preguntas causales no están sujetas a modificaciones del proceso generador de datos mediante aleatorización, y es necesario recurrir a otras estrategias.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#el-operador-do",
    "href": "06-calculo-do.html#el-operador-do",
    "title": "6  Identificación y cálculo-do",
    "section": "6.2 El operador do",
    "text": "6.2 El operador do\nRegresamos al diagrama original donde \\(U\\) es una causa común de \\(X\\) y \\(Y\\), y que no tenemos recursos o no es posible hacer un experimento. ¿Existe algún procedimiento estadístico que nos permita estimar el efecto causal de \\(X\\) sobre \\(Y\\)?\nEscribiremos la distribución condicional de la respuesta \\(Y\\) dada una manipulación de \\(X\\) como sigue (es decir, en la situación experimental):\n\\[p(Y| do(X=x))\\]\nEsto significa: ¿cómo se distribuye la \\(Y\\) dado que intervenimos en la población completa (aunque podemos también considerar subpoblaciones más adelante) para poner en \\(X=x\\)? En primer lugar, notemos que esto no es lo mismo que la distribución condicional usual\n\\[p(Y|X=x),\\] que siempre podemos estimar directamente de los datos, y no es la que nos interesa. En el siguiente ejemplo vemos la distinción entre las dos distribuciones:\n\nEjemplo\nSupongamos que tenemos el siguiente diagrama causal. Supondremos también que conocemos todas las relaciones funcionales involucradas.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n   T -&gt; A\n   T -&gt; Z\n   \n   \n}\n\", width = 100, height = 50)\n\n\n\n\nGráfica de datos observacionales\n\n\ndonde \\(T\\) es la temperatura, \\(A\\) son las unidades de agua embotellada vendidas y \\(Z\\) es la actividad de los mosquitos (medido con muestreo, por ejemplo).\nNo interesa contestar la pregunta: ¿qué tanto influyen las ventas de agua embotellada en la actividad de los mosquitos? Del diagrama, sabemos que no hay ningún camino causal de \\(Z\\) a \\(A\\), por lo que nuestra respuesta debería ser igual a 0.\nSin embargo, sabemos que estas dos variables están asociadas (por el análisis de DAGs), de manera que describir cómo cambia \\(p(Z|A)\\) cuando condicionamos a distintos valores de \\(A\\) no responde nuestra pregunta. La distribución \\(p(Z|do(A = a))\\) nos dice cómo se distribuye \\(Z\\) cuando manipulamos \\(a\\) artificialmente. Por ejemplo, si cerramos todas las tiendas un día haciendo \\(do(A=0)\\), veríamos que esta variable no tiene efecto sobre la actividad de mosquitos, por ejemplo comparado con \\(do(A = 10000)\\).\nIlustramos la diferencia entre \\(p(Y|X)\\) y \\(p(Y|do(X))\\) simulando del ejemplo anterior. Supondremos que sólo consideramos un día del año a lo largo de varios años, para no modelar el comportamiento cíclo de la temperatura:\n\nsimular_t &lt;- function(n = 10, dia = 150){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima &lt;- rnorm(n, 28, 2)\n  mosquitos &lt;- rpois(n, 250 + 10 * (t_maxima - 28))\n  a_unidades &lt;- rnorm(n, 20000 + 2000 * (t_maxima -  28), 2000)\n  tibble(t_maxima, a_unidades, mosquitos)\n}\nset.seed(128)\nsimular_dias &lt;- simular_t(50)\n\nSi simulamos, vemos que \\(mosquitos\\) y \\(unidades\\) son dependientes, pues tenemos un camino abierto dado por la bifurcación en temperatura:\n\nggplot(simular_dias, aes(x = a_unidades, y = mosquitos)) + geom_point() +\n  geom_smooth(method = \"loess\", method.args = list(degree = 1)) +\n  xlab(\"Ventas de agua embotellada\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nSabemos que esta asociación no es causal, pues no hay caminos causales entre estas variables dos variables, pero que hay una dependencia debido a la bifurcación en \\(T\\). La gráfica muestra que la media condicional \\(E[M|A=a]\\) depende fuertemente de \\(a\\), lo que quiere decir que \\(p(m|a)\\) depende de \\(a\\) fuertemente.\nEn este caso, nos interesaría saber qué sucede si alteramos artificalmente el número de botellas de agua vendidas (puedes imaginar distintas maneras de hacer esto).\nComo en este ejemplo conocemos todas las relaciones funcionales, y. nuestros supuesto es que el diagrama mostrado es correcto, podemos cambiar nuestra simulación para simular el proceso generador de datos del experimento asociado.\nComo veremos, esto se puede entender como una cirugía de la gráfica original donde quitamos las aristas que inciden en \\(A\\). Desde el punto de vista del proceso generador, si intervenimos el proceso generador deberíamos excluir cómo \\(A\\) responde a otras variables, pues ahora la estamos fijando:\n\nsimular_cirugia &lt;- function(n = 10, a_unidades = a_unidades){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima &lt;- rnorm(n, 28, 2)\n  #### cirugía #########\n  # ahora a_unidades es fijado por nosotros:\n  # a_unidades &lt;- rnorm(n, 20000 + 2000 * (t_maxima -  28), 2000)\n  a_unidades &lt;- a_unidades\n  ######################\n  mosquitos &lt;- rpois(n, 250 + 10 * (t_maxima - 28))\n  tibble(t_maxima, a_unidades, mosquitos)\n}\n\nY ahora simulamos y graficamos \\(p(Z|do(A=a))\\) para distintos valores de \\(a\\):\n\nset.seed(128)\nsimular_dias_2 &lt;- map_df(seq(10000, 30000, 1000),\n  \\(u) simular_cirugia(50, a_unidades = u))\n\n\nggplot(simular_dias_2, aes(x = a_unidades, y = mosquitos)) +\n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\ncor(simular_dias_2$mosquitos, simular_dias_2$a_unidades)\n\n[1] -0.05055934\n\n\ny vemos, como esperaríamos, que no hay relación entre unidades de agua embotellada y mosquitos.\nDesde el punto de vista de la gráfica, la manipulación donde fijamos manualmente \\(A\\) sería:\nCuando hacemos esto, quitamos las aristas que van hacia \\(A\\), pues \\(A\\) ya no está determinado por el proceso generador de datos. Tenemos entonces la nueva gráfica:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n   A\n  edge [minlen = 3]\n   T -&gt; Z\n{ rank = same; A; Z }\n}\n\", width = 100, height = 50)\n\n\n\n\nGráfica con intervención en A\n\n\nEn esta nueva gráfica, \\(A\\) y \\(Z\\) son independientes, que es la respuesta correcta. Como cambiamos la gráfica, su proceso generador es diferente al original de los datos observados. Sin embargo, en este ejemplo puedes ver por qué es claro que el cambio que hicimos (manipular \\(A\\) en lugar de que esté determinado por su proceso generador original) no cambia el modelo de \\(Z\\), de manera que podemos simular de nuestro nuevo proceso generador donde manipulamos \\(A\\):",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#cálculo-do-de-pearl",
    "href": "06-calculo-do.html#cálculo-do-de-pearl",
    "title": "6  Identificación y cálculo-do",
    "section": "6.3 Cálculo-do de Pearl",
    "text": "6.3 Cálculo-do de Pearl\nEl cálculo do nos da reglas para operar con probabilidades que incluyen nuestro operador do de intervención, y nos dice cómo pasar de cantidades que incluyen manipulaciones do a cantidades estadísticas que se pueden estimar directamente de los datos.\nEn este ejemplo anterior, veremos cómo es el argumento:\nNótese que al intervenir \\(A\\) hemos modificado el proceso generador. Si la conjunta original tiene distribución \\(p\\), escribimos \\(p_m\\) para la conjunta de la gráfica modificada, de manera que \\(p(Z|do(A)) = p_m(Z|A)\\): con esto podemos pasar de una pregunta causal (lado izquierdo con operador do) a una estadística (lado derecho).\nAunque intuitivamente vimos cómo simular de esta distribución arriba, especificamos abajo qué reglas son las que nos permiten hacer esto: ¿cómo calculamos \\(p_m\\)?\nEn primer lugar, consideremos la marginal \\(p_m(T)\\). Esta marginal es invariante a nuestra cirugía, pues la arista \\(T\\to A\\) que eliminamos \\(T\\) no afecta el proceso que determina \\(T\\). De modo que la marginal del proceso modificado es igual a la marginal observada:\n\\[p_m(T) = p(T)\\] En segundo lugar, tenemos que\n\\[p_m(Z|T=t,A=a) = p(Z|T=t,A=a),\\] Pues el proceso por el cual \\(Z\\) responde a \\(T\\) y \\(A\\) es el mismo, no importa si \\(A\\) fue modificada artificalmente o no.\nJuntamos estos argumentos. Primero, por definición,\n\\[p(Z|do(A=a)) = p_m(Z|A=a).\\]\nAhora por la regla de probabilidad total, podemos condicionar todo a \\(T\\) y marginalizar. La segunda igualdad la obtenemos por la independencia entre \\(T\\) y \\(Z\\) en nuestra gráfica modificada (están \\(d\\) separadas):\n\\[p_m(z|a) = \\int p_m(z|a,t)p_m(t|a)dt = \\int p_m(z|a,t)p_m(t)dt\\] En segunda igualdad, nótese que cambiamos \\(p_m(t|a) = p_m(t)\\), lo cual podemos verificar pues en la gráfica modificada \\(A\\) y \\(T\\) están \\(d\\)-separados, lo que implica que son condicionalmente independientes.\nFinalmente, las últimas dos distribuciones podemos extraerlas de los datos, como explicamos arriba \\(p_m(z|t,a) = p(z|t,a)\\) y \\(p_m(t) = p(t),\\) y terminamos con la fórmula:\n\\[p(z|do(a))=p_m(z|a) = \\int p(z|a,t)p(t)dt \\]\nLas dos distribuciones de la derecha están en el contexto de \\(p\\), el proceso generador de datos original. Así que podemos estimarlas de los datos observados.\n\nEste argumento justifica el proceso que hicimos arriba: simulamos primero \\(T\\) con su proceso generador, y después simulamos \\(Z\\) condicional a \\(A\\) y \\(T\\) según el proceso generador original, el cual no depende de \\(A\\) en este ejemplo.\n\nEn el caso de arriba, simulamos de la distribución para entender cómo se distribuía \\(Z\\) dependiendo de modificaciones a \\(A\\). Muchas veces nos interesa calcular solamente la esperanza condicional, es decir, cuál es el valor esperado de la variable de interés dado el nivel intervenido, es decir:\n\\(E(Z|do(A=a)) = E_m(Z|A =a),\\)\nque mostramos arriba con la línea ajustada. También quisiéramos calcular contrastes particulares, como qué pasaría si las ventas de agua las aumentamos en 10 mil unidades:\n\\[E(Z|do(A=30000)) - E(Z|do(A=20000)),\\]\n\nEjemplo\nAhora hagamos otro ejemplo donde hay una relación causal que queremos estimar. Imaginemos una ciudad en donde temperaturas altas producen desabasto de agua en algunos hogares, debido a un aumento del riego y uso de agua en general. Nos interesa estimar el efecto del desabasto en las compras de agua embotellada. Nuestro diagrama ahora es:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n   U_t -&gt; T\n   T -&gt; A\n   T -&gt; D\n   D -&gt; A\n   U_a -&gt; A\n   U_d -&gt; D\n\n{ rank = same; A; D }\n\n}\n\")\n\n\n\n\n\n\n\nsimular_t &lt;- function(n = 10, dia = 150){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima &lt;- rnorm(n, 28, 2)\n  u &lt;- rnorm(n, 0, 1)\n  desabasto_agua &lt;- 1/(1 + exp(-(t_maxima - 28) + u))\n  unidades &lt;- rnorm(n, 20000 + 2000 * (t_maxima -  28) + 8000*desabasto_agua, 2000)\n  tibble(t_maxima, unidades, desabasto_agua)\n}\nset.seed(128)\nsimular_dias &lt;- simular_t(150)\n\n\nggplot(simular_dias, aes(x = desabasto_agua, y = unidades)) + \n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nLa correlación parece muy fuerte, sin embargo, sabemos que hay un camino no causal de asociación entre estas dos variables.\nIgual que en ejemplo anterior, vamos a intervenir teóricamente en el desabasto de agua. Después de la cirugía, nuestro diagrama modificado es:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n   U_t -&gt; T\n   T -&gt; A\n   D -&gt; A\n   U_a -&gt; A\n{ rank = same; A; D }\n\n}\n\")\n\n\n\n\n\n\nAhora queremos calcular \\(p(a|do(d)) = p_m(a|d)\\) en función de los datos. Siguiendo el mismo argumento que en el ejemplo anterior, sabemos que tenemos que estratificar o condicionar a \\(T\\) para poder usar nuestro proceso generador de observaciones, y obtenemos:\n\\[p(a|do(d))=p_m(a|d) = \\int p(a|d,t)p(t)dt \\] Aunque a veces es posible calcular analíticamente el lado derecho analíticamente, podemos simular como hicimos en los ejemplos anteriores:\n\nsimular_cirugia &lt;- function(n = 10, da = 0){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima &lt;- rnorm(n, 28, 2)\n  ### cirugía ####\n  #u &lt;- rnorm(n, 0, 1) \n  desabasto_agua &lt;- da\n  ######\n  unidades &lt;- rnorm(n, 20000 + 2000 * (t_maxima -  28) + 8000*desabasto_agua, 2000)\n  tibble(t_maxima, unidades, desabasto_agua)\n}\nset.seed(128)\nsimular_dias_c &lt;- map_df(seq(0, 1, 0.1), \\(da) simular_cirugia(1000, da = da))\n\n\nggplot(simular_dias_c, aes(x = desabasto_agua, y = unidades)) + \n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nPodemos también resumir promediando:\n\nefecto_verdadero_desabasto &lt;- simular_dias_c |&gt; \n  group_by(desabasto_agua) |&gt; \n  summarise(media_unidades = mean(unidades)) |&gt; \n  rename(desabasto = desabasto_agua)\nggplot(efecto_verdadero_desabasto,\n       aes(x = desabasto, y = media_unidades)) + \n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nY este es el efecto causal del desabasto de agua. No tenemos medidas de incertidumbre pues conocemos todos los parámetros de los modelos. La media condicional parece ser lineal, así que podríamos resumir con un modelo lineal:\n\n# Modelo 1 (con datos de intervención)\nlm(unidades ~ desabasto_agua, simular_dias_c)\n\n\nCall:\nlm(formula = unidades ~ desabasto_agua, data = simular_dias_c)\n\nCoefficients:\n   (Intercept)  desabasto_agua  \n         19831            8272  \n\n\nAproximadamente, cada incremento en puntos porcentuales de 10% en desabasto incrementa las ventas en unas 800 unidades. Compara con el análisis donde no estratificamos o controlamos por la temperatura:\n\n# Modelo 2\nlm(unidades ~ desabasto_agua, simular_dias)\n\n\nCall:\nlm(formula = unidades ~ desabasto_agua, data = simular_dias)\n\nCoefficients:\n   (Intercept)  desabasto_agua  \n         14102           19491  \n\n\nOtra forma de estratificar es ajustando un modelo que incluye la variable de temperatura. Podríamos hacer\n\n# Modelo 3\nlm(unidades ~ desabasto_agua + t_maxima, simular_dias)\n\n\nCall:\nlm(formula = unidades ~ desabasto_agua + t_maxima, data = simular_dias)\n\nCoefficients:\n   (Intercept)  desabasto_agua        t_maxima  \n        -35030            8648            1948",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#fórmula-de-ajuste",
    "href": "06-calculo-do.html#fórmula-de-ajuste",
    "title": "6  Identificación y cálculo-do",
    "section": "6.4 Fórmula de ajuste",
    "text": "6.4 Fórmula de ajuste\nEn resumen, tenemos la primera regla de Pearl de inferencia causal:\n\n\n\n\n\n\nFórmula de ajuste (Pearl)\n\n\n\nConsideramos una DAG donde los padres de \\(X\\) son \\(Z_1,Z_2\\). El efecto causal total de \\(X\\) en \\(Y\\) se puede calcular como\n\\[p(y|do(x)) = \\int p(y|x, z_1,z_2) p(z_1,z_2)\\, dz_1dz_2\\] Es decir, condicionamos al valor de \\(x\\) y todos los padres de \\(X\\) para calcular \\(p(y|x,z_1,z_2)\\), y después marginalizamos sobre los padres.\n\n\nEsta fórmula se extiende a más de dos padres \\(Z_1,Z_2,Z_3,\\ldots, Z_k\\).\n\n\n\n\n\n\nTip\n\n\n\nA este proceso se llama de diferentes maneras en distintos contextos:\n\nEstamos calculando el efecto causal estratificando por las variables \\(z\\).\nControlamos por las variables \\(z\\) para calcular el efecto causal.\n\n\n\nPodemos pensar en esta fórmula de dos maneras: en primer lugar, si estamos modelando toda nuestra gráfica causal, podemos simular de la conjunta de la gráfica mutilada:\n\nFijando el nivel del tratamiento \\(T\\)\nSimulando \\(p(z_1,z_2,\\ldots, z_k)\\) de nuestro modelo completo (y tomar sólo los valores de las \\(z\\)’s).\nUsar \\(t\\) y las \\(z\\) simuladas para simular \\(y\\).\nAl final, nótese que nos quedan simulaciones de \\(p_m(y|t)\\) (marginalizamos sobre las \\(z\\)).\n\nEl otro enfoque busca sólo construir modelos para la parte que nos interesa:\n\nConstruir un modelo separado para \\(p(z_1, z_2,\\ldots, z_k) = p(z)\\) (que puede ser difícil si tenemos muchas variables) a partir los datos. Podemos también simular tomando al azar esta variables de nuestros datos.\nConstruir un modelo \\(p(y|t, z)\\) para simular la \\(y\\) a partir de los datos.\nMarginalizar sobre las \\(z\\)’s para quedarnos con \\(p_m(y|t)\\)\n\nFinalmente, si tenemos un modelo \\(p(y| t, z)\\) podemos también investigar cómo se comporta \\(E[y|t_2,z] - E[y|t_1,z]\\) para distintos combinaciones de valores de \\(Z\\).\nNota 1: Con este principio podemos resolver algunos problemas, pero no todos. Veremos que en algunos casos existen padres que no son observados, por ejemplo, no es posible condicionar para usar la fórmula de ajuste y es necesario desarrollar otras estrategias.\nNota 2: En regresión lineal, cuando incluímos una variable en el modelo (que consideramos una variable control), estamos estratificando por ella: por ejemplo, en el modelo lineal \\(U\\sim N(m_u(d,t), \\sigma_u)\\), donde\n\\[m_u = \\beta_0 +\\beta_1 d + \\beta_2 t\\] Estamos calculando un estimador para cada valor de \\(T=t\\), que es:\n\\[m_u = (\\beta_0 + \\beta_2 t) + \\beta_1 d = \\gamma_0 + \\gamma_1 d\\] Esta es una de las maneras más simples de obtener el efecto de \\(d\\) estratificando por, o controlando por \\(t\\), siempre y cuando los modelos lineales sean apropiados.\nNótese que en este último caso, tenemos que el efecto de \\(d\\) no depende de las covariables, de forma que no es necesario hacer el promedio sobre la conjunta, es decir, suponemos que el efecto causal es el mismo independientemente de los valores de las variables de control. Sin embargo, este no siempre es el caso.\nNota 3 Sin nuestro modelo \\(p(y|t,z)\\) es lineal, y nos interesa calcular el efecto causal promedio de la variable \\(t\\), no es necesario promediar por la conjunta de \\(p(z)\\). Bajo estas condiciones, el efecto causal promedio está simplemente dado por el coeficiente de \\(t\\) en el modelo lineal. Sin embargo, si este no es el caso, entonces para estimar el efecto causal promedio es necesario promediar apropiadamente según la fórmula de ajuste.\n\nEjemplo: variación de efectos causales\nEn McElreath (2020), McElreath presenta un ejemplo interesante de por qué es necesario marginalizar sobre las variables de estratificación que no son el tratamiento. En su diagrama causal, la cantidad de guepardos afecta la población de babuinos y de gacelas, y también la población de babuinos afecta la población de gacelas. Cuando hay muchos guepardos, los babuinos no cazan, de forma que el efecto \\(Babuinos\\to Gazelas\\) es débil. Cuando hay pocos guepardos, sin embargo, el efecto \\(Babuinos\\to Gazelas\\) es fuerte pues los babuinos pueden aventurarse a cazar. Podemos obtener un efecto causal promedio marginalizando sobre la cantidad de guepardos.\nOtro ejemplo que podríamos considerar es el de intervenir por ejemplo un semáforo para agilizar la vialidad. El tráfico previo influye la decisión de intervenir un semáforo, y también influye en el tráfico actual. Cuando el tráfico previo es bajo, la intervención tiene poco efecto, pero cuando el tráfico previo es alto, al intervención tiene un efecto más fuerte.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#bloqueando-puertas-traseras",
    "href": "06-calculo-do.html#bloqueando-puertas-traseras",
    "title": "6  Identificación y cálculo-do",
    "section": "6.5 Bloqueando puertas traseras",
    "text": "6.5 Bloqueando puertas traseras\nEn las partes anteriores vimos que estratificando por los padres de la variable de tratamiento \\(X\\) podemos construir un estimador del efecto de \\(X\\) sobre otra variable \\(Y\\), pasando de una distribución observacional a una conceptualmente experimental (dado que los supuestos causales sean aproximadamente correctos).\nSin embargo, esta aplicación de la fórmula de ajuste no funciona si existen padres que no fueron observados, y por tanto no podemos estratificar por ellos. El siguiente método (ajuste por “puerta trasera”) nos da una generalización que podemos usar dado ciertos tipos de estructura en nuestro modelo causal (veremos también por ejemplo, que a veces podemos usar menos variables que padres de la variable de interés). Nótese que una vez más, este criterio sólo depende de la gráfica causal \\(G\\) asociada a nuestro modelo, y no los modelos locales que utilizemos para modelar la condicional de cada nodo.\n\n\n\n\n\n\nAjuste de puerta trasera (Pearl)\n\n\n\nSi tenemos dos variables \\(T\\) y \\(Y\\) en una gráfica \\(G\\), un conjunto \\(Z\\) de variables satisface el criterio de puerta trasera relativo a \\(T\\) y \\(Y\\) cuando \\(Z\\) bloquea cualquier camino entre \\(T\\) y \\(Y\\) que tenga una arista que incida en \\(T\\), y ninguna variable de \\(Z\\) es descendiente de \\(T\\).\nEn tal caso, podemos utilizar la fórmula de ajuste, pero en lugar de estratificar por los padres de \\(T\\), estratificamos por las variables en \\(Z\\)\n\n\nLa idea es:\n\nQueremos bloquear todos los caminos no causales entre \\(T\\) y \\(Y\\).\nQueremos no perturbar todos los caminos dirigidos de \\(T\\) a \\(Y\\) (caminos causales).\nNo queremos activar caminos no causales entre \\(T\\) y \\(Y\\) al condicionar.\n\nCumplimos 1 al estratificar por variables que bloquean los caminos que son causas de \\(T\\), pues estos caminos no son causales y distorsionan la relación entre \\(T\\) y \\(Y\\). Al mismo tiempo, no bloqueamos caminos causales porque ningúna variable de \\(Z\\) es descendiente de \\(T\\), de modo que se satisface el criterio 2 (todos los caminos causales comienzan con \\(T\\to\\)). Finalmente, al excluir descendientes de \\(T\\) también implica que no condicionamos a colisionadores del tipo \\(T\\to \\cdots \\to Z_1\\gets  Y\\), pues esto activa un camino no causal entre \\(T\\) y \\(Y\\) (se cumple 3).\n\nEjemplo (Pearl)\nConsideramos primero este ejemplo simple, donde queremos evaluar la efectividad de un tratamiento en cierta enfermedad. Los datos que tenemos disponibles son si una persona recibió o no un tratamiento, y si se recuperó o no. No se registró el nivel socioeconómico, pero sabemos que el tratamiento es caro, de forma que fue accedido más por gente de NSE más alto. También que sabemos que para este tipo de tratamiento, el peso de la persona es un factor importante. Nuestros supuestos están en la siguiente gráfica:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Trata\n    Res\n  node [shape = circle]\n    NSE\n    Peso\n    U\n  edge [minlen = 3]\n    NSE -&gt; Peso\n    NSE -&gt; Trata\n    Trata -&gt; Res\n    Peso -&gt; Res\n    U -&gt; NSE\n    U -&gt; Peso\n}\n\")\n\n\n\n\n\n\nObservamos que no podemos directamente usar la fórmula de ajuste pues NSE no es una variable observada.\nEn esta circunstancia no podríamos identificar el efecto causal, pues existen un caminos abiertos no causales. Quizá el tratamiento no es muy efectivo, y parece ser bueno pues fue aplicado a personas con menor peso que las que no recibieron el tratamiento, a través del efecto de NSE. Sin embargo, supón que tuviéramos disponible la variable Peso:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Trata\n    Res\n    Peso\n  node [shape = circle]\n    NSE\n    U\n  edge [minlen = 3]\n    NSE -&gt; Peso\n    NSE -&gt; Trata\n    Trata -&gt; Res\n    Peso -&gt; Res\n    U -&gt; NSE\n    U -&gt; Peso\n}\n\")\n\n\n\n\n\n\nEn este caso, todavía no podemos aplicar la fórmula original de ajuste pues no conocemos \\(NSE\\). Sin embargo, podemos bloquear los caminos no causales estratificando por Peso, y entonces podemos usar el criterio de puerta trasera para identificar el efecto del tratamiento, aún cuando no tengamos NSE.\n\n\nEjemplo\nPrimero consideramos un modelo generador:\n\ninv_logit &lt;- function(x) 1 / (1 + exp(-x))\nsimular_bd &lt;- function(n = 10){\n  nse &lt;- sample(c(0, 1), n, replace = TRUE)\n  peso &lt;- rnorm(n, 70 - 7 * nse, 12 + 2 * nse)\n  trata &lt;- rbinom(n, 1, 0.8 * nse + 0.2 * (1 - nse))\n  p_trata &lt;- inv_logit(1 * trata - 0.2 * (peso - 70))\n  res &lt;- rbinom(n, 1, p_trata)\n  tibble(nse, peso, trata, res)\n}\ndatos_bd &lt;- simular_bd(10000)\nhead(datos_bd)\n\n# A tibble: 6 × 4\n    nse  peso trata   res\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1     1  71.9     0     0\n2     0  45.0     0     1\n3     0  73.5     0     0\n4     0  66.1     0     1\n5     1  49.4     1     1\n6     0  69.0     1     1\n\n\nVeamos qué sucede si cruzamos tratamiento con resultado (es una muestra grande y el error de estimación no es importante):\n\ndatos_bd |&gt; \n  count(trata, res) |&gt;\n  group_by(trata) |&gt; \n  mutate(p = n / sum(n)) |&gt; \n  filter(res == 1) |&gt; \n  ungroup() |&gt; \n  mutate(dif = p - lag(p))\n\n# A tibble: 2 × 5\n  trata   res     n     p    dif\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0     1  2678 0.533 NA    \n2     1     1  3686 0.741  0.208\n\n\nSabemos que esta diferencia en respuesta puede estar confundida por un camino no causal. El verdadero efecto casual podemos calcularlo en nuestras simulaciones como sigue a partir de nuestro modelo (igualmente, usamos una muestra muy grande):\n\nsimular_efecto &lt;- function(n = 10, peso = NULL){\n  # cómo es la población\n  nse &lt;- sample(c(0, 1), n, replace = TRUE)\n  if(is.null(peso)){\n    peso &lt;- rnorm(n, 70 - 7 * nse, 12 + 2 * nse)\n  }\n  # asignar al azar\n  trata &lt;- rbinom(n, 1, 0.5)\n  p_trata &lt;- inv_logit(1 * trata - 0.2 * (peso - 70))\n  res &lt;- rbinom(n, 1, p_trata)\n  tibble(nse, peso, trata, res)\n}\nsims_efecto &lt;- simular_efecto(20000)\nresumen &lt;- sims_efecto |&gt; \n  count(trata, res) |&gt;\n  group_by(trata) |&gt; \n  mutate(p = n / sum(n)) |&gt; \n  filter(res == 1) |&gt; \n  ungroup() |&gt; \n  mutate(dif = p - lag(p))\ndif_real &lt;- resumen$dif[2]\nresumen\n\n# A tibble: 2 × 5\n  trata   res     n     p    dif\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0     1  5929 0.590 NA    \n2     1     1  6996 0.703  0.113\n\n\nLa estimación ingenua del cruce simple es mucho más grande que el verdadero efecto.\nPodemos también calcular el efecto para un peso particular:\n\nsims_efecto &lt;- simular_efecto(20000, peso = 70)\nres_70 &lt;- sims_efecto |&gt; \n  count(trata, res) |&gt;\n  group_by(trata) |&gt; \n  mutate(p = n / sum(n)) |&gt; \n  filter(res == 1) |&gt; \n  ungroup() |&gt; \n  mutate(dif = p - lag(p))\ndif_70 &lt;- res_70$dif[2]\nres_70\n\n# A tibble: 2 × 5\n  trata   res     n     p    dif\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0     1  5002 0.500 NA    \n2     1     1  7344 0.735  0.235\n\n\nSuponiendo nuestro diagrama, queremos estimar estratificando por peso. Podríamos usar un sólo modelo logístico, pero pueden ser más simples los cálculos si construimos nuestro modelo en stan. En este caso, podríamos calcular las diferencias para un peso particular, por ejemplo 70 kg (en lugar de modelar estaturas para producir una estimación de diferencia promedio).\nUsaremos una muestra de 2 mil personas:\n\nmod_trata &lt;- cmdstan_model(\"./src/trata-backdoor.stan\")\nprint(mod_trata)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] trata;\n  array[N] int res;\n  vector[N] peso;\n\n}\n\ntransformed data {\n  real media_peso;\n\n  // centrar\n  media_peso = mean(peso);\n}\n\nparameters {\n  real gamma_0;\n  real gamma_1;\n  real gamma_2;\n}\n\ntransformed parameters {\n  vector[N] p_logit_res;\n\n  p_logit_res = gamma_0 + gamma_1 * trata + gamma_2 * (peso - media_peso);\n\n}\n\nmodel {\n  // modelo de resultado\n  res ~ bernoulli_logit(p_logit_res);\n  gamma_0 ~ normal(0, 2);\n  gamma_1 ~ normal(0, 1);\n  gamma_2 ~ normal(0, 0.2);\n\n\n}\ngenerated quantities {\n  real dif_trata;\n  real p_trata;\n  real p_no_trata;\n\n  real peso_sim = 70;\n  {\n    array[2000] int res_trata;\n    array[2000] int res_no_trata;\n    for(k in 1:2000){\n      res_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 1 +\n              gamma_2 * (peso_sim - media_peso)));\n      res_no_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 0 +\n              gamma_2 * (peso_sim - media_peso)));\n    }\n    dif_trata = mean(res_trata) - mean(res_no_trata);\n  }\n}\n\n\n\nset.seed(915)\ndatos_bd &lt;- simular_bd(2000)\ndatos_lista &lt;- list(N = nrow(datos_bd),\n  trata = datos_bd$trata, res = datos_bd$res,\n  peso = datos_bd$peso)\najuste &lt;- mod_trata$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.9 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 2.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 2.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 2.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.0 seconds.\nTotal execution time: 8.2 seconds.\n\nsims &lt;- ajuste$draws( format = \"df\")\nresumen &lt;- ajuste$summary(c( \"dif_trata\"))\n\n\nresumen |&gt; select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean    q5   q95\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 dif_trata 0.214 0.162 0.268\n\nsims |&gt; select(dif_trata) |&gt; \n  ggplot(aes(x = dif_trata)) + geom_histogram() +\n  geom_vline(xintercept = dif_70, colour = \"red\")\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nY obtenemos una estimación correcta del efecto en 70 kg. Podríamos también calcular el efecto en distintos pesos (nuestro estimador es una curva), promediar estimando una distribución de pesos modelada, o tomar una distribución fija de pesos para modelar (cada una de estas estrategias tiene propósitos diferentes).\nSi queremos tener un efecto promedio, podemos modelar los pesos. Otra estrategia es promediar sobre los valores observados de la muestra. Nótese que esto ignora una parte de la incertidumbre proveniente de la muestra particular usada.\n\nmod_trata &lt;- cmdstan_model(\"./src/trata-backdoor-promedio.stan\")\nprint(mod_trata)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] trata;\n  array[N] int res;\n  vector[N] peso;\n\n}\n\ntransformed data {\n  real media_peso;\n\n  // centrar\n  media_peso = mean(peso);\n}\n\nparameters {\n  real gamma_0;\n  real gamma_1;\n  real gamma_2;\n}\n\ntransformed parameters {\n  vector[N] p_logit_res;\n\n  p_logit_res = gamma_0 + gamma_1 * trata + gamma_2 * (peso - media_peso);\n\n}\n\nmodel {\n  // modelo de resultado\n  res ~ bernoulli_logit(p_logit_res);\n  gamma_0 ~ normal(0, 2);\n  gamma_1 ~ normal(0, 1);\n  gamma_2 ~ normal(0, 0.2);\n\n\n}\ngenerated quantities {\n  real dif_trata;\n  real p_trata;\n  real p_no_trata;\n  vector[N] probs;\n\n  for(i in 1:N){\n    probs[i] = 1.0 / N;\n  }\n\n  {\n    array[2000] int res_trata;\n    array[2000] int res_no_trata;\n    for(k in 1:2000){\n      real peso_sim = peso[categorical_rng(probs)];\n      res_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 1 +\n              gamma_2 * (peso_sim - media_peso)));\n      res_no_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 0 +\n              gamma_2 * (peso_sim - media_peso)));\n    }\n    p_trata = mean(res_trata);\n    p_no_trata = mean(res_no_trata);\n  }\n  dif_trata = p_trata - p_no_trata;\n\n}\n\n\n\ndatos_lista &lt;- list(N = nrow(datos_bd),\n  trata = datos_bd$trata, res = datos_bd$res,\n  peso = datos_bd$peso)\najuste &lt;- mod_trata$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 11.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 10.9 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 10.9 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 10.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 10.9 seconds.\nTotal execution time: 43.9 seconds.\n\nsims &lt;- ajuste$draws(c(\"dif_trata\"), format = \"df\")\n\n\nresumen &lt;- ajuste$summary(c( \"dif_trata\"))\nresumen |&gt; select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean     q5   q95\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 dif_trata 0.111 0.0805 0.141\n\nsims |&gt; select(dif_trata) |&gt; \n  ggplot(aes(x = dif_trata)) + geom_histogram() +\n  geom_vline(xintercept = dif_real, colour = \"red\")\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nY recuperamos nuevamente el efecto verdadero que mostramos arriba.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#reglas-del-cálculo-do-opcional",
    "href": "06-calculo-do.html#reglas-del-cálculo-do-opcional",
    "title": "6  Identificación y cálculo-do",
    "section": "6.6 Reglas del cálculo-do (opcional)",
    "text": "6.6 Reglas del cálculo-do (opcional)\nExisten tres axiomas básicos del cálculo-do de las que se derivan los demás resultados, como veremos en el siguiente ejemplo del criterio de la puerta delantera.\nAntes de verlas, un resumen rápido de las reglas es el siguiente:\n\nLa regla 1 nos dice que las distribuciones asociadas a intervenciones satisfacen también la equivalencia de \\(d\\)-separación e independencia condicional: si \\(Y\\) y \\(Z\\) están \\(d\\)-separadas dado en la gráfica manipulada, entonces \\(p(y | do(x), z) = p(y|do(x))\\).\nLa regla 2 es el criterio de la puerta trasera: si condicionamos a variables \\(W\\) que bloquean toda puerta trasera de \\(X\\) a \\(Y\\), podemos cambiar \\(do(x)\\) por \\(x\\): \\(p(y | do(x), w) = p(y | x, w)\\).\nLa regla 3 expresa que si no hay caminos causales de \\(X\\) a \\(Y\\), entonces \\(p(y|do(x)) = p(y)\\).\n\n\n\n\n\n\n\nCompletitud (Shpitser, Pearl)\n\n\n\nSi un efecto causal es identificable (puede expresarse en términos de cantidades observacionales), entonces puede derivarse una estrategia de identificación a partir de las tres reglas del cálculo-do.\n\n\nNota: esto no excluye que bajo ciertas hipótesis adicionales a las de nuestra gráfica causal (por ejemplo cómo se comportan las distribuciones particulares qeu componen el modelo), sea posible identificar efectos causales con otros medios que van más allá del cálculo-do.\nCon más generalidad, abajo están estas reglas (donde condicionamos a más variables o hacemos más intervenciones, y afinamos las condiciones):\nDenotamos por \\(G_m\\) la gráfica mutilada por \\(do(x)\\), donde quitamos todas las aristas que entran en \\(X\\). Los tres axiomas son:\nRegla 1 Ignorar observaciones: Si \\(Y\\) y \\(Z\\) están \\(d\\)-separados por \\(X\\) y \\(W\\) en \\(G_m\\),\n\\[ p(y|do(x), z, w) = p(y|do(x), w)\\] O en otras palabras, si \\(p_m\\) es la conjunta para \\(G_m\\),\n\\[p_m(y|x,z,w) = p_m(y|x, w)\\] es cierto si \\(Y\\) y \\(Z\\) están \\(d\\)-separados por \\(X\\) y \\(W\\) en \\(G_m\\) (condicionalmente independientes). Así que esta regla es independencia condicional dado \\(d\\)-separación, pero para la gráfica intervenida.\nRegla 2 Usando observaciones como intervenciones:\nSi \\(Y\\) y \\(Z\\) están \\(d\\)-separados por \\(X\\) y \\(W\\) en \\(G_m\\) quitándole todas las aristas que salen de \\(Z\\), entonces\n\\[ p(y|do(x), do(z), w) = p(y|do(x), z, w)\\] Regla 3 Ignorar intervenciones:\nSi \\(Z\\) y \\(Y\\) están \\(d\\)-separadas por \\(X\\) y \\(W\\) en la gráfica \\(G_m\\) donde además quitamos cualquier arista a \\(Z\\) si \\(Z\\) no es antecesor de \\(W\\) en \\(G_m\\), entonces:\n\\[ p(y|do(x), do(z), w) = p(y|do(x), w)\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#el-criterio-de-puerta-delantera",
    "href": "06-calculo-do.html#el-criterio-de-puerta-delantera",
    "title": "6  Identificación y cálculo-do",
    "section": "6.7 El criterio de puerta delantera",
    "text": "6.7 El criterio de puerta delantera\nEn algunos casos, puede ser que no sea posible bloquear algún camino no causal con variables observadas. Un ejemplo clásico es el de la discusión acerca de la relación de fumar con cáncer de pulmón. Algunos estadísticos plantearon que los estudios de asociación entre fumar y cáncer de pulmón podrían tener efectos gravemente confundidos, por ejemplo, por aspectos genéticos que hacen a una persona propensa a fumar al mismo tiempo que aumenta su probabilidad de fumar:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    F\n    C\n  node [shape = circle]\n    U\n  edge [minlen = 3]\n    U -&gt; F\n    U -&gt; C\n    F -&gt; C\n{rank= same; C; F}\n}\n\")\n\n\n\n\n\n\nEn este caso, el efecto de fumar (\\(F\\)) sobre cáncer (\\(C\\)) no es identificable pues no podemos condicionar a la variable de Genotipo (\\(U\\)). Supongamos que tenemos una medida adicional, que es la cantidad de depósitos de alquitrán den los pulmones de los pacientes. Este es es afectado por \\(F\\), y a su vez, el alquitrán incrementa la probabilidad de cáncer:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    F\n    C\n    A\n  node [shape = circle]\n    U\n  edge [minlen = 3]\n    U -&gt; F\n    U -&gt; C\n    F -&gt; A\n    A -&gt; C\n{rank= same; C; F; A}\n}\n\")\n\n\n\n\n\n\nLa idea es primero estimar el efecto de \\(F\\) sobre \\(A\\), y después estimar el efecto de \\(A\\) sobre \\(C\\). La “composición” de estos dos efectos, dado el diagrama, debe darnos el estimador correcto. Primero consideramos el efecto de \\(F\\) sobre \\(A\\), y tenemos que (regla 2)\n\\[p(a|do(f)) = p(a|f),\\] La igualdad se debe a que una vez que condicionamos a \\(F\\) no hay puertas traseras entre \\(F\\) y \\(A\\) (pues no condicionamos a \\(C\\)). Esta dependencia causal la podemos entonces estimar de los datos.\nEl efecto de \\(A\\) sobre \\(C\\) también es identificable, pues el camino no causal se bloquea cuando condicionamos a \\(F\\), de forma que por la fórmula de ajuste:\n\\[p(c|do(a)) = \\int p(c|a, f') p(f')\\, df'\\]\nAhora encadenamos estas dos ecuaciones:\n\\[p(c|do(f)) = \\int p(c|do(a))p(a|f)\\,da\\]\nque equivale en simulación a: dado un valor de \\(F\\), simulamos \\(A\\) con nuestro modelo ajustado con datos naturales. Ahora intervenimos \\(A\\) con el valor \\(a\\) que obtuvimos y simulamos \\(C\\). Sin embargo, para hacer este último paso con datos naturales, necesitamos usar el criterio de puerta trasera como explicamos arriba: simulamos entonces \\(f´\\) de \\(p(f)\\), y después simulamos \\(C\\) en función de \\(a\\) y \\(f´\\) (con una distribución construida a partir de datos).\nRequerimos en este caso construir y estimar la condicional \\(p(c|a, f)\\) basado en los datos.\nEn fórmula, en general, se escribe como:\n\n\n\n\n\n\nCriterio de fuerta delantera (Pearl)\n\n\n\nDecimos que un conjunto de variables \\(A\\) satisface el criterio de puerta delantera en relación a las variables \\(F\\) y \\(C\\) cuando:\n\n\\(A\\) intercepta todos las cadenas dirigidos de \\(F\\) a \\(C\\)\nNo hay ningún camino activo de puerta trasera de \\(F\\) a \\(A\\)\nTodos los caminos de puerta trasera de \\(A\\) a \\(C\\) están bloqueados por \\(F\\).\n\nSi \\(A\\) satisface el criterio de puerta delantera en relación a \\(F\\) y \\(C\\), entonces el efecto causal de \\(F\\) en \\(C\\) es identificable y está dado por la fórmula:\n\\[p(c|do(f)) = \\int \\left [ \\int p(c|a,f´)p(f´)\\,df´ \\right ] p(a|f)\\,da\\]\n\n\nTodas estas cantidades puede estimarse de los datos.\n\nEjemplo: proceso generador\nAntes de aplicar este nuevo procedimiento, describamos el proceso generador que utilizaremos:\n\n# simular distribución natural\nsimular_fd &lt;- function(n = 10, efecto_a = 0.3){\n  ## causa común\n  u &lt;- rnorm(n, 0, 1);\n  # cantidad que fuma\n  f &lt;- exp(rnorm(n, 1 + 0.2 * u, 0.1))\n  # acumulación de alquitrán\n  a &lt;- rnorm(n,  4 * f, 2)\n  # probabilidad de cancer\n  p_c &lt;- inv_logit(-6 + efecto_a * a +  2 * u)\n  c &lt;- rbinom(n, 1, p_c)\n  tibble(f, a, c, u)\n}\n# simular datos intervenidos (suponiendo que conocemos todo)\nsim_int_f &lt;- function(n = 100, do_f = 0.3, efecto_a = 0.3){\n  a &lt;- rnorm(n,  4 * do_f, 2)\n  u &lt;- rnorm(n, 0, 1)\n  p_c &lt;-  inv_logit(-6 + efecto_a * a +  2 * u)\n  c &lt;- rbinom(n, 1, p_c)\n  tibble(do_f = do_f, media_c = mean(c))\n}\n\n\nset.seed(4481)\nsims_fd &lt;- simular_fd(5000)\nsims_fd_1 &lt;- simular_fd(10000)\nqplot(sims_fd$f, sims_fd$a)\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n\n\n\n\n¿Cómo se ve la relación de fumador con cáncer? En esta gráfica mostramos también el valor de la variable no observada \\(U\\). Nótese que parte de la correlación positiva que existe es debido a esta variable \\(U\\).\n\nggplot(sims_fd, aes(x = f, y = c, colour = u)) + \n  geom_jitter() + scale_colour_continuous(type = \"viridis\")\n\n\n\n\n\n\n\n\nAhora veamos cómo se ve el efecto de \\(F\\) sobre \\(C\\) y también cómo se ve el cruce de \\(F\\) y \\(C\\) en los datos naturales:\n\nsims_1 &lt;- map_df(seq(1, 4, 0.5), ~ sim_int_f(100000, .x))\n\nsims_1 |&gt; \n  ggplot() + geom_line(aes(x = do_f, y = media_c)) +\n  geom_smooth(data = sims_fd_1, aes(x = f, y = c), method = \"loess\", span = 0.3, se = FALSE, colour =\"red\") + xlab(\"Grado de tabaquismo\") +\n  xlim(c(1,4))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 376 rows containing non-finite values (`stat_smooth()`).\n\n\n\n\n\n\n\n\n\nEn efecto causal promedio de fumar, en cada nivel, sobre la incidencia de cáncer de pulmón, suponiendo nuestro proceso generador. Nótese que la relación no es tan fuerte como observamos en los datos naturales (en rojo). Esto se debe a que en los datos naturales, las personas existe una causa común entre no fumar y prevenir cáncer de pulmón.\n\n\nEjemplo: estimación con puerta delantera\nVeamos cómo sería la estimación si tuviéramos datos disponible, y si es que podemos recuperar el efecto correcto dados los datos observados y la técnica de puerta delantera.\nNótese que sólo necesitamos \\(p(c|a, f), p(a|f)\\) y \\(p(f)\\). Estos son modelos estadísticos con el que podemos identificar el efecto que nos interesa. Una vez que los estimemos, podemos usar simulación:\n\nFijamos una \\(f\\).\nSimulamos una \\(a\\) del modelo \\(p(a|f)\\)\nPara calcular \\(\\int p(c|a,f')p(f')\\), tenemos que simular un valor \\(f'\\) de la marginal de \\(p(f)\\), y luego, sustituir junto la \\(a\\) de 1 para simular una \\(c\\) de \\(p(c|a, f')\\).\nConsideramos solamente \\(c\\) y \\(f\\) para resumir el efecto.\n\n\nset.seed(481)\nsims_fd &lt;- simular_fd(2000)\nmod_front_door &lt;- cmdstan_model(\"./src/front-door.stan\")\nprint(mod_front_door)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; n_f;\n  vector[N] f;\n  vector[N]  a;\n  array[N]  int&lt;lower=0, upper=1&gt; c;\n  array[n_f] real do_f;\n\n}\n\ntransformed data {\n  real media_a;\n  real media_f;\n\n  media_a = mean(a);\n  media_f = mean(f);\n}\n\nparameters {\n  real&lt;lower=0&gt; alpha;\n  real alpha_a;\n  real&lt;lower=0&gt; alpha_f;\n  real int_a;\n  real beta_0;\n  real&lt;lower=0&gt; beta_1;\n  real&lt;lower=0&gt; beta;\n  real&lt;lower=0&gt; a_f;\n  real&lt;lower=0&gt; b_f;\n  real&lt;lower=0&gt; sigma_a;\n  real&lt;lower=0&gt; sigma_f;\n\n}\n\n\n\ntransformed parameters {\n\n\n}\n\nmodel {\n  f ~ gamma(a_f, b_f);\n  a ~ normal(beta * f, sigma_a);\n  c ~ bernoulli_logit(int_a + alpha_a * a + alpha_f * f);\n  alpha_a ~ normal(0, 1);\n  alpha_f ~ normal(0, 1);\n  int_a ~ normal(0, 3);\n  sigma_a ~ normal(0, 1);\n  sigma_f ~ normal(0, 0.1);\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  beta_0 ~ normal(0, 3);\n  beta_1 ~ normal(0, 1);\n\n}\ngenerated quantities {\n  array[n_f] real mean_c;\n\n  for(i in 1:n_f){\n    array[2000] real res_sim;\n    for(j in 1:2000){\n      real a_sim = normal_rng(beta * (do_f[i]), sigma_a);\n      real f_sim = gamma_rng(a_f, b_f);\n      res_sim[j] = bernoulli_rng(inv_logit(int_a + alpha_a * a_sim + alpha_f * f_sim));\n    }\n    mean_c[i] = mean(res_sim);\n  }\n\n}\n\n\n\ndo_f &lt;- seq(1, 4, 0.1)\nn_f &lt;- length(do_f)\nsims &lt;- mod_front_door$sample(data = list(N = nrow(sims_fd),\n      f = sims_fd$f, a = sims_fd$a,\n      c = sims_fd$c, do_f = do_f, n_f = n_f),\n  init = 0.01, step_size = 0.01, \n  refresh = 1000,\n  parallel_chains = 4)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 43.1 seconds.\nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 43.3 seconds.\nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 44.1 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 44.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 43.8 seconds.\nTotal execution time: 44.8 seconds.\n\n\n\nsims_efecto_tbl &lt;- sims$draws(\"mean_c\", format = \"df\") |&gt; \n  pivot_longer(cols = contains(\"mean_c\"), values_to = \"media_c\") |&gt; \n  separate(name, c(\"nom\", \"id\"), \n    sep = \"[\\\\[\\\\]]\", convert = TRUE, extra = \"drop\") |&gt; \n  left_join(tibble(f = do_f) |&gt; \n  mutate(id = seq_along(f))) \nresumen_tbl &lt;- sims_efecto_tbl |&gt; \n  group_by(id, f) |&gt; \n  summarise(media = mean(media_c), \n    q5 = quantile(media_c, 0.05),\n    q95 = quantile(media_c, 0.95))\n\n\nggplot(resumen_tbl) + \n  geom_linerange(aes(x= f, ymax = q95, ymin = q5), colour = \"red\") + \n  geom_point(aes(x = f, y = media), colour = \"red\") +\n  geom_line(data = sims_1, aes(x = do_f, y = media_c)) +\n  xlab(\"Nivel de tabaquismo\") + ylab(\"Prop afectada\")\n\n\n\n\n\n\n\n\nY parece que hemos obtenido una estimación razonable del efecto causal de fumar sobre cáncer. Recordemos también que debemos ser cuidadosos al comparar intervalos que salen del mismo modelo por su nivel de traslape.\nPor ejemplo, si quisiéramos calcular contrastes con el nivel 2 de tabaquismo:\n\nefecto_2 &lt;- sims_efecto_tbl |&gt; filter(f == 2) |&gt; \n  select(.draw, efecto_2 = media_c)\ncomp_tbl &lt;- left_join(sims_efecto_tbl, efecto_2) |&gt; \n  mutate(dif_2 = media_c - efecto_2)\n\nJoining with `by = join_by(.draw)`\n\ncomp_tbl |&gt; group_by(f) |&gt; \n  summarise(media = mean(dif_2), q5 = quantile(dif_2, 0.05),\n            q95 = quantile(dif_2, 0.95)) |&gt; \nggplot() + geom_linerange(aes(x= f, ymax = q95, ymin = q5)) + geom_point(aes(x = f, y = media))  +\n  xlab(\"Nivel de tabaquismo\") + ylab(\"Prop afectada\")\n\n\n\n\n\n\n\n\nNota: nótese como en este ejemplo hemos evitado incluir en nuestro modelo la variable no observada \\(U\\), gracias al procedimiento de puerta delantera descrito arriba.\nEs posible sin embargo intentar un modelo completo bayesiano, sin necesidad de recordar la fórmula. El procedimiento, que es más difícil de ajustar: considera una variable latente \\(U\\) no observada, y es necesario definir cómo puede ser su relación con sus descendientes. Es necesario más cuidado en definir formas funcionales e iniciales apropiadas para que los muestreadores funcionen apropiadamente.\n\n\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html",
    "href": "07-buenos-malos-controles.html",
    "title": "7  Buenos y malos controles",
    "section": "",
    "text": "7.1 Controles buenos o neutros\nConsideramos el siguiente diagrama: en este caso, \\(Z\\) causa variación en \\(Y\\). Controlar por \\(Y\\) puede mejorar la precisión de nuestras estimaciones causales, sin abrir ningún camino no causal (Modelo 8 en Cinelli, Forney, y Pearl, A Crash Course in Good and Bad Controls) :\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    Z -&gt; Y\n    T -&gt; Y\n  }\n}\n', width = 250, height = 60)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html#controles-buenos-o-neutros",
    "href": "07-buenos-malos-controles.html#controles-buenos-o-neutros",
    "title": "7  Buenos y malos controles",
    "section": "",
    "text": "7.1.1 Ejemplo\nQueremos probar un tratamiento para reducir peso. Aleatorizaremos las personas al tratamiento (por ejemplo una medicina), y antes de comenzar el estudio registramos su peso inicial y estatura. Nuestro diagrama es el siguiente, donde incluímos también el peso inicial que influye en el peso final después del tratamiento, y otras variables no observadas que influyen tanto en peso final como peso inicial (por ejemplo, si las personas estuvieron haciendo alguna dietas o no). También medimos una cantidad, al final del experimento, que es bienestar general de la persona (o una calificación de su estado de salud general). Adicionalmente medimos una variable \\(C\\) (cansancio), pues sabemos que esta medicina puede tener ese efecto. El cansancio puede afectar el peso final pues los niveles de actividad pueden cambiar. \\(B\\) puede ser en este caso una medición de circunferencia de abdomen, por ejemplo.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node[shape=circle]\n      U\n      V\n  node [shape=plaintext]\n    Z\n    T\n  edge [minlen = 3]\n   #G -&gt; H\n   #H -&gt; PI\n   Z -&gt; T\n   T -&gt; PF\n   #G -&gt; PF\n   PI -&gt; PF\n   U -&gt; PI\n   U -&gt; PF\n   V -&gt; PF\n   T -&gt; C -&gt; PF\n   PF -&gt; B\n}\n\")\n\n\n\n\n\n\nNo hay ninguna variable confusora, y una estrategia de estimación es comparar \\(PF\\) entre los grupos.\n\nsim_peso &lt;- function(n){\n  Z &lt;- rnorm(n, 0, 0.5)\n  p &lt;- inv_logit( Z)\n  T &lt;- rbinom(n, 1, p)\n  C &lt;- rbinom(n, 1, 1/(1+exp(-(-2 + 4 * T))))\n  U &lt;- rnorm(n, 0, 5)\n  G &lt;- rbinom(n, 1, 0.5)\n  H &lt;- rnorm(n, 170 - 10 * G, 20)\n  PI &lt;- rnorm(n, -20 +  0.5 * H + U, 10)\n  PF &lt;- rnorm(n, PI + U - 20 * T + 3 * C , 5)\n  #V &lt;- PF - (PI + U - 10 * T + 2 * C)\n  B &lt;- rbinom(n, 1, 1/(1 + exp(-(PF-50)/2)))\n  tibble(G, H, T, PI, PF, B, C, Z)\n}\nset.seed(226)\npeso_tbl &lt;- sim_peso(1200)\npeso_tbl\n\n# A tibble: 1,200 × 8\n       G     H     T    PI    PF     B     C       Z\n   &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;\n 1     0  152.     0  53.8  46.8     0     0 -0.701 \n 2     0  211.     0  87.2  87.0     1     0 -0.328 \n 3     0  169.     1  71.8  48.1     0     1 -0.256 \n 4     0  174.     0  66.4  61.6     1     0  0.208 \n 5     1  164.     0  64.0  63.9     1     0 -0.470 \n 6     0  146.     0  46.9  48.9     0     0 -0.126 \n 7     1  201.     0  69.9  74.4     1     0 -0.892 \n 8     1  153.     0  40.2  28.7     0     1 -0.0218\n 9     0  168.     1  58.1  26.3     0     1  0.221 \n10     1  162.     0  56.0  63.4     1     0  0.126 \n# ℹ 1,190 more rows\n\n\nEn aplicaciones realidad, no sabemos cuál es el efecto causal, pero en ejemplos simulados sí podemos calcularlo. En este caso, hacemos la siguiente simulación para tener nuestra referencia:\n\npeso_sims_tbl &lt;- sim_peso(100000)\npeso_sims_tbl |&gt; group_by(T) |&gt; \n  summarise(peso_final_medio = mean(PF)) |&gt; \n  arrange(T) |&gt; \n  mutate(dif = peso_final_medio - lag(peso_final_medio))\n\n# A tibble: 2 × 3\n      T peso_final_medio   dif\n  &lt;int&gt;            &lt;dbl&gt; &lt;dbl&gt;\n1     0             62.8  NA  \n2     1             45.2 -17.6\n\n\nPodemos hacer simplemente\n\nlm(PF ~ T, peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     64.1     0.774      82.8 0       \n2 T              -18.7     1.11      -16.9 1.38e-57\n\n\ny el coeficiente de \\(T\\) sería una estimación del efecto causal promedio. Sin embargo, si condicionamos a \\(PI\\) tampoco creamos ninguna ruta no causal entre \\(T\\) y \\(PF\\). Podemos hacer también\n\nlm(PF ~ T + PI, peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    -7.30    0.855      -8.54 3.91e- 17\n2 T             -17.8     0.404     -44.1  5.19e-253\n3 PI              1.13    0.0127     88.5  0        \n\n\nY notamos que nuestra estimación es más precisa. Esto es porque \\(PI\\) absorbe una parte importante de la variación de PF. Al incluir este control no cambiamos la cantidad que estamos estimando, pero sí el estimador particular, que en este caso tiene menos incertidumbre.\n\n\n\n\n\n\nFalacia de la Tabla 2\n\n\n\nNótese que no necesariamente podemos interpetar el coeficiente de \\(PI\\) fácilmente, pues existen rutas no casuales activas entre \\(PF\\) y \\(PI\\). Como explicamos antes, un modelo que se usa para identificar un efecto causal particular no implica que puedan interpretarse como causales otros coeficientes.\n\n\nNota: este error se llama “Falacia de Tabla 2” porque muchas veces se presenta, después de una tabla de descriptivos de los grupos de tratamiento y de no-trameinto, una tabla con los resultados de un modelo de regresión que identifica el efecto causal de interés. Aunque la identificación puede ser correcta, esto no quiere decir que podamos interpretar el coeficiente de las variables de estratificación o control.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html#malos-controles-sobrecontrol",
    "href": "07-buenos-malos-controles.html#malos-controles-sobrecontrol",
    "title": "7  Buenos y malos controles",
    "section": "7.2 Malos controles: sobrecontrol",
    "text": "7.2 Malos controles: sobrecontrol\nEn los siguientes diagramas, condicionar por \\(Z\\) corta parte del efecto causal de \\(T\\) sobre \\(Y\\) (modelos 11 y 12 de Cinelli, Forney, y Pearl):\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    T -&gt; Z\n    Z -&gt; Y\n    T -&gt; Y\n  }\n  \n  subgraph caso_2 {\n    node [shape=plaintext]\n    Ya [label=\"Y\"]\n    Ta [label=\"T\"]\n    Za [label=\"Z\"][fontcolor=\"red\"]\n    edge [minlen = 3]\n    Ta -&gt; M\n    M -&gt; Ya\n    M -&gt; Za\n    Ta -&gt; Ya\n  }\n}\n', width = 250, height = 120)\n\n\n\n\n\n\n\nlm(PF ~ T +  C, peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   64.0       0.805    79.5   0       \n2 T            -19.1       1.69    -11.3   2.38e-28\n3 C              0.514     1.69      0.305 7.60e- 1\n\nlm(PF ~ T +  PI + C, peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    -7.77    0.856      -9.08 4.41e- 19\n2 T             -19.8     0.610     -32.4  7.57e-166\n3 PI              1.13    0.0126     89.2  0        \n4 C               2.59    0.610       4.25 2.32e-  5\n\n\nY vemos que nuestra estimación del efecto del tratamiento está sesgada, aparentando ser más efectiva de lo que es. La razón es que el camino que pasa por \\(C\\) “daña” en lugar de ayudar. El efecto causal total toma en cuenta tanto beneficios como daños.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html#malos-controles-variables-post-tratamiento",
    "href": "07-buenos-malos-controles.html#malos-controles-variables-post-tratamiento",
    "title": "7  Buenos y malos controles",
    "section": "7.3 Malos controles: variables post-tratamiento",
    "text": "7.3 Malos controles: variables post-tratamiento\nVariables que son efectos de la variable respuesta que nos interesa son en general malos controles. Es un caso particular de cómo se produce sesgo casos-control (por ejemplo, cuando seleccionamos individuos para observar dependiendo de una variable post-tratamiento). Para entender eso, agregamos explícitamente nodos que usualmente no mostramos en nuestros diagramas (están ahí implícitamente), que son efectos sobre \\(Y\\) que no tienen conexiones causales con otras partes del diagrama:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node[shape= circle]\n    U_y\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    Y -&gt; Z\n    T -&gt; Y  \n    U_y -&gt; Y\n  }\n}\n', width = 250, height = 120)\n\n\n\n\n\n\nHemos añadido un nodo implícito (otros factores que afectan \\(Y\\) y no tienen relación con otras variables del sistema) para explicar qué es lo que pasa cuando condicionamos a \\(Z\\): como \\(Z\\) es un descendiente del colisionador en \\(Y\\), se activa una ruta no causal entre \\(U_y\\) y \\(T\\), y estas dos cantidades aparecen como correlacionadas (es una correlación no causal). Esto en consecuencia modifica la correlación entre \\(T\\) y \\(Y\\).\n\nEjemplo\nEn nuestro ejemplo, podemos comparar las pendientes condicionando o no a la variable \\(B\\): vemos que dentro de cada grupo de \\(B\\), la pendiente es más chica que la que sugiere el efecto del tratamiento:\n\nggplot(peso_tbl, aes(x = T, y = PF, colour = factor(B))) +\n  geom_jitter() + \n   geom_smooth(method = \"lm\") +\n  geom_smooth(formula = \"y~ 1+x\", method = \"lm\", colour = \"red\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nComo vemos, la pendiente en cada grupo de \\(B\\) es más baja que la que obtendríamos si no condicionáramos a \\(B\\). Podemos explicarlo así, bajo el supuesto de que el tratamiento tiene algún efecto:\n\nEn el grupo \\(B=0\\): tiende a haber gente de peso más bajo. Para los que no recibieron el tratamiento, esto quiere decir que otros factores externos \\(U_y\\) fueron los explican por qué que cayeran en un nivel bajo (tienen \\(U_y\\) bajas. Por otro lado, el peso bajo de los que recibieron el tratamiento se debe también al tratamiento, por lo tanto, este grupo tiene \\(U_y\\) parecidas más parecidas a la población. Esto implica que estamos comparando grupos distintos de personas, y negamos ventajas de la aleatorización.\nEn el grupo \\(B=1\\): el argumento es similar. Aquí tiene a haber gente de peso más alto. Para los que recibieron tratamiento, esto implica que tienden a tener \\(U_y\\)’s más altas que la población. Para el grupo que no recibió el tratamiento, sus \\(U_y\\) son más parecidas a la población.\n\nEn ambos casos, obtenemos una estimación sesgada del efecto causal. En una regresión, \\(B\\) absorbe entonces parte de la variación que en realidad le corresponde al tratamiento:\n\nlm(PF ~ T +  B, peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    40.3      0.810     49.8  4.04e-294\n2 T              -7.68     0.798     -9.62 3.73e- 21\n3 B              31.0      0.811     38.2  1.09e-209\n\n\nEn la regresión el coeficiente de \\(T\\) está contaminado por esa asociación que creamos al condicionar a un descendiente de un colisionador: este coeficiente “explica” otra variación del peso final que no tiene qué ver con el tratamiento, en lugar de explicar solamente la variación por el tratamiento.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html#malos-controles-sesgo-de-colisionador",
    "href": "07-buenos-malos-controles.html#malos-controles-sesgo-de-colisionador",
    "title": "7  Buenos y malos controles",
    "section": "7.4 Malos controles: sesgo de colisionador",
    "text": "7.4 Malos controles: sesgo de colisionador\nLos modelo 16 y 17 ya los hemos examinado antes: cuando condicionamos a un colisionador activamos no causales que distorsionan la asociación.\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    T -&gt; Z\n    Y -&gt; Z\n    T -&gt; Y\n  }\n  \n  subgraph caso_2 {\n    node [shape=circle]\n    U\n    node [shape=plaintext]\n    Ya [label=\"Y\"]\n    Ta [label=\"T\"]\n    Za [label=\"Z\"][fontcolor=\"red\"]\n    edge [minlen = 3]\n    U -&gt; Za\n    U -&gt; Ya\n    Ta -&gt; Ya\n    Ta -&gt; Za\n  {rank=same; Za; Ta}\n  }\n}\n', width = 250, height = 140)\n\n\n\n\n\n\n\nEjemplo: la paradoja de peso de recién nacidos\nPara ilustrar la primera de estas gráficas referimos al caso de la paradajo del peso bajo de los recién nacidos (Hernández-Díaz, Schisterman, y Hernán (2006)), The Birth Weight “Paradox” Uncovered?\nEn 1991, se observó que bebés nacidos de madres fumadoras tenían tanto peso más bajo como más alta mortalidad. Sin embargo, si excluíamos el análisis a bebés nacidos con bajo peso, los bebés de fumadoras tenían menos mortalidad que los de no fumadoras. Aunque hubo algunas especulaciones si fumar “protegía” a niños de bajo peso, podemos explicar la aparición de esta correlación por la activación de una ruta no causal al condicionar a niños de bajo peso.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    T [label = 'T']\n    Y [label = 'Y']\n    Z [label = 'Z'][fontcolor = 'red']\n    node [shape=circle]\n    U\n    edge [minlen = 3]\n    T -&gt; Y\n    T -&gt; Z\n    Z -&gt; Y\n    U -&gt; Z\n    U -&gt; Y\n  }\n}\")\n\n\n\n\n\n\nEn la gráfica de arriba, \\(T\\) indica si la madre es fumadora o no, y \\(Y\\) la mortalidad. \\(Z\\) si el bebé nació con bajo peso o no.\n\\(U\\) son posibles defectos de nacimiento no observados, que causan peso bajo e incrementan el riesgo de muerte. Cuando observamos a mujeres fumadoras, tenemos una explicación para el peso bajo, lo cual hace más improbable que se trate de un defecto grave de nacimiento. En consecuencia, el riesgo de muerte es más bajo.\nEsta es una asociación no causal creada por condicionar a un colisionador.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html#controles-neutros-o-malos-parásito-de-precisión",
    "href": "07-buenos-malos-controles.html#controles-neutros-o-malos-parásito-de-precisión",
    "title": "7  Buenos y malos controles",
    "section": "7.5 Controles neutros o malos: parásito de precisión",
    "text": "7.5 Controles neutros o malos: parásito de precisión\nConsideramos el siguiente diagrama:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    Z -&gt; T\n    T -&gt; Y\n  }\n}', width = 100, height = 50)\n\n\n\n\n\n\nEn este caso, condicionar a \\(Z\\) no sesga nuestras estimaciones, pues no activamos ninguna ruta no causal. La dificultad es que típicamente disminuye la precisión de la estimación (usamos un modelo más grande donde no es necesario):\n\nlm(PF ~ T + Z, data = peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   64.1       0.784    81.8   0       \n2 T            -18.8       1.14    -16.5   2.21e-55\n3 Z              0.446     1.15      0.388 6.98e- 1\n\nlm(PF ~ T, data = peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     64.1     0.774      82.8 0       \n2 T              -18.7     1.11      -16.9 1.38e-57\n\n\nEstos parásitos en ciertas circunstancias pueden empeorar estimaciones causales y causar sesgo adicional. Consideremos el siguiente diagrama:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    X\n    Y\n    node [shape = circle]\n    U\n    edge [minlen = 3]\n    U -&gt; X\n    U -&gt; Y\n    Z -&gt; X\n    X -&gt; Y\n  }\n}', width = 100, height = 50)\n\n\n\n\n\n\nEn este caso, tenemos una variable confusora \\(U\\) que no nos permite estimar sin sesgo el efecto de \\(T\\) sobre \\(Y\\). Sin embargo, si condicionamos a \\(Z\\), la situación puede emperorar (amplificación de sesgo), pues dentro de cada nivel de \\(Z\\) hay menos variación de \\(X\\), y eso implica que la covarianza entre \\(X\\) y \\(Y\\), en cada nivel de \\(Z\\), se debe más a la variable confusora.\nPodemos hacer un ejemplo simulado (ver más en McElreath (2020)):\n\nn &lt;- 5000\nz &lt;- rbinom(n, 1, 0.5)\nu &lt;- rnorm(n)\nx &lt;- rnorm(n, 5 * z + u, 1)\ny &lt;- rnorm(n, x +  u, 1)\ndatos &lt;- tibble(x = x, z = z, u = u, y = y) \nlm(y ~ x, datos) |&gt; broom::tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   -0.278   0.0265      -10.5 1.47e-25\n2 x              1.12    0.00697     161.  0       \n\nlm(y ~ x + z, datos) |&gt; broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   0.0254    0.0250      1.02 3.09e-  1\n2 x             1.51      0.0124    121.   0        \n3 z            -2.56      0.0708    -36.2  1.78e-254\n\n\nEl efecto causal es de 1 unidad. Los modelos presentan estimaciones sesgadas, pero es peor el que incluye la variable parásito.\n\n\n\n\nCinelli, Carlos, Andrew Forney, y Judea Pearl. «A Crash Course in Good and Bad Controls». Sociological Methods & Research 0 (0): 00491241221099552. https://doi.org/10.1177/00491241221099552.\n\n\nHernández-Díaz, Sonia, Enrique F. Schisterman, y Miguel A. Hernán. 2006. «The Birth Weight “Paradox” Uncovered?» American Journal of Epidemiology 164 (11): 1115-20. https://doi.org/10.1093/aje/kwj275.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "08-mcmc.html",
    "href": "08-mcmc.html",
    "title": "8  Markov Chain Monte Carlo",
    "section": "",
    "text": "8.1 Algoritmos Metropolis-Hastings\nUno de los primeros algoritmos MCMC fue el de Metropolis-Hastings, que veremos primero en algunos ejemplos. Veremos también por qué ahora tenemos mejores opciones que MH para estimar posteriores de nuestros modelos.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "08-mcmc.html#algoritmos-metropolis-hastings",
    "href": "08-mcmc.html#algoritmos-metropolis-hastings",
    "title": "8  Markov Chain Monte Carlo",
    "section": "",
    "text": "Ejemplo: dos implementaciones de Metropolis\nSupongamos que queremos simular de una variable aleatoria \\(X\\) con distribución discreta sobre los valores \\(1,2\\ldots, k\\) con probabilidades \\(p(1),p(2),\\ldots,p(k)\\). Este problema puede resolverse fácilmente de varias maneras, pero utilizaremos un método de Monte Carlo tipo Metropolis. Supongamos que podemos simular de una variable aleatoria \\(U\\) que es uniforme en \\(1,2,\\ldots, k\\) (con probabilidades iguales a 1/k).\nLo que podemos hacer es lo que sigue, para \\(i=1,\\ldots, M\\):\n\nPara \\(i=1\\), comenzamos fijando un valor \\(x_1\\) en \\(1,2,\\ldots, k\\).\n\nPara cada \\(i\\),\n\nSimulamos una uniforme en \\(1,2,\\ldots, k\\). Al valor \\(u_i\\) obtenido le llamamos valor propuesto.\nCalculamos \\(q = p(u_i)/p(x_i)\\) (el cociente de la probabilidad del valor propuesto entre la probabilidad del valor actualo).\nSi \\(q &gt; 1\\), aceptamos el valor propuesto y ponemos \\(x_{i+1} = u_i\\).\nSi \\(q &lt; 1\\), aceptamos el valor propuesto con probabilidad \\(q\\) (\\(x_{i+1} = u_i\\)), y con probabilidad \\(1-q\\) rechazamos (\\(x_{i+1} = x_i\\)).\n\nEl resultado es una sucesión de valores \\(x_1,x_2,\\ldots, x_M\\). Es posible demostrar que la distribución de estas \\(x_i\\) converge a la distribución \\(p(1),\\ldots, p(k)\\) si \\(M\\) es suficientemente grande.\nEste método se llama Metropolis-Hastings. Es un método de Monte Carlo, y como podemos ver, se trata de una cadena de Markov, pues la distribución cada siguiente lugar \\(x_{i+1}\\), condicionada al valor actual \\(x_i\\) no depende de valores anteriores de las \\(x\\).\n\nset.seed(45123)\n# definimos estas p\nk &lt;- 40\np &lt;- exp(-(1:k - k/3)^2 / 10)\np &lt;- p /sum(p)\ndist_obj &lt;- tibble(x = 1:k, p = p)\n# simulamos\nM &lt;- 200000\nx &lt;- numeric(M)\nx[1] &lt;- 20\nfor(i in 1:M){\n  u &lt;- sample(1:k, 1)\n  q &lt;- p[u] / p[x[i]]\n  if(runif(1) &lt; q){\n    x[i+1] &lt;- u\n  } else {\n    x[i+1] &lt;- x[i]  \n  }\n}\n\nEn rojo mostramos las probabilidades objetivo que queremos estimar, y en negro las estimadas con nuestro método de arriba.\n\nresultados_sim &lt;- tibble(x = x) |&gt; \n  mutate(n_sim = row_number())\nresumen_sim &lt;- resultados_sim |&gt; count(x) |&gt; \n  right_join(tibble(x = 1:k, p = p)) |&gt; \n  mutate(n = ifelse(is.na(n), 0, n)) |&gt; \n  mutate(p_aprox = n / sum(n))\n\nJoining with `by = join_by(x)`\n\nggplot(dist_obj, aes(x = x)) +\n    geom_point(aes(y = p)) +\n  geom_point(data = resumen_sim, \n             aes(y = p_aprox), color = \"red\", size = 3, alpha = 0.5) \n\n\n\n\n\n\n\n\nComo vemos, los valores de \\(x_1,\\ldots, x_M\\) se distribuyen aproximadamente como la distribución \\(p\\) objetivo. Esta es una manera de simular valores de esta distribución discreta \\(p\\). Podemos ver cómo se ven las simulaciones sucesivas:\n\nggplot(resultados_sim |&gt; filter(n_sim &lt; 400), aes(x = n_sim, y = x)) +\n  geom_line() + scale_y_continuous(breaks = 1:20)\n\n\n\n\n\n\n\n\nEl defecto que tiene este algoritmo es que puede ser relativamente lento, pues vemos que hay periodos largos donde se “atora” en valores de probabilidad relativamente alta. La razón es que en muchos pasos, estamos proponiendo “saltos al vacío” a lugares de probabilidad muy baja, que rara vez se aceptan.\nPodemos hacer más eficiente nuestro algoritmo si le permitimos explorar con mayor facilidad los posibles valores de \\(x\\). Esto se logra proponiendo saltos locales: si estamos en \\(x_i\\), entonces proponemos los valores \\(x_i - 1\\) y \\(x_i + 1\\) con la misma probabilidad 1/2 (excepto en los extremos donde sólo proponemos \\(x_i,x_i+1\\) o \\(x_i-1,x_i\\)).\nProponemos entonces la suguiente modificación del paso 1 de propuesta:\n\nPara \\(i=1\\), comenzamos fijando un valor \\(x_1\\) en \\(1,2,\\ldots, k\\).\n\nPara cada \\(i\\),\n\nSi \\(1&lt; x_i&lt;k\\), escogemos al azar un salto a la derecha o al izquierda con igual probabilidad 1/2. En los extremos \\(x_i=1\\) o \\(x_i=k\\) escogemos entre \\(1,2\\) o \\(k-1,k\\) respectivamente. Al valor \\(u_i\\) obtenido le llamamos valor propuesto.\nCalculamos \\(q = p(u_i)/p(x_i)\\) .\nSi \\(q &gt; 1\\), aceptamos el valor propuesto y ponemos \\(x_{i+1} = u_i\\).\nSi \\(q &lt; 1\\), aceptamos el valor propuesto con probabilidad \\(q\\) (\\(x_{i+1} = u_i\\)), y con probabilidad \\(q\\) rechazamos(\\(x_{i+1} = x_i\\)).\n\nEsto lo escribimos como sigue:\n\n#set.seed(4511)\n# simulamos\nx &lt;- numeric(M)\nx[1] &lt;- 20\nfor(i in 1:M){\n  u &lt;- sample(c(x[i] - 1,  x[i] + 1), 1)\n  if(u == k+1) u &lt;- k\n  if(u == 0) u &lt;- 1\n  q &lt;- p[u] / p[x[i]]\n  if(runif(1) &lt; q){\n    x[i+1] &lt;- u\n  } else {\n    x[i+1] &lt;- x[i]  \n  }\n}\n\nObtenemos:\n\nresultados_sim_2 &lt;- tibble(x = x) |&gt; \n  mutate(n_sim = row_number())\nresumen_sim_2 &lt;- resultados_sim_2 |&gt; count(x) |&gt; \n  mutate(p_aprox = n / sum(n))\nggplot(dist_obj, aes(x = x)) +\n    geom_point(aes(y = p)) +\n  geom_point(data = resumen_sim_2, \n             aes(y = p_aprox), color = \"red\", size = 3, alpha = 0.5) \n\n\n\n\n\n\n\n\nY podemos ver cómo evoluciona nuestra cadena de Markov:\n\nggplot(resultados_sim_2 |&gt; filter(n_sim &lt; 400), aes(x = n_sim, y = x)) +\n  geom_line() + scale_y_continuous(breaks = 1:20)\n\n\n\n\n\n\n\n\n¿Cómo se comparan estos dos métodos? Podemos ver por ejemplo cómo se comparan las distribuciones aproximadas hasta cierto número de iteraciones con la verdadera distribución objetivo:\n\napprox_sim &lt;- map_df(seq(200, 30000, by = 200), function(n_sims){\n  resumen_1 &lt;- resultados_sim |&gt; filter(n_sim &lt;= n_sims) |&gt; \n    count(x) |&gt;\n    mutate(p_aprox = n / sum(n)) |&gt;\n    select(-n) |&gt;\n    right_join(dist_obj, by = \"x\") |&gt; \n    mutate(metodo = \"MH-1\") |&gt; \n    mutate(n_sims = n_sims) \n  resumen_2 &lt;- resultados_sim_2 |&gt; filter(n_sim &lt;= n_sims) |&gt;\n    count(x) |&gt;\n    mutate(p_aprox = n / sum(n)) |&gt;\n    select(-n) |&gt;\n    right_join(dist_obj, by = \"x\") |&gt; \n    mutate(metodo = \"MH-2\") |&gt; \n    mutate(n_sims = n_sims) \n  bind_rows(resumen_1, resumen_2) |&gt; \n    mutate(p_aprox = ifelse(is.na(p_aprox), 0, p_aprox))\n})\n\n\napprox_sim |&gt; \n  mutate(dif_abs = abs (p_aprox-p)) |&gt;\n  group_by(metodo, n_sims) |&gt; \n  summarise(dif_abs = sum(dif_abs)) |&gt; \nggplot(aes(n_sims, dif_abs, color = metodo)) +\n  geom_line() \n\n`summarise()` has grouped output by 'metodo'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nEn este caso, considera qué es lo que sucede en cada uno de estos casos:\n\nEl algoritmo que da saltos grandes muchas veces rechaza porque cae en un área de probilidad muy baja.\nEl algoritmo que da saltos chicos puede tardar en explorar regiones de probabilidad relativamente alta con suficiente frecuencia (tarda un moverse de un lugar a otro), por su naturaleza de “caminata aleatoria”. Pero sus tasas de aceptación son más altas.\n\nEste es el primer trade-off que existe en este algoritmo: tomar pasos grandes y balancear las probabilidades quizá rechazando muy frecuentemente (no es eficiente), o tomar pasos chicos y vagar más tiempo para visitar regiones de alta probabilidad, aunque con menos tasa de rechazo. Dependiendo de la distribución que queremos aproximar podemos inclinarnos más por una o por otra opción. En dimensiones altas generalmente ninguna combinación es muy buena.\n\n\n\n\n\n\nIdea básica de MCMC\n\n\n\nEn MCMC, buscamos un cadena de Markov que, en el largo plazo, visite cada posible valor del parámetro proporcionalmente a la probabildad posterior del parámetro. En el caso multivariado es la misma idea: cada combinación de parámetros debe ser visitada por la cadena en proporción a su probabilidad posterior.\n\n\n\n\nBalance detallado\n¿Por qué funcionan estos algoritmos? Supongamos que en cada paso, se cumple que (balance detallado): \\[{q(x|y)}p(y) = {q(y|x)}{p(x)}\\] donde \\(q(x|y)\\) son las probabilidades de transición de nuestra cadena de Markov propuesta. Esta ecuación dice que la proporción de transiciones de \\(y\\) a \\(x\\) en relación a las transiciones de \\(x\\) a \\(y\\) es la misma que la proporción de probabildad que hay entre \\(y\\) y \\(x\\) en la distribución objetivo.\nEsta ecuación implica que si la probabilidad se distribuye como \\(p(x)\\), entonces al transicionar con \\(q\\) la probabilidad fluje de manera que se mantiene estática en \\(p\\), es decir \\(p\\) es una distribución estacionaria para la cadena de Markov producida por las transiciones.\nEsto es fácil de demostrar pues \\[\\sum_{y} q(x|y)p(y) = \\sum_{y} q(y|x)p(x) = p(x) \\sum_{y} q(y|x) = p(x).\\]\nBajo otros supuestos adicionales de ergodicidad (aperiodicidad y tiempos de recurrencia finitos, es decir, las transiciones mezclan bien los estados), entonces podemos simular la cadena de Markov por un tiempo suficientemente largo y con esto obtener una muestra de la distribución objetivo \\(p\\), es decir, la distribución estacionaria \\(p(x)\\) también es la distribución de largo plazo para cualquier cadena que simulemos.\n¿Cómo podemos diseñar entonces las \\(q(x|y)\\) correspondientes?\nComenzamos considerando distribuciones propuesta \\(q_0(x|y)\\) que no necesariamente satisfacen la ecuación de balance, y supondremos como en los ejemplos de arriba (verifícalo) que nuestras transiciones tienen probabilidades simétricas \\(q_0(y|x) = q_0(x|y)\\). Entonces, cuando \\(p(y)/p(x) &gt; 1\\), queremos transicionar de \\(x\\) a \\(y\\) con más frecuencia que de \\(y\\) a \\(x\\). Comenzando en \\(x\\), si la propuesta de \\(q_0(y|x)\\) es \\(y\\), podríamos poner entonces que el sistema transicione con probabilidad 1 a \\(y\\). Sin embargo, si empezamos en \\(y\\) y la propuesta es \\(x\\), ponemos que el sistema sólo transiciona de \\(y\\) a \\(x\\) con probabilidad \\(p(x)/p(y)\\).\nDe esta manera, obtenemos que bajo \\(q(y|x)\\), \\(x\\) transiciona a \\(y\\) con probabilidad \\(\\min\\{1, p(y)/p(x)\\}\\). Entonces, el cociente \\(\\frac{q(y|x)}{q(x|y)}\\) es igual a \\(\\frac{p(y)}{p(x)}\\) si \\(p(y)&lt;p(x)\\), y es igual a \\(1/\\frac{p(x)}{p(y)} = \\frac{p(y)}{p(x)}\\) si \\(p(y)&gt;p(x)\\). Esto demuestra que se cumple el balance detallado.\n\n\nEjemplo: Metropolis bivariado\nSupongamos ahora que quisiéramos simular de una normal multivariada con media en c(2,3) y matriz de covarianza \\(\\Sigma\\), que supondremos es tal que la desviación estándar de cada variable es 1 y la correlación es 0.8. La matriz \\(\\Sigma\\) tiene 1 en la diagonal y 0.8 fuera de la diagonal.\nLa distribución objetivo \\(p\\) está dada entonces (módulo una constante de proporcionalidad):\n\nconstruir_log_p &lt;- function(m, Sigma){\n  Sigma_inv &lt;- solve(Sigma)\n  function(z){\n    - 0.5 * (t(z-m) %*% Sigma_inv %*% (z-m))\n  }\n}\nSigma &lt;- matrix(c(1, 0.8, 0.8, 1), nrow = 2)\nm &lt;- c(2, 3)\nlog_p &lt;- construir_log_p(m, Sigma)\n\nNótese que como Metropolis hace cocientes de probabilidades, sólo es necesario conocer la densidad objetivo módulo una constante de proporcionalidad.\nUna algoritmo de Metropolis podría ser el siguiente:\n\n# simulamos\nM &lt;- 50000\nmetropolis_mc &lt;- function(M, z_inicial = c(0,0), log_p, delta_x, delta_y){\n  z &lt;- matrix(nrow = M, ncol = 2)\n  z[1, ] &lt;-z_inicial\n  colnames(z) &lt;- c(\"x\", \"y\")\n  rechazo &lt;- 0\n  for(i in 1:(M-1)){\n    x_prop &lt;- rnorm(1, z[i, 1], delta_x)\n    y_prop &lt;- rnorm(1, z[i, 2], delta_y)\n    z_prop &lt;- c(x_prop, y_prop)\n    q &lt;- exp(log_p(z_prop) - log_p(z[i, ]))\n    if(runif(1) &lt; q){\n      z[i + 1, ] &lt;- z_prop\n    } else {\n      rechazo &lt;- rechazo + 1\n      z[i + 1, ] &lt;- z[i, ]\n    } \n  }\n  print(rechazo / M)\n  z_tbl &lt;- as_tibble(z) |&gt; \n    mutate(n_sim = row_number())\n  z_tbl\n}\nz_tbl &lt;- metropolis_mc(M, c(2.5, 3.5), log_p, 1.0, 1.0)\n\n[1] 0.59752\n\n\nVemos que tenemos una tasa alta de rechazos. ¿Por qué? Veamos cómo se ven las simulaciones hasta 500 iteraciones:\n\n\nCódigo\n# estas las usamos para graficar\nsims_normal &lt;- mvtnorm::rmvnorm(100000, mean = m, sigma = Sigma)\ncolnames(sims_normal) &lt;- c(\"x\", \"y\")\nsims_normal &lt;- as_tibble(sims_normal)\nelipses_normal &lt;-list(stat_ellipse(data = sims_normal, aes(x, y), \n               level = c(0.9), type = \"norm\", colour = \"salmon\"),\n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c(0.5), type = \"norm\", colour = \"salmon\"), \n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c(0.2), type = \"norm\", colour = \"salmon\"))\n\n\n\ngraf_tbl &lt;- map_df(seq(10, 500, 20), function(i){\n  z_tbl |&gt; filter(n_sim &lt;= i) |&gt; mutate(num_sims = i)\n})\nggplot(graf_tbl, aes(x, y)) + \n  elipses_normal +\n  geom_point(alpha = 0.1) +\n  facet_wrap(~num_sims) + theme_minimal()\n\n\n\n\n\n\n\n\n\nlibrary(gganimate)\nanim_mh_1 &lt;- z_tbl |&gt; filter(n_sim &lt; 50) |&gt; \n  ggplot() + \n  geom_point(aes(x, y, group = n_sim), size = 3) +\n  transition_reveal(n_sim) +\n  elipses_normal +\n  labs(title = 'Iteración: {frame_along}') +\n  theme_minimal()\nanim_save(animation = anim_mh_1, filename = \"figuras/mh-1-normal.gif\", \n          renderer = gifski_renderer())\n\n\n\n\nMetropolis Hastings\n\n\nObservaciones:\n\nLos puntos que tienen intensidad alta son puntos donde hubo varios rechazos. Esto es porque las propuestas a veces caen en elipses de baja probabilidad (en la gráfica mostramos una elipse de 50% probabilidad y otra de 95%).\nEsto se debe a que los saltos en cada dirección son de desviación estándar 1, y esto fácilmente nos lleva a una zona de alta probabilidad a una de baja probabilidad.\nSin embargo, a largo plazo, vemos cómo la cadena está visitando las regiones de alta probabilidad con aparentemente la frecuencia correcta.\n\nPodemos entonces proponer saltos más chicos, por ejemplo:\n\nz_tbl &lt;- metropolis_mc(M, c(2.5, 3.5), log_p, 0.2, 0.2)\n\n[1] 0.15584\n\ngraf_tbl &lt;- map_df(seq(10, 500, 20), function(i){\n  z_tbl |&gt; filter(n_sim &lt;= i) |&gt; mutate(num_sims = i)\n})\nggplot(graf_tbl, aes(x, y)) + \n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c( 0.9), type = \"norm\", colour = \"salmon\") +\n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c( 0.5), type = \"norm\", colour = \"salmon\") +\n  geom_point(alpha = 0.1) +\n  facet_wrap(~num_sims) + theme_minimal()\n\n\n\n\n\n\n\n\n\nanim_mh_2 &lt;- z_tbl |&gt; filter(n_sim &lt; 150) |&gt; \n  ggplot() + \n  geom_point(aes(x, y, group = n_sim), size = 3) +\n  transition_reveal(n_sim) +\n  elipses_normal +\n  labs(title = 'Iteración: {frame_along}') +\n  theme_minimal()\nanim_save(animation = anim_mh_2, filename = \"figuras/mh-2-normal.gif\", \n          renderer = gifski_renderer())\n\n\n\n\nMetropolis Hastings salto chico\n\n\nObservaciones:\n\nEn este caso tenemos una tasa de aceptación más alta.\nSin embargo, la cadena parece “vagar” en la regiones de probabilidad alta, y tiene dificultades para explorar correctamente estas regiones: se comporta localmente como una caminata aleatoria.\nSin embargo, a largo plazo, vemos cómo la cadena está visitando las regiones de alta probabilidad con aparentemente la frecuencia correcta.\n\n\n\n\n\n\n\nMetropolis-Hastings\n\n\n\nEn el algoritmo de Metropolis Hastings hay una tensión natural entre el tamaño de salto y la tasa de aceptación. Si el tamaño de los saltos es muy grande, la tasa de aceptación puede ser baja y esto producen ineficiencias. Si el tamaño de los saltos es muy chico, la tasa de aceptación es más alta, pero esto también es ineficiente pues la cadena puede explorar muy lentamente el espacio de parámetros.\n\n\nExisten métodos que pueden superar este problema, como son muestreo de Gibbs y Monte Carlo Hamiltoniano. El primero no lo discutiremos, pues requiere poder simular fácilmente de cada parámetro dados los otros, y esto no siempre es posible. Veremos más el segundo, donde usaremos información del gradiente de la distribución objetivo para proponer exploración más eficiente.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "08-mcmc.html#monte-carlo-hamiltoniano",
    "href": "08-mcmc.html#monte-carlo-hamiltoniano",
    "title": "8  Markov Chain Monte Carlo",
    "section": "8.2 Monte Carlo Hamiltoniano",
    "text": "8.2 Monte Carlo Hamiltoniano\nUna manera de mejorar la exploración de Metropolis es utilizar una distribución de propuestas más apropiada. La intuición en el caso anterior es:\n\nHay direcciones de más curvatura de la posterior que otras: movimientos relativamente chicos en las direcciones de alta curvatura nos lleva a regiones de probabilidad demasiado baja, y entonces tendemos a rechazar. Pero hacer movimientos aún más chicos para evitar rechazos nos lleva a explorar muy lentamente el espacio de parámetros.\nPodríamos evitar esto si nuestros saltos siguieran la curvatura natural de la distribución, como una pelota que rueda por la superficie de la distribución objetivo (con signo negativo, de forma que regiones de probabilidad alta sean valles o regiones bajas).\n\nLa idea de HMC es considerar el problema de muestrear de una distribución como un problema físico, donde introducimos aleatoridad solamente en cuanto a la “energía” de la pelota que va a explorar la posterior. Inicialmente impartimos un momento tomado al azar a la pelota, seguimos su trayectoria por un tiempo y el lugar a donde llega es nuestra nueva simulación. Esto permite que podamos dar saltos más grandes, sin “despeñarnos” en regiones de probabilidad muy baja y así evitar rechazos.\nAdicionalmente, veremos que si definimos el sistema físico apropiadamente, es posible obtener ecuaciones de balance detallado, lo cual en teoría nos garantiza una manera de transicionar que resultará a largo plazo en una muestra de la distribución objetivo.\n\nFormulación Hamiltoniana 1: introducción\nPrimero veremos cuál es la formulación Hamiltoniana (muy simple) de un sistema físico que nos sirve para encontrar la trayectoria de partículas del sistema. Consideremos una sola partícula cuya posición está dada por \\(q\\), que suponemos en una sola dimensión. La partícula rueda en una superficie cuya altura describimos como \\(V(q)\\), y tiene en cada instante tiene momento \\(p = m\\dot{q}\\).\nEl Hamiltoniano es la energía total de este sistema, en el espacio fase que describe el estado de cada partícula dadas su posición y momento \\((p,q)\\), y es la suma de energía cinética más energía potencial:\n\\(H(p,q) = T(p) + V(q)\\)\ndonde \\(V(q) = q^2/2\\) está dada y \\(T(p) = \\frac{p^2}{2m}\\), de modo que\n\\[H(p, q) = \\frac{p^2}{2m} + V(q) = \\frac{p^2}{2m} + \\frac{q^2}{2}\\]\nAhora consideremos las curvas de nivel de \\(H\\), que en este caso se conservan a lo largo del movimiento de la partícula. Como sabemos por cálculo, estas curvas son perpendiculares al gradiente del Hamiltoniano, que es \\((\\partial{H}/\\partial{p}, \\partial{H}/\\partial{q})\\). El movimiento de las partículas, sin embargo, es a lo largo de las curvas de nivel, de manera que el flujo instantáneo debe estar dado por el gradiente de \\(H\\) rotado 90 grados, es decir, por \\((\\partial{H}/\\partial{q}, -\\partial{H}/\\partial{p})\\).\nEntonces tenemos que el movimiento de la partícula debe cumplir las ecuaciones de Hamilton:\n\\[\\frac{dp}{dt} = \\frac{\\partial{H}}{\\partial{q}}, \\frac{dq}{dt} = -\\frac{\\partial{H}}{\\partial{p}}\\] Simplificando y usando la definición de \\(H\\), obtenemos que \\[\\frac{dq}{dt} = \\frac{p}{m}, \\frac{dp}{dt} = -\\frac{\\partial{V}}{\\partial{q}} = -q\\] Ilustramos este campo vectorial en la siguiente gráfica, donde escogemos \\(V(q) = q^2/2\\), \\(m=1\\), y dibujamos algunas curvas de nivel del Hamiltoniano:\n\n\nCódigo\nespacio_fase_1 &lt;- tibble(p = seq(-3, 3, length.out = 1000), q = seq(-3, 3, length.out = 1000)) |&gt; \n  expand(p, q) |&gt; \n  mutate(dq = p, dp = -q) |&gt; \n  mutate(H = p^2/2 + q^2/2)\nespacio_fase &lt;- tibble(p = seq(-3, 3, length.out = 10), q = seq(-3, 3, length.out = 10)) |&gt; \n  expand(p, q) |&gt; \n  mutate(dq = p, dp = -q)\nespacio_fase |&gt; \n  ggplot(aes(p, q)) +\n  geom_contour(data = espacio_fase_1, aes(x = p, y = q, z = H)) +\n  geom_segment(aes(xend = p + dp/5, yend = q + dq/5), \n               arrow = arrow(length = unit(0.1, \"inches\"))) +\n  theme_minimal() +\n  labs(subtitle = \"Movimiento en espacio fase: 1 dimensión\")\n\n\n\n\n\n\n\n\n\nOjo: este no es le movimiento de una partícula en dimensión 2: es el movimiento de la partícula en el espacio fase \\((p,q)\\), y la variable de posición \\(q\\) es de dimensión 1. Los ciclos de la gráfica muestran como conforme la partícula se mueve, energía potencial y cinética se intercambian a lo largo de su trayectoria en un “hilo”.\n\n\nFormulación Hamiltoniana 2: densidades de probabilidad\nConsideremos una partícula en el espacio de parámetros \\(\\theta\\). En esta formulación, si \\(\\theta\\) son los parámetros de interés, consideramos la energía potencial del sistema como \\(V(p) = -\\log p(\\theta)\\), donde \\(p(\\theta)\\) es la distribución objetivo.\nBuscamos simular del sistema con ecuaciones de movimiento para \\(\\theta\\). Como hicimos antes, vamos a levantar al espacio fase incluyendo el momento, que denotaremos como \\(\\rho\\). La energía cinética, en el caso más simple, podemos definirla (en la práctica existen reescalamientos) como como \\(T(\\rho) =\\frac{1}{2}\\sum_i \\rho_i^2\\) (la energía cinética es proporcional al momento cuadrado, pues el momento es masa por velocidad).\nEl Hamiltoniano por definición \\(H(\\rho, \\theta) = T(\\rho) + V(\\theta)\\), y las ecuaciones de Hamilton son las mismas que arriba, que en este caso nos dan\n\\[\\frac{d\\theta}{dt} = \\rho, \\frac{d\\rho}{dt} = \\nabla(\\log(p(\\theta)).\\]\nSi resolvemos estas ecuaciones, podemos entonces simular del sistema como sigue:\n\nDado un punto inicial \\(\\theta\\), escogemos un momento inicial \\(\\rho\\) al azar, por ejemplo cada componente normal \\(N(0,1)\\) (en la práctica existe un reescalamiento, pero en general queremos que \\(p(\\rho) = p(-\\rho)\\)). Es decir, agregamos inicialmente una cantidad de energía a la partícula.\nUsando las ecuaciones de Hamilton, actualizamos la posición \\(\\theta\\) y el momento de la partícula un cierto tiempo \\(t\\) fijo, de manera que no quedemos muy cerca del valor inicial, pero tampoco hagamos demasiado trabajo computacional.\nLa posición nueva \\(\\theta^*\\) es aceptada como nuestra nueva simulación (si el paso 2 es exacto, pero frecuentemente no lo es).\nRepetimos los pasos 1-3 un número suficiente de veces para obtener simulaciones de la posterior.\n\nEste método produce simulaciones de la distribución objetivo bajo condiciones de regularidad. Podemos demostrar por ejemplo, que se cumple el balance detallado.\n\n\nBalance detallado para HMC\nSupongamos que las transiciones que da este sistema son \\(q(y|x)\\). Nótese que dado el momento simulado, tenemos el estado \\((\\rho, x)\\), y la transición \\(x\\to\\y\\) es determinista, gobernada por las ecuaciones de Hamilton. Escribimos la transición como \\[(\\rho, x) \\to (\\rho^*, y).\\] Nótese que \\(\\rho\\) y \\(x\\) determinan la transición, de modo que\n\\[p(x)q(y|x) = p(x)p(\\rho) = \\exp(-H(\\rho, x)) = \\exp(-H(\\rho^*, y))\\] Que es cierto por conservación de la energía total y la transición sigue exactamente trayectorias del Hamiltoniano. Esta última cantidad, usando un argumento similar, es igual a\n\\[p(y)p(\\rho^*) = p(y)p(-\\rho^*) = p(y) q(x|y)\\] La segunda igualdad se da porque \\(p(\\rho)\\) es Gaussiana (simétrica). Y finalmente, la última igualdad se da porque si necesitamos momento \\(\\rho\\) para llegar de \\(x\\) a \\((\\rho^*, y)\\), entonces necesitamos \\(-\\rho^*\\) (volteamos la velocidad ifnal) para llegar de \\(y\\) a \\((\\rho, x)\\), pues el sistema físico es reversible.\nNótese que este argumento se rompe si por ejemplo si es imposible transicionar de un punto a otro (por ejemplo, cuando la distribución objetivo \\(p\\) tiene dos regiones separadas de probabilidad positiva).\n\n\nIntegración de las ecuaciones de Hamilton\nPara aproximar soluciones de estas ecuaciones diferenciales utilizamos el integrador leapfrog, en el que hacemos actualizaciones alternadas de posición y momento con un tamaño de paso \\(\\epsilon\\) chico. Hacemos este paso un número \\(L\\) de veces, para no quedar muy cerca del valor inicial.\nEn nuestro ejemplo, actualizaríamos por ejemplo el momento a la mitad del paso:\n\\[\\rho_{t+\\epsilon/2} = \\rho_t - \\frac{\\epsilon}{2}\\nabla(\\log(p(\\theta_t)))\\] Seguido de una actualización de la posición:\n\\[\\theta_{t+\\epsilon} = \\theta_t + \\epsilon \\rho_{t+\\epsilon/2}\\] y finalmente otra actualización del momento:\n\\[\\rho_{t+\\epsilon} = \\rho_{t+\\epsilon/2} - \\frac{\\epsilon}{2}\\nabla(\\log(p(\\theta_{t+\\epsilon})))\\] Al final de este proceso, encontraremos que por errores numéricos, quizá el Hamiltoniano varió un poco. Si esto sucede, podemos hacer un paso de aceptación y rechazo como en Metropolis Hastings, donde la probabilidad de aceptar es\n\\[\\min\\left(1, \\exp(H(\\rho,\\theta) - H(\\rho^{*},\\theta^{*}))\\right)\\] donde \\(\\rho^{*}\\) y \\(\\theta^{*}\\) son los valores de momento y posición nuevos y \\(H(\\rho,\\theta)\\) es el Hamiltoniano en el paso anterior.\nObservaciones:\n\nUn caso posible obtengamos desbordes o casi desbordes numéricos del momento o la posición (el Hamiltoniano en el punto inicial es órdenes de magnitud diferente que el inicial, ver el manual de Stan ). Esto indica problemas graves con el algoritmo de integración, y en general marcamos estas iteraciones como divergentes. Estas fallas pueden producir, como veremos, exploración insuficiente de la distribución objetivo.\nSi queremos usar HMC directamente, es delicado afinar el tamaño de paso, la distribución de propuesta para el momento, y el número de saltos \\(L\\). En Stan, que usa una variación de HMC, estos valores son ajustados en el periodo de calentamiento o warmup, antes de\n\n\n\nEjemplo: HMC en una distribución normal bivariada\nPrimero calculamos el gradiente que requerimos. En este caso, podemos hacerlo analíticamente:\n\nconstruir_log_p &lt;- function(m, Sigma){\n  Sigma_inv &lt;- solve(Sigma)\n  function(z){\n    - 0.5 * (t(z-m) %*% Sigma_inv %*% (z-m))\n  }\n}\nSigma &lt;- matrix(c(1, 0.8, 0.8, 1), nrow = 2)\nm &lt;- c(2, 3)\nlog_p &lt;- construir_log_p(m, Sigma)\n# en diferenciación automática, el siguiente constructor\n# puede tomar como argumento log_p, pero aquí la escribimos\n# explícitamente\nconstruir_grad_log_p &lt;- function(m, Sigma){\n  Sigma_inv &lt;- solve(Sigma)\n  function(theta){\n    - Sigma_inv %*% (theta-m)\n  }\n}\ngrad_log_p &lt;- construir_grad_log_p(m, Sigma)\nconstruir_H &lt;- function(m, Sigma){\n  Sigma_inv &lt;- solve(Sigma)\n  function(theta, rho){\n    - log_p(theta) + 0.5 * sum(rho^2)\n  }\n}\nH &lt;- construir_H(m, Sigma)\nlog_p(c(1,3))\n\n          [,1]\n[1,] -1.388889\n\ngrad_log_p(c(1,3))\n\n          [,1]\n[1,]  2.777778\n[2,] -2.222222\n\n\nAhora, implementamos el algoritmo de HMC. Primero, definimos una función\n\nhamilton_mc &lt;- function(n, theta_0 = c(0,0), log_p, grad_log_p, epsilon, L){\n  p &lt;- length(theta_0)\n  theta &lt;- matrix(0, n, p)\n  theta[1, ] &lt;- theta_0\n  rho &lt;- matrix(0, n, p)\n  theta_completa &lt;- matrix(0, n*L, p)\n  theta_completa[1, 0] &lt;- theta_0\n  rho_completa &lt;- matrix(0, n*L, p) \n  indice_completa &lt;- 2\n  rechazo &lt;- 0\n  for(i in 2:n){\n    prop_rho &lt;- rnorm(p)\n    rho[i-1, ] &lt;- prop_rho\n    prop_theta &lt;- theta[i-1, ]\n    for(t in 1:L){\n      prop_rho &lt;- prop_rho + 0.5 * epsilon * grad_log_p(prop_theta)\n      prop_theta &lt;- prop_theta + epsilon * prop_rho \n      prop_rho  &lt;- prop_rho + 0.5 * epsilon * grad_log_p(prop_theta)\n      theta_completa[indice_completa,] &lt;- prop_theta\n      rho_completa[indice_completa,] &lt;- prop_rho\n      indice_completa &lt;- indice_completa + 1\n    }\n  \n    q &lt;- min(1, exp(H(theta[i-1, ], rho[i-1, ]) - \n                  H(prop_theta, prop_rho))) \n    if(runif(1) &lt; q){\n      theta[i, ] &lt;- prop_theta\n    } else {\n      rechazo &lt;- rechazo + 1\n      theta[i, ] &lt;- theta[i-1, ]\n      rho[i, ] &lt;- rho[i-1, ]\n      theta_completa[indice_completa - 1,] &lt;- theta[i-1, ]\n      rho_completa[indice_completa - 1,] &lt;- rho[i-1, ]\n    } \n  }\n  print(rechazo / n)\n  list(sims = tibble(x = theta[,1], y = theta[,2]),\n       trayectorias = tibble(x = theta_completa[,1], y = theta_completa[,2]) |&gt;\n         mutate(iteracion = rep(1:n, each = L), paso = rep(1:L, times = n)))\n}\n\nRevisamos que la muestra aproxima apropiadamente nuestra distribución\n\nset.seed(10)\nhmc_salida &lt;- hamilton_mc(1000, c(0,0), log_p, grad_log_p, 0.2, 12)\n\n[1] 0.016\n\nggplot(hmc_salida$sims, aes(x = x, y = y)) + geom_point() +\n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c(0.9), type = \"norm\", colour = \"salmon\") +\n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c( 0.5), type = \"norm\", colour = \"salmon\") +\n  stat_ellipse(level = c( 0.9), colour = \"green\", type = \"norm\") +\n  stat_ellipse(level = c( 0.5), colour = \"green\", type = \"norm\") \n\n\n\n\n\n\n\n\n\ntray_tbl &lt;- hmc_salida$trayectorias\nhead(tray_tbl)\n\n# A tibble: 6 × 4\n        x      y iteracion  paso\n    &lt;dbl&gt;  &lt;dbl&gt;     &lt;int&gt; &lt;int&gt;\n1  0      0              1     1\n2 -0.0185 0.0409         1     2\n3 -0.0757 0.231          1     3\n4 -0.148  0.545          1     4\n5 -0.201  0.940          1     5\n6 -0.192  1.37           1     6\n\n\n\nlibrary(gganimate)\nanim_hmc &lt;- ggplot(tray_tbl |&gt; mutate(iter = 4*as.numeric(paso == 1), \n                          s = as.numeric(paso == 2)) |&gt; \n         filter(iteracion &lt; 30) |&gt; \n         mutate(tiempo = row_number()) |&gt; \n         mutate(tiempo = tiempo + cumsum(50 * s)), \n       aes(x = x, y = y)) + \n    geom_point(aes(colour = iter, alpha = iter, size = iter, group = tiempo)) +\n    geom_path(colour = \"gray\", alpha = 0.5) +\n  transition_reveal(tiempo) +\n  elipses_normal +\n  theme(legend.position = \"none\") \nanim_save(animation = anim_hmc, filename = \"figuras/hmc-normal.gif\", \n          renderer = gifski_renderer())\n\n\n\n\nHMC\n\n\nObservaciones:\n\nNótese que ahora podemos dar pasos más grandes a lo largo de los lugares donde concentra mayor probabilidad.\nEsto implica dos cosas: evitamos el comportamiento de caminata aleatoria (pasos muy cortos), y también tasas de rechazo alto (cuando los pasos son muy grandes en HMC)\nEl algoritmo utiliza información adicional: además de calcular la posterior, como en metropolis, es necesario calcular también el gradiente de la posterior.\nEste algoritmo hace más trabajo para cada iteración (requiere la integración leapfrog), pero cada iteración es más informativa\nBien afinado, funciona para problemas de dimensión alta (cientos o miles de parámetros), donde geométricamente la densidad está concentrada en un espacio geométricamente chico. Existen todavía dificultades que discutiremos en otros modelos más adelante.\n\n\n\n\n\n\n\nTip\n\n\n\nObservamos que hasta ahora no hemos aplicado estos algoritmos para simular de la posterior de un modelo: hemos tomado distribuciones fijas y usamos MCMC para simular de ellas. El proceso para una posterior es el mismo, pero usualmente más complicado pues generalmente involucra mucho más parámetros y una posterior que no tiene una forma analítica conocida.\nSin embargo, la aplicación para una posterior es la misma: siempre podemos calcular el logaritmo de la posterior (al menos hasta una constante de proporcionalidad), y siempre podemos usar diferenciación automática para calcular el gradiente de la log posterior. Podemos aplicar entonces HMC o Metropolis.\n\n\n\n\nComparación de HMC y Metropolis\nFinalmente, haremos una comparación entre el desempeño de HMC y Metropolis en el caso de la distribución normal. Utilizaremos otra normal bivariada con más correlación.\n\nset.seed(737)\nSigma &lt;- matrix(c(1, -0.9, -0.9, 1), nrow = 2)\nm &lt;- c(1, 1)\nlog_p &lt;- construir_log_p(m, Sigma)\ngrad_log_p &lt;- construir_grad_log_p(m, Sigma)\nsystem.time(hmc_1 &lt;- hamilton_mc(1000, c(1,2), log_p, grad_log_p, 0.2, 12))\n\n[1] 0.042\n\n\n   user  system elapsed \n  0.065   0.000   0.065 \n\nsystem.time(metropolis_1 &lt;- metropolis_mc(1000, c(1,2), log_p, 0.2, 0.2))\n\n[1] 0.204\n\n\n   user  system elapsed \n  0.017   0.000   0.018 \n\nsystem.time(metropolis_2 &lt;- metropolis_mc(1000, c(1,2), log_p, 1, 1))\n\n[1] 0.692\n\n\n   user  system elapsed \n  0.018   0.000   0.018 \n\n\n\nsims_hmc &lt;- hmc_1$sims |&gt; mutate(n_sim = row_number()) |&gt; \n  mutate(algoritmo = \"hmc\")\nsims_metropolis_1 &lt;- metropolis_1 |&gt; \n  mutate(algoritmo = \"metropolis (corto)\") \nsims_metropolis_2 &lt;- metropolis_2 |&gt; \n  mutate(algoritmo = \"metropolis (largo)\") \nsims_comp &lt;- bind_rows(sims_hmc, sims_metropolis_1, sims_metropolis_2)\nanim_comp &lt;- ggplot(sims_comp |&gt; filter(n_sim &lt; 200)) + \n  transition_reveal(n_sim) +\n  theme(legend.position = \"none\") +\n  geom_path(aes(x, y), colour = \"gray\", alpha = 0.2) + \n    geom_point(aes(x, y, group = n_sim)) +\n  facet_wrap(~algoritmo)\nanim_save(animation = anim_comp, filename = \"figuras/comparacion-normal.gif\", height = 250, width = 500,\n          units = \"px\",\n          renderer = gifski_renderer())\n\n\n\n\nComparación\n\n\n\n\nHMC en Stan\nEn Stan se incluyen tres componentes adicionales importantes para estimar posteriores de manera eficiente:\n\nPeriodos de warm-up (calentamiento) y sampling (muestreo). En el periodo de calentamiento, el muestreador afina tamaños de paso, escalamiento de la distribución de propuesta (normal multivariada), y otros parámetros de manera automática.\nImplementación de diferenciación automática para no tener que calcular el grandiente de la log posterior directamente. A partir del código que damos, se crean automáticamente funciones que calculan el grandiente (no es una aproximación numérica).\nImplementación de HMC sin vueltas en U (NUTS): una afinación adicional es dinámicamente adaptar el número de pasos de integración para evitar “regresos”, como vimos que sucedía en los ejemplos de arriba. Ver por ejemplo aquí, o la documentación de Stan.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "08-mcmc.html#diagnósticos-de-convergencia",
    "href": "08-mcmc.html#diagnósticos-de-convergencia",
    "title": "8  Markov Chain Monte Carlo",
    "section": "8.3 Diagnósticos de convergencia",
    "text": "8.3 Diagnósticos de convergencia\nAunque casi nunca es posible demostrar rigurosamente que las simulaciones de un algoritmo MCMC dan buena aproximación de la distribución posterior de interés, especialmente con HMC y NUTS, tenemos muchos diagnósticos que fallan cuando existen problemas serios.\nEn primer lugar, será útil correr distintas cadenas con valores iniciales aleatorios diferentes, analizamos cada una y las comparamos entre sí. Recordamos que cada una de estas cadenas tiene como distribución estacionaria límite la distribución posterior. Diagnósticos que indican que las cadenas se comportan de manera muy distinta, explorando distintas regiones del espacio de parámetros, o que no han convergido porque exploran lentamente el espacio de parámetros, son señales de problemas.\nLos diagnósticos más comunes son:\n\nTraza de cadenas\nMedida R-hat de convergencia: mide la variabilidad entre cadenas y dentro de cadenas.\nNúmero de muestras efectivas (ESS) y autocorrelación.\nTransiciones divergentes.\n\n\nModelos con variables latentes\nVeremos el ejemplo de calificación de vinos de distintos países de McElreath (2020), sus diagnósticos, y aprovecharemos para introducir variables no observadas o latentes para enriquecer nuestras herramientas de modelación.\nNuestra pregunta general es si el país de origen de los vinos influye en su calidad. Los datos que tenemos son calificaciones de vinos de distintos países por distintos jueces. La calidad del vino no la observamos directamente, sino que es causa de las calificaciones que recibe. Para construir nuestro diagrama, las consideraciones básicas son:\n\nEl origen del vino es una causa del calidad del vino (es nuestra cantidad a estimar).\nLos jueces tienen distintas maneras de calificar, de manera que son causa de variación en las calificaciones (hay jueces más duros, otros más barcos, etc.) No observamos directamente que tan “duro” es cada juez.\nLos jueces califican vinos de distintos países de manera ciega. Sin embargo es posible que reconozcan el país de origen por las características de los vinos, de manera que puede existir un efecto directo de Origen en Calificación (no pasa por Calidad).\nEs posible que Jueces de distintos países tienen distintos estándares de calificación.\n\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Origen\n    Score\n    Origen_Juez\n  node [shape = circle]\n    Q\n    J\n  edge [minlen = 3]\n    Origen -&gt; Q\n    Origen -&gt; Score\n    Q -&gt; Score\n    J -&gt; Score\n    Origen_Juez -&gt; J\n}\n\")\n\n\n\n\n\n\nY vemos, por nuestro análisis del DAG, que podemos identificar el efecto de Origen sobre Calidad sin necesidad de estratificar por ninguna variable (no hay puertas traseras). Sin embaergo, podemos estratificar por Juez para obtener más precisión (ver sección anterior de buenos y malos controles).\n\n8.3.0.1 Primera iteración: modelo simple\nComenzamos con un modelo simple, y lo iremos construyendo para obtener la mejor estimación posible de la influencia del país de origen en la calidad del vino. Nuestro primer modelo consideramos que la calificación de cada vino depende de su calidad, y modelamos con una normal:\n\\[S_i \\sim \\text{Normal}(\\mu_i, \\sigma)\\] donde \\[\\mu_i = Q_{vino(i)}\\]. Nuestra medida de calidad tiene escala arbitaria. Como usaremos la calificación estandarizada, podemos poner \\[Q_j \\sim \\text{Normal}(0, 1).\\] finalmente, ponemos una inicial para \\(\\sigma\\), por ejemplo \\(\\sigma \\sim \\text{Exponential}(1)\\) (puedes experimentar con una normal truncada también)\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.7.1\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.34.0\n\n\n- CmdStan version: 2.34.0\n\n\n\nA newer version of CmdStan is available. See ?install_cmdstan() to install it.\nTo disable this check set option or environment variable CMDSTANR_NO_VER_CHECK=TRUE.\n\nmod_vinos_1 &lt;- cmdstan_model(\"./src/vinos-1.stan\")\nprint(mod_vinos_1)\n\ndata {\n  int&lt;lower=0&gt; N; //número de calificaciones\n  int&lt;lower=0&gt; n_vinos; //número de vinos\n  int&lt;lower=0&gt; n_jueces; //número de jueces\n  vector[N]  S;\n  array[N]  int juez;\n  array[N]  int vino;\n}\n\nparameters {\n  vector[n_vinos] Q;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  vector[N] media_score;\n  // determinístico dado parámetros\n  for (i in 1:N){\n    media_score[i] = Q[vino[i]];\n  }\n}\n\nmodel {\n  // partes no determinísticas\n  S ~ normal(media_score, sigma);\n  Q ~ std_normal();\n  sigma ~ exponential(1);\n}\n\n\n\n# Wines 2022 de Statistical Rethinking\nwines_2012 &lt;- read_csv(\"../datos/wines_2012.csv\")\n\nRows: 180 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): judge, flight, wine\ndbl (3): score, wine.amer, judge.amer\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(wines_2012)\n\nRows: 180\nColumns: 6\n$ judge      &lt;chr&gt; \"Jean-M Cardebat\", \"Jean-M Cardebat\", \"Jean-M Cardebat\", \"J…\n$ flight     &lt;chr&gt; \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"whit…\n$ wine       &lt;chr&gt; \"A1\", \"B1\", \"C1\", \"D1\", \"E1\", \"F1\", \"G1\", \"H1\", \"I1\", \"J1\",…\n$ score      &lt;dbl&gt; 10.0, 13.0, 14.0, 15.0, 8.0, 13.0, 15.0, 11.0, 9.0, 12.0, 1…\n$ wine.amer  &lt;dbl&gt; 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,…\n$ judge.amer &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\nwines_2012 &lt;- wines_2012 |&gt; \n  mutate(juez_num = as.numeric(factor(judge)),\n         vino_num = as.numeric(factor(wine))) |&gt; \n  mutate(score_est = (score - mean(score))/sd(score))\n\n\nn_jueces &lt;- length(unique(wines_2012$juez_num))\nn_vinos &lt;- length(unique(wines_2012$vino_num))\nc(\"num_vinos\" = n_jueces, \"num_jueces\" = n_vinos, \"num_datos\" = nrow(wines_2012))\n\n num_vinos num_jueces  num_datos \n         9         20        180 \n\n\n\ndatos_lst &lt;- list(\n  N = nrow(wines_2012),\n  n_vinos = n_vinos,\n  n_jueces = n_jueces,\n  S = wines_2012$score_est,\n  vino = wines_2012$vino_num,\n  juez = wines_2012$juez_num\n)\najuste_vinos_1 &lt;- mod_vinos_1$sample(\n  data = datos_lst,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 2000,\n  refresh = 1000,\n  step_size = 0.1,\n)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 1 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 1 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 2 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 2 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 3 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 3 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 3 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 4 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 4 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 4 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 1 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 1 finished in 0.3 seconds.\nChain 2 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 3 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 2 finished in 0.4 seconds.\nChain 3 finished in 0.4 seconds.\nChain 4 finished in 0.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.6 seconds.\n\n\nVemos que hay variabilidad en los vinos:\n\najuste_vinos_1$summary(c(\"Q\", \"sigma\")) |&gt; \n  select(variable, mean, sd, q5, q95, rhat, ess_bulk, ess_tail) |&gt; \n  filter(variable != \"lp__\") |&gt; kable()\n\n\n\n\n\nvariable\nmean\nsd\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nQ[1]\n0.1370912\n0.3170989\n-0.3960673\n0.6717348\n1.0014315\n20694.09\n5373.128\n\n\nQ[2]\n0.1026616\n0.3206776\n-0.4251738\n0.6289236\n1.0005150\n20994.93\n5362.172\n\n\nQ[3]\n0.2712234\n0.3179687\n-0.2471324\n0.7978429\n1.0003059\n20676.69\n5913.964\n\n\nQ[4]\n0.5547986\n0.3134388\n0.0433080\n1.0687915\n1.0004011\n18730.09\n5575.563\n\n\nQ[5]\n-0.1201627\n0.3148910\n-0.6355627\n0.3899127\n1.0014694\n19760.24\n5848.199\n\n\nQ[6]\n-0.3703511\n0.3121537\n-0.8799762\n0.1454459\n1.0004956\n16654.60\n5972.842\n\n\nQ[7]\n0.2864329\n0.3138624\n-0.2308735\n0.7948061\n1.0009093\n17442.52\n6084.769\n\n\nQ[8]\n0.2710509\n0.3192163\n-0.2555284\n0.8051071\n1.0002587\n18199.26\n5596.789\n\n\nQ[9]\n0.0795946\n0.3139398\n-0.4384925\n0.5844989\n1.0004109\n19534.73\n5983.451\n\n\nQ[10]\n0.1183569\n0.3084865\n-0.3858242\n0.6264702\n1.0003986\n21143.80\n5814.923\n\n\nQ[11]\n-0.0103080\n0.3209106\n-0.5455419\n0.5102136\n0.9998260\n20940.00\n5531.936\n\n\nQ[12]\n-0.0290247\n0.3216726\n-0.5599822\n0.5001753\n1.0007141\n18276.46\n5849.228\n\n\nQ[13]\n-0.1054757\n0.3118851\n-0.6094262\n0.4135486\n1.0029519\n20575.88\n5957.570\n\n\nQ[14]\n0.0052002\n0.3133557\n-0.5046232\n0.5253581\n1.0007147\n17541.60\n5723.524\n\n\nQ[15]\n-0.2154847\n0.3184756\n-0.7401160\n0.3121019\n1.0008500\n17150.00\n5412.980\n\n\nQ[16]\n-0.2009862\n0.3150938\n-0.7222090\n0.3153228\n1.0011144\n17596.06\n5120.461\n\n\nQ[17]\n-0.1424943\n0.3156712\n-0.6649443\n0.3794220\n0.9998971\n20718.38\n6172.910\n\n\nQ[18]\n-0.8601598\n0.3142863\n-1.3841900\n-0.3425655\n0.9998919\n18745.31\n6126.091\n\n\nQ[19]\n-0.1607195\n0.3113936\n-0.6657445\n0.3425211\n0.9998770\n18166.25\n6352.717\n\n\nQ[20]\n0.3802103\n0.3132727\n-0.1266551\n0.8961100\n1.0001031\n21072.45\n5060.363\n\n\nsigma\n0.9968337\n0.0543950\n0.9118465\n1.0916805\n1.0004242\n13245.07\n6385.483\n\n\n\n\n\n\n\n\nPara hacer diagnósticos, podemos comenzar con las trazas de una cadena para todas las estimaciones de calidad de vino:\n\nlibrary(bayesplot)\n\nThis is bayesplot version 1.11.1\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\nmcmc_trace(ajuste_vinos_1$draws(\"Q\", format = \"df\") |&gt; filter(.chain == 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nLa traza de una cadena es la gráfica de las simulaciones de cada parámetro. Generalmente buscamos que: no tenga tendencia, que no se quede “atorada” en algunos valores, y que no muestre oscilaciones de baja frecuencia (la cadena “vaga” por los valores que explora).\n\n\nSi incluímos todas las cadenas, nos fijemos en que todas ellas exploren regiones similares del espacio de parámetros:\n\ncolor_scheme_set(\"viridis\")\nmcmc_trace(ajuste_vinos_1$draws(\"Q\", format = \"df\")) \n\n\n\n\n\n\n\n\nLo que no queremos ver es lo siguiente, por ejemplo:\n\najuste_vinos_malo &lt;- mod_vinos_1$sample(\n  data = datos_lst,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 5,\n  iter_sampling = 100,\n  refresh = 1000,\n  step_size =1 ,\n  seed = 123\n)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 WARNING: No variance estimation is \nChain 1          performed for num_warmup &lt; 20 \nChain 1 Iteration:   1 / 105 [  0%]  (Warmup) \nChain 1 Iteration:   6 / 105 [  5%]  (Sampling) \nChain 1 Iteration: 105 / 105 [100%]  (Sampling) \nChain 2 WARNING: No variance estimation is \nChain 2          performed for num_warmup &lt; 20 \nChain 2 Iteration:   1 / 105 [  0%]  (Warmup) \nChain 2 Iteration:   6 / 105 [  5%]  (Sampling) \nChain 2 Iteration: 105 / 105 [100%]  (Sampling) \nChain 3 WARNING: No variance estimation is \nChain 3          performed for num_warmup &lt; 20 \nChain 3 Iteration:   1 / 105 [  0%]  (Warmup) \nChain 3 Iteration:   6 / 105 [  5%]  (Sampling) \nChain 3 Iteration: 105 / 105 [100%]  (Sampling) \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/Rtmpzl2o5P/model-2944458c03fd.stan', line 25, column 2 to column 33)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 4 WARNING: No variance estimation is \nChain 4          performed for num_warmup &lt; 20 \nChain 4 Iteration:   1 / 105 [  0%]  (Warmup) \nChain 4 Iteration:   6 / 105 [  5%]  (Sampling) \nChain 4 Iteration: 105 / 105 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.2 seconds.\n\n\nWarning: 324 of 400 (81.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nWarning: 2 of 4 chains had an E-BFMI less than 0.3.\nSee https://mc-stan.org/misc/warnings for details.\n\n\n\ncolor_scheme_set(\"viridisA\")\nmcmc_trace(ajuste_vinos_malo$draws(\"Q\", format = \"df\")) \n\n\n\n\n\n\n\n\nHay varios problemas graves:\n\nAlgunas cadenas parecen “atoradas” en ciertos valores\nAlgunas cadenas parecen caminatas aleatorias (oscilaciones de baja frecuencia)\nLas cadenas no exploran de manera similar el espacio de parámetros\n\n\n\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  }
]